---
title: "The rise of \"context engineering\""
source: "https://blog.langchain.com/the-rise-of-context-engineering/"
author:
  - "[[Harrison Chase]]"
published: 2025-06-24
created: 2025-06-26
description: "Header image from Dex Horthy on Twitter.Context engineering is building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task.Most of the time when an agent is not performing reliably the underlying cause is that the"
tags:
  - "clippings"
---
*标题图片来自* [*推特上的德克斯·霍尔蒂*](https://x.com/dexhorthy/status/1933283008863482067?ref=blog.langchain.com) *。*

上下文工程是构建动态系统，以便以正确的格式提供正确的信息和工具，使大语言模型（LLM）能够合理地完成任务。

大多数情况下，当智能体表现不稳定时，根本原因是没有向模型传达适当的上下文、指令和工具。

大语言模型（LLM）应用正在从单一提示发展为更复杂、动态的智能体系统。因此，上下文工程正成为人工智能工程师能够培养的最重要技能。

## 什么是上下文工程？

上下文工程是构建动态系统，以正确的格式提供正确的信息和工具，使大语言模型（LLM）能够合理地完成任务。

这就是我喜欢的定义，它基于托比·卢特克（Tobi Lutke）、安库尔·戈亚尔（Ankur Goyal）和瓦尔登·严（Walden Yan）最近对此的看法。让我们来剖析一下。

**上下文工程是一个系统**

复杂的智能体可能会从多个来源获取上下文。上下文可以来自应用程序的开发者、用户、先前的交互、工具调用或其他外部数据。将这些全部整合在一起需要一个复杂的系统。

**这个系统是动态的**

许多这些上下文片段可以动态传入。因此，构建最终提示的逻辑也需要是动态的。它不仅仅是一个静态提示。

**你需要正确的信息**

智能代理系统表现不佳的一个常见原因是它们没有正确的上下文。大语言模型无法读取人的心思——你需要给它们正确的信息。输入垃圾，输出垃圾。

**你需要合适的工具**

并非总是仅基于输入，LLM 就能解决任务。在这些情况下，如果你想让 LLM 有能力这样做，你需要确保它有合适的工具。这些工具可以是用于查找更多信息、采取行动或介于两者之间的任何工具。给 LLM 提供合适的工具与给它提供正确的信息同样重要。

**格式很重要**

就像与人类交流一样，你与大语言模型（LLMs）的交流方式很重要。一条简短但具有描述性的错误消息比一大串 JSON 数据更有用。这同样适用于工具。在确保大语言模型能够使用工具时，工具的输入参数非常重要。

**它有可能完成这项任务吗？**

当你思考上下文工程时，这是一个非常值得提出的好问题。它强化了一个观点，即大语言模型（LLMs）不是读心术者——你需要为它们的成功做好准备。这也有助于区分失败模式。它失败是因为你没有给它正确的信息或工具吗？还是它已经掌握了所有正确信息，只是搞砸了？这些失败模式有非常不同的解决方法。

## 为什么上下文工程很重要

当智能代理系统出错时，很大程度上是因为大型语言模型（LLM）出了问题。从第一性原理思考，大型语言模型（LLMs）可能出错有两个原因：

1. 基础模型搞砸了，它还不够好
2. 基础模型没有被传递适当的上下文以产生良好的输出

通常情况下（尤其是随着模型性能提升），模型错误更多是由第二个原因导致的。传递给模型的上下文可能由于以下几个原因而存在问题：

- 只是缺少模型做出正确决策所需的上下文。模型又不是读心术。如果你不给它们正确的上下文，它们就不会知道其存在。
- 上下文格式很差。就像人类一样，沟通很重要！当你将数据传入模型时，你对数据的格式化方式绝对会影响它的响应。

## 上下文工程与提示工程有何不同？

为什么从“提示”转向“上下文”？早期，开发者专注于巧妙措辞提示以引出更好的答案。但随着应用变得越来越复杂，向人工智能提供完整且结构化的上下文远比任何神奇的措辞重要得多这一点变得愈发明显。

我还要指出，提示工程是上下文工程的一个子集。即使你拥有所有的上下文信息，如何在提示中组织这些信息仍然至关重要。不同之处在于，你构建提示的目的不是使其在单一的输入数据集上运行良好，而是处理一组动态数据并对其进行正确格式化。

我还要强调的是，上下文的一个关键部分通常是关于大语言模型（LLM）应如何表现的核心指令。这往往是提示工程的一个关键部分。你会说为智能体应如何表现提供清晰详细的指令是上下文工程还是提示工程呢？我认为两者都有一点。

## 上下文工程的示例

一些良好的上下文工程的基本示例包括：

- 工具使用：确保如果智能体需要访问外部信息，它拥有能够访问该信息的工具。当工具返回信息时，其格式应最大程度便于大语言模型（LLMs）理解。
- 短期记忆：如果一段对话持续了一段时间，创建该对话的摘要并在未来使用。
- 长期记忆：如果用户在之前的对话中表达了偏好，能够获取该信息。
- 提示工程：关于智能体应如何表现的指令在提示中清晰列出。
- 检索：在调用大语言模型（LLM）之前，动态获取信息并将其插入到提示中。

## LangGraph 如何实现上下文工程

当我们构建 [LangGraph](https://github.com/langchain-ai/langgraph?ref=blog.langchain.com) 时，我们的构建目标是使其成为最可控的智能体框架。这也使其能够完美地实现上下文工程。

使用 LangGraph，你可以掌控一切。你决定运行哪些步骤。你决定\*\*确切地\*\*将什么输入到你的 LLM 中。你决定将输出存储在哪里。你掌控一切。

这使你能够进行所有你想要的上下文工程。代理抽象（大多数其他代理框架所强调的）的缺点之一是它们限制了上下文工程。可能存在一些地方，你无法确切更改进入大语言模型（LLM）的内容，或者无法确切更改事先运行的步骤。

旁注：Dex Horthy 的《十二要素应用》是一本非常值得一读的书。其中很多观点都与上下文工程相关（“掌控你的提示”、“掌控你的上下文构建”等）。本博客的标题图片也取自 Dex。我们非常欣赏他阐述该领域重要内容的方式。

## LangSmith 如何助力上下文工程

[LangSmith](https://smith.langchain.com/?ref=blog.langchain.com) 是我们的大语言模型（LLM）应用可观测性和评估解决方案。LangSmith 的关键特性之一是能够 [追踪你的智能体调用](https://docs.smith.langchain.com/observability/tutorials/observability?ref=blog.langchain.com) 。虽然在我们构建 LangSmith 时“上下文工程”这个术语还不存在，但它恰如其分地描述了这种追踪所带来的帮助。

LangSmith 让你能够查看智能体中发生的所有步骤。这使你可以了解为收集发送到 LLM 的数据而运行了哪些步骤。

LangSmith 让你能够查看 LLM 的精确输入和输出。这使你能确切了解输入到 LLM 的内容——它所拥有的数据以及数据的格式。然后，你可以调试这些内容是否包含任务所需的所有相关信息。这包括 LLM 可以使用哪些工具——这样你就能调试它是否被赋予了有助于完成手头任务的适当工具。

## 沟通就是你所需要的一切

几个月前，我写了一篇名为《沟通就是一切》的博客。主要观点是，与大语言模型（LLM）进行沟通很困难，且未得到足够重视，它常常是许多智能体错误的根源。其中许多观点都与上下文工程有关！

上下文工程并不是一个新想法——在过去一两年里，智能体构建者们一直在这么做。这是一个新术语，恰如其分地描述了一项日益重要的技能。我们将围绕这个主题撰写并分享更多内容。我们认为我们构建的许多工具（LangGraph、LangSmith）非常适合用于实现上下文工程，所以我们很高兴看到对这方面的重视开始兴起。