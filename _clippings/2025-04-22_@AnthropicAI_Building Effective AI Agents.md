---
title: "Building Effective AI Agents"
source: "https://www.anthropic.com/engineering/building-effective-agents"
author:
  - "[[@AnthropicAI]]"
published:
created: 2025-04-22
description: "Discover how Anthropic approaches the development of reliable AI agents. Learn about our research on agent capabilities, safety considerations, and technical framework for building trustworthy AI."
tags:
  - "clippings"
---
[Anthropic 公司的工程团队](https://www.anthropic.com/engineering) ![](https://www-cdn.anthropic.com/images/4zrzovbb/website/039b6648c28eb33070a63a58d49013600b229238-2554x2554.svg)

## 构建有效的智能体

在过去的一年里，我们与数十个团队合作，为各行各业构建大型语言模型（LLM）智能体。一直以来，最成功的实现方式并非使用复杂的框架或专门的库。相反，它们是用简单、可组合的模式构建的。

在这篇文章中，我们分享了我们在与客户合作以及自行构建智能体过程中学到的知识，并为开发者提供关于构建高效智能体的实用建议。

## 什么是智能体？

“智能体”可以有多种定义方式。一些客户将智能体定义为完全自主的系统，这些系统可以长时间独立运行，使用各种工具来完成复杂任务。另一些人则用这个术语来描述遵循预定义工作流程的更具规范性的实现方式。在 Anthropic，我们将所有这些变体归类为智能体系统，但在工作流程和智能体之间做出了重要的架构区分：

- 工作流是通过预定义代码路径编排LLMs和工具的系统。
- 另一方面，智能体是这样的系统，其中LLMs动态地指导自身的进程和工具使用，保持对其完成任务方式的控制。

以下，我们将详细探讨这两种智能体系统。在附录 1（“实践中的智能体”）中，我们描述了客户在使用这类系统时发现具有特别价值的两个领域。

## 何时（以及何时不）使用智能体

使用LLMs构建应用程序时，我们建议找到尽可能简单的解决方案，仅在必要时增加复杂性。这可能意味着根本不构建智能系统。智能系统通常会以延迟和成本为代价来换取更好的任务性能，您应该考虑这种权衡何时是合理的。

当需要更多复杂性时，工作流为定义明确的任务提供可预测性和一致性，而在需要大规模的灵活性和模型驱动的决策时，智能体是更好的选择。然而，对于许多应用程序来说，使用检索和上下文示例优化单个LLM调用通常就足够了。

## 何时以及如何使用框架

有许多框架使智能体系统更易于实现，包括：

- 来自 LangChain 的 LangGraph；
- 亚马逊云科技 Bedrock 的人工智能代理框架；
- Rivet，一款拖放式图形用户界面LLM工作流程构建器；以及
- Vellum，另一个用于构建和测试复杂工作流程的图形用户界面工具。

这些框架通过简化标准的底层任务（如调用LLMs、定义和解析工具以及将调用链接在一起），使入门变得容易。然而，它们通常会创建额外的抽象层，这可能会掩盖底层的提示和响应，使其更难调试。当简单的设置就足够时，它们还可能会让人忍不住增加复杂性。

我们建议开发者首先直接使用LLM API：许多模式只需几行代码就能实现。如果你确实使用了框架，请确保你理解其底层代码。对底层内容的错误假设是导致客户出错的常见原因。

请参阅我们的烹饪书以获取一些示例实现。

## 构建模块、工作流和代理

在本节中，我们将探讨在生产环境中看到的智能系统的常见模式。我们将从基础构建块——增强型LLM开始，然后逐步增加复杂性，从简单的组合工作流程到自主智能体。

### 构建模块：增强的LLM

智能系统的基本构建模块是一个通过检索、工具和记忆等增强功能进行增强的LLM。我们当前的模型可以积极利用这些能力——生成自己的搜索查询、选择合适的工具以及确定要保留哪些信息。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)

增强的LLM

我们建议关注实现的两个关键方面：根据您的特定用例定制这些功能，并确保它们为您的LLM提供一个简单且文档完善的接口。虽然有许多方法可以实现这些增强功能，但一种方法是通过我们最近发布的模型上下文协议，该协议允许开发人员通过简单的客户端实现与不断发展的第三方工具生态系统进行集成。

在本文的其余部分，我们将假设每次LLM调用都可以使用这些增强功能。

### 工作流程：提示链

提示链将任务分解为一系列步骤，其中每个 LLM 调用都处理上一个调用的输出。你可以在任何中间步骤添加编程检查（见下图中的“门”），以确保流程仍在正轨上。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75)

提示链工作流程

何时使用此工作流程：此工作流程适用于任务可以轻松且清晰地分解为固定子任务的情况。主要目标是通过使每个LLM调用成为更简单的任务，以延迟换取更高的准确性。

**提示链有用的示例：**

- 生成营销文案，然后将其翻译成另一种语言。
- 编写文档大纲，检查大纲是否符合某些标准，然后根据大纲编写文档。

### 工作流程：路由

路由对输入进行分类，并将其导向专门的后续任务。此工作流程允许分离关注点，并构建更专门的提示。没有此工作流程，针对一种输入进行优化可能会损害其他输入的性能。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75)

路由工作流程

何时使用此工作流程：对于复杂任务，路由效果良好。在这些任务中，存在不同的类别，这些类别最好分别处理，并且可以通过LLM或更传统的分类模型/算法准确地进行分类。

**路由有用的示例：**

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）导入不同的下游流程、提示和工具中。
- 将简单/常见问题路由到较小的模型，如 Claude 3.5 Haiku，将困难/不寻常的问题路由到更强大的模型，如 Claude 3.5 Sonnet，以优化成本和速度。

### 工作流程：并行化

LLMs 有时可以同时处理一项任务，并通过编程方式汇总它们的输出。这种工作流程，即并行化，表现为两种关键变体：

- 分段：将一个任务分解为并行运行的独立子任务。
- 投票：多次运行相同任务以获得多样化的输出。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75)

并行化工作流程

何时使用此工作流程：当划分后的子任务能够为了提高速度而进行并行化处理时，或者当需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于具有多个考量因素的复杂任务，当每个考量因素由单独的LLM调用处理时，LLMs通常表现得更好，这样可以专注于每个特定方面。

**并行化有用的示例：**

- 分段：
	- 在一个模型实例处理用户查询的同时，另一个模型实例对查询进行不当内容或请求筛查的情况下实施防护机制。这往往比让同一个LLM调用同时处理防护机制和核心响应的表现更好。
	- 自动化评估以评估LLM性能，其中每个LLM调用评估模型在给定提示下性能的不同方面。
- **Voting**:
	- 审查一段代码是否存在漏洞，其中几个不同的提示会在发现问题时审查并标记该代码。
	- 评估给定的一段内容是否不合适，通过多个提示来评估不同方面或需要不同的投票阈值以平衡误报和漏报。

### 工作流程：编排器 - 工作节点

在编排器-工作器工作流程中，一个中央LLM动态地分解任务，将它们委托给工作器LLMs，并合成它们的结果。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75)

编排器-工作节点工作流程

何时使用此工作流程：此工作流程非常适合于无法预测所需子任务的复杂任务（例如在编码中，需要更改的文件数量以及每个文件中的更改性质可能取决于任务）。虽然它在拓扑结构上与并行化相似，但与并行化的关键区别在于其灵活性——子任务不是预先定义的，而是由协调器根据特定输入确定的。

**编排器-工作节点有用的示例：**

- 每次对多个文件进行复杂更改的编码产品。
- 搜索任务，这些任务涉及从多个来源收集和分析信息以获取可能的相关信息。

### 工作流程：评估器-优化器

在评估器-优化器工作流程中，一个LLM调用生成一个响应，而另一个在循环中提供评估和反馈。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75)

评估器-优化器工作流程

何时使用此工作流程：当我们有明确的评估标准，并且迭代优化能提供可衡量的价值时，此工作流程特别有效。良好契合的两个标志是，第一，当人工阐述其反馈时，LLM响应能够得到明显改善；第二，LLM能够提供此类反馈。这类似于人类作家在撰写一篇精致文档时可能经历的迭代写作过程。

**评估器-优化器有用的示例：**

- 文学翻译中存在一些细微差别，译者LLM 最初可能无法捕捉到，但评估者LLM 可以提供有用的批评意见。
- 复杂的搜索任务，需要多轮搜索和分析以收集全面信息，在此过程中评估者决定是否需要进一步搜索。

### Agents

随着LLMs在关键能力方面逐渐成熟，智能体正在生产环境中崭露头角，这些关键能力包括理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复。智能体通过接收人类用户的命令或与人类用户进行交互式讨论来开始工作。一旦任务明确，智能体就会独立进行规划和操作，可能会返回与人类进一步获取信息或寻求判断。在执行过程中，智能体在每一步从环境中获取“真实情况”（例如工具调用结果或代码执行情况）以评估其进展至关重要。然后，智能体可以在检查点或遇到阻碍时暂停以获取人类反馈。任务通常在完成时终止，但也通常会设置停止条件（例如最大迭代次数）以进行控制。

智能体可以处理复杂的任务，但其实现通常很简单。它们通常只是在一个循环中根据环境反馈使用工具。因此，清晰且周全地设计工具集及其文档至关重要。我们在附录 2（“为你的工具进行提示工程”）中详细阐述了工具开发的最佳实践。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&w=3840&q=75)

自主代理

何时使用智能体：智能体可用于开放式问题，即难以或无法预测所需步骤数，且无法硬编码固定路径的情况。LLM可能会运行多个回合，并且你必须对其决策有一定程度的信任。智能体的自主性使其非常适合在可信任环境中扩展任务。

智能体的自主性意味着更高的成本，以及错误叠加的可能性。我们建议在沙盒环境中进行广泛测试，并设置适当的防护措施。

**智能体有用的示例：**

以下示例来自我们自己的实现：

- 一个用于解决 SWE-bench 任务的编码代理，这些任务涉及根据任务描述对许多文件进行编辑；
- 我们的“计算机使用”参考实现，即 Claude 使用计算机来完成任务的情况。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&w=3840&q=75)

编码代理的高级流程

## 组合并自定义这些模式

这些构建模块并非规定性的。它们是常见的模式，开发人员可以对其进行塑造和组合以适应不同的用例。与任何LLM功能一样，成功的关键在于衡量性能并对实现进行迭代。再说一次：只有在能明显改善结果时，才应考虑增加复杂性。

## Summary

在LLM领域取得成功并非在于构建最复杂的系统。而是在于构建适合你需求的正确系统。从简单的提示开始，通过全面评估进行优化，只有在更简单的解决方案不足时才添加多步智能系统。

在实现智能体时，我们尝试遵循三个核心原则：

1. 在你的智能体设计中保持简洁。
2. 通过明确展示智能体的规划步骤来优先考虑透明度。
3. 通过详尽的工具文档和测试，精心设计您的智能体-计算机接口（ACI）。

框架可以帮助您快速上手，但在进入生产阶段时，不要犹豫减少抽象层并使用基本组件进行构建。遵循这些原则，您可以创建出不仅功能强大，而且可靠、可维护且受用户信任的智能体。

### 致谢

作者：埃里克·施伦茨（Erik Schluntz）和巴里·张（Barry Zhang）。本作品借鉴了我们在 Anthropic 构建智能体的经验以及客户分享的宝贵见解，对此我们深表感激。

## 附录 1：实际中的代理

我们与客户的合作揭示了人工智能代理的两个特别有前景的应用，这些应用展示了上述模式的实际价值。这两个应用都说明了代理如何为需要对话和行动、有明确成功标准、能够实现反馈循环并融入有意义的人工监督的任务带来最大价值。

### A. 客户支持

客户支持通过工具集成将熟悉的聊天机器人界面与增强功能相结合。这对于更开放型的客服代理来说是很自然的选择，因为：

- 支持交互自然地遵循对话流程，同时需要访问外部信息和执行操作；
- 工具可以集成以提取客户数据、订单历史记录和知识库文章；
- 诸如退款或更新票务等操作可以通过编程方式处理；并且
- 成功可以通过用户定义的分辨率来清晰衡量。

几家公司已经通过基于使用量的定价模式证明了这种方法的可行性，这种模式仅对成功解决的问题收费，显示出对其代理有效性的信心。

### B. 编码代理

软件开发领域在LLM功能方面展现出了巨大潜力，其能力已从代码补全发展到自主解决问题。智能体尤其有效，原因如下：

- 代码解决方案可通过自动化测试进行验证；
- 智能体可以使用测试结果作为反馈来迭代解决方案；
- 问题空间定义明确且结构清晰；并且
- 输出质量可以客观地衡量。

在我们自己的实现中，现在代理可以仅根据拉取请求描述在 SWE-bench 验证基准中解决实际的 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

## 附录 2：为你的工具设计提示词

无论你正在构建哪种智能体系统，工具都可能是你的智能体的重要组成部分。通过在我们的 API 中指定其确切结构和定义，工具使 Claude 能够与外部服务和 API 进行交互。当 Claude 做出响应时，如果它计划调用工具，将会在 API 响应中包含一个工具使用块。工具定义和规范应该像对待你的整体提示一样，给予同样多的提示工程关注。在这个简短的附录中，我们将描述如何对你的工具进行提示工程。

通常有几种方法可以指定相同的操作。例如，你可以通过编写差异（diff）来指定文件编辑，或者通过重写整个文件来指定。对于结构化输出，你可以在 Markdown 或 JSON 中返回代码。在软件工程中，像这样的差异只是表面的，可以无损地从一种格式转换为另一种格式。然而，某些格式对于LLM来说编写起来比其他格式要困难得多。编写差异需要在编写新代码之前知道块头中有多少行在变化。在 JSON 中编写代码（与 Markdown 相比）需要对换行符和引号进行额外的转义。

我们关于确定工具格式的建议如下：

- 在模型把自己逼入绝境之前，给它足够的词元来“思考”。
- 保持格式与模型在互联网文本中自然出现的格式相近。
- 确保不存在格式“开销”，例如不必精确统计数千行代码，也无需对其编写的任何代码进行字符串转义。

一条经验法则是考虑在人机界面（HCI）上投入了多少精力，并计划在创建良好的智能体-计算机界面（ACI）时投入同样多的精力。以下是关于如何做到这一点的一些想法：

- 设身处地从模型的角度想一想。根据描述和参数，使用这个工具的方法是否显而易见，还是说你需要仔细考虑一下？如果是这样，那么对模型来说可能也是如此。一个好的工具定义通常包括示例用法、边界情况、输入格式要求以及与其他工具的明确界限。
- 你如何更改参数名称或描述，以使事情更清晰明了？可以把这想象成是为团队中的初级开发人员编写一个出色的文档字符串。在使用许多类似工具时，这一点尤为重要。
- 测试模型如何使用你的工具：在我们的工作台中运行许多示例输入，以查看模型会出现哪些错误，然后进行迭代。
- 防错你的工具。更改参数，以便更难出错。

在为 SWE-bench 构建我们的智能体时，实际上我们在优化工具上花费的时间比在整个提示上花费的时间更多。例如，我们发现，在智能体移出根目录后，模型在使用相对文件路径的工具时会出错。为了解决这个问题，我们将工具改为始终要求使用绝对文件路径，并且我们发现模型能够完美地使用这种方法。