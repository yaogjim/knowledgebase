---
title: "Building Effective AI Agents"
source: "https://www.anthropic.com/engineering/building-effective-agents"
author:
  - "[[@AnthropicAI]]"
published:
created: 2025-07-01
description: "Discover how Anthropic approaches the development of reliable AI agents. Learn about our research on agent capabilities, safety considerations, and technical framework for building trustworthy AI."
tags:
  - "clippings"
---
[Anthropic 公司的工程团队](https://www.anthropic.com/engineering) ![](https://www-cdn.anthropic.com/images/4zrzovbb/website/039b6648c28eb33070a63a58d49013600b229238-2554x2554.svg)

## 构建有效的智能体

在过去一年里，我们与数十个跨行业构建大语言模型（LLM）智能体的团队合作。一直以来，最成功的实现方式并非使用复杂的框架或专门的库。相反，他们是用简单、可组合的模式进行构建。

在这篇文章中，我们分享了我们在与客户合作以及自行构建智能体过程中学到的知识，并为开发者提供关于构建高效智能体的实用建议。

## 什么是智能体？

“智能体”可以有多种定义方式。一些客户将智能体定义为完全自主的系统，这些系统能够在较长时间内独立运行，使用各种工具来完成复杂任务。另一些人则用这个术语来描述遵循预定义工作流程的更具规范性的实现方式。在 Anthropic，我们将所有这些变体都归类为 **智能体系统** ，但在 **工作流程** 和 **智能体** 之间做出了重要的架构区分：

- **工作流** 是通过预定义代码路径编排大语言模型（LLMs）和工具的系统。
- 另一方面， **智能体** 是这样的系统，其中大语言模型（LLMs）动态地指导自身的进程和工具使用，对如何完成任务保持控制。

下面，我们将详细探讨这两种智能体系统。在附录1（“实际应用中的智能体”）中，我们描述了客户在使用这类系统时发现具有特别价值的两个领域。

## 何时（以及何时不）使用智能体

在使用大语言模型（LLMs）构建应用程序时，我们建议尽可能找到最简单的解决方案，只有在必要时才增加复杂性。这可能意味着根本不构建智能体系统。智能体系统通常会以延迟和成本为代价来换取更好的任务性能，你应该考虑这种权衡何时是合理的。

当需要更多复杂性时，工作流可为定义明确的任务提供可预测性和一致性，而在需要大规模的灵活性和模型驱动的决策时，智能体则是更好的选择。然而，对于许多应用程序来说，使用检索和上下文示例优化单个 LLM 调用通常就足够了。

## 何时以及如何使用框架

有许多框架使代理系统更易于实现，包括：

- 来自 LangChain 的 [LangGraph](https://langchain-ai.github.io/langgraph/) ；
- 亚马逊云科技 Bedrock 的 [人工智能代理框架](https://aws.amazon.com/bedrock/agents/) ；
- [铆钉](https://rivet.ironcladapp.com/) ，一款拖放式图形用户界面 LLM 工作流程构建器；以及
- [韦勒姆（Vellum）](https://www.vellum.ai/) ，另一个用于构建和测试复杂工作流程的图形用户界面工具。

这些框架通过简化标准的底层任务，如调用 LLMs、定义和解析工具以及将调用链接在一起，使得入门变得容易。然而，它们常常创建额外的抽象层，这可能会掩盖底层的提示和响应，使其更难调试。当一个更简单的设置就足够时，它们还可能会让人忍不住添加复杂性。

我们建议开发者首先直接使用 LLM API：许多模式只需几行代码就能实现。如果你确实使用了某个框架，要确保你理解其底层代码。对底层情况的错误假设是导致客户出错的常见原因。

有关一些示例实现，请参阅我们的 [烹饪手册](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents) 。

## 构建模块、工作流程和智能体

在本节中，我们将探讨在实际应用中所见到的智能体系统的常见模式。我们将从基础构建模块——增强型语言模型（LLM）开始，并逐步增加复杂度，从简单的组合式工作流程到自主智能体。

### 构建模块：增强型语言模型

智能体系统的基本构建模块是一个通过检索、工具和记忆等增强功能强化的语言模型（LLM）。我们当前的模型能够积极运用这些能力——生成自己的搜索查询、选择合适的工具以及确定保留哪些信息。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)

增强型大语言模型

我们建议关注实现的两个关键方面：根据您的特定用例定制这些功能，并确保它们为您的大语言模型（LLM）提供一个简单且文档完善的接口。虽然实现这些增强功能有很多方法，但一种方法是通过我们最近发布的 [模型上下文协议](https://www.anthropic.com/news/model-context-protocol) ，该协议允许开发人员通过简单的 [客户端实现](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients) 与不断发展的第三方工具生态系统进行集成。

在本文的剩余部分，我们将假设每次 LLM 调用都可以使用这些增强功能。

### 工作流程：提示链

提示链将一个任务分解为一系列步骤，其中每个大语言模型（LLM）调用都会处理上一个调用的输出。你可以在任何中间步骤添加程序检查（见下图中的“门控”），以确保流程仍在正轨上。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75)

提示链工作流程

**何时使用此工作流程：** 此工作流程适用于任务能够轻松且清晰地分解为固定子任务的情况。主要目标是通过使每个 LLM 调用成为更简单的任务，以延迟换取更高的准确性。

**提示链很有用的示例：**

- 生成营销文案，然后将其翻译成另一种语言。
- 撰写文档大纲，检查大纲是否符合某些标准，然后根据大纲撰写文档。

### 工作流程：路由

路由对输入进行分类，并将其导向专门的后续任务。这种工作流程允许关注点分离，并构建更专门化的提示。没有这种工作流程，针对一种输入进行优化可能会损害其他输入的性能。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75)

路由工作流程

**何时使用此工作流程：** 对于复杂任务，路由效果良好。在这些任务中，存在不同的类别，分别处理会更好，并且可以通过 LLM 或更传统的分类模型/算法准确地进行分类。

**路由有用的示例：**

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导至不同的下游流程、提示和工具中。
- 将简单/常见问题路由到较小的模型，如 Claude 3.5 Haiku，将困难/不寻常的问题路由到更强大的模型，如 Claude 3.5 Sonnet，以优化成本和速度。

### 工作流程：并行化

大语言模型（LLMs）有时可以在一个任务上同时运行，并通过编程方式聚合它们的输出。这种工作流程，即并行化，表现为两种关键变体：

- **任务拆分** ：将一个任务分解为并行运行的独立子任务。
- **投票：** 多次运行同一任务以获得多样化的输出。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75)

并行化工作流程

**何时使用此工作流程：** 当划分后的子任务能够为了提高速度而进行并行处理时，或者当需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于具有多个需要考虑因素的复杂任务，当每个因素由单独的大语言模型（LLM）调用处理时，大语言模型（LLMs）通常表现得更好，这样可以专注于每个特定方面。

**并行化有用的示例：**

- **章节划分** ：
	- 实施护栏机制，即一个模型实例处理用户查询，而另一个模型实例则对查询进行筛选，以检查是否存在不当内容或请求。这种方式往往比让同一个大语言模型（LLM）调用同时处理护栏检查和核心回复的表现更好。
	- 自动化评估以评估 LLM 性能，其中每次 LLM 调用都会根据给定提示评估模型性能的不同方面。
- **Voting**:
	- 审查一段代码是否存在漏洞，其中几个不同的提示会在发现问题时对代码进行审查并标记。
	- 评估给定的一段内容是否不当，通过多个提示来评估不同方面，或者需要不同的投票阈值来平衡误报和漏报。

### 工作流程：编排器 - 工作节点

在编排器-工作器工作流程中，一个中央大语言模型（LLM）动态地分解任务，将其委托给工作器大语言模型（LLMs），并合成它们的结果。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75)

编排器-工作节点工作流程

**何时使用此工作流程：** 此工作流程非常适合于无法预测所需子任务的复杂任务（例如在编码中，需要更改的文件数量以及每个文件中的更改性质可能取决于任务）。虽然它在形式上与并行化相似，但其与并行化的关键区别在于其灵活性——子任务不是预先定义的，而是由协调器根据特定输入确定的。

**编排器-工作器模式很有用的示例：**

- 每次对多个文件进行复杂更改的编码产品。
- 搜索任务涉及从多个来源收集和分析信息以获取可能的相关信息。

### 工作流程：评估器-优化器

在评估器-优化器工作流程中，一个 LLM 调用生成响应，而另一个在循环中提供评估和反馈。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75)

评估器-优化器工作流程

**何时使用此工作流程：** 当我们有明确的评估标准，并且迭代优化能带来可衡量的价值时，此工作流程特别有效。契合度良好的两个标志是，第一，当人类阐述反馈时，LLM 的回答能得到明显改善；第二，LLM 能够提供这样的反馈。这类似于人类作家在撰写一篇完美文档时可能经历的迭代写作过程。

**评估器-优化器有用的示例：**

- 文学翻译中存在一些细微差别，翻译 LLM 最初可能无法捕捉到，但评估 LLM 可以提供有用的批评意见。
- 复杂的搜索任务，需要多轮搜索和分析以收集全面信息，在此过程中评估者决定是否有必要进行进一步搜索。

### Agents

随着大语言模型（LLMs）在关键能力方面逐渐成熟，如理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复，智能体正在生产环境中崭露头角。智能体通过接收人类用户的命令或与人类用户进行交互式讨论来开始工作。一旦任务明确，智能体就会独立进行规划和操作，可能会返回与人类进一步获取信息或寻求判断。在执行过程中，智能体在每一步从环境中获取“真实情况”（如工具调用结果或代码执行情况）以评估其进展至关重要。然后，智能体可以在检查点或遇到阻碍时暂停以获取人类反馈。任务通常在完成时终止，但也通常会设置停止条件（如最大迭代次数）以进行控制。

智能体可以处理复杂的任务，但其实现通常很直接。它们通常只是基于环境反馈在循环中使用工具的语言模型。因此，清晰且周全地设计工具集及其文档至关重要。我们在附录2（“为你的工具进行提示工程”）中详细阐述了工具开发的最佳实践。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&w=3840&q=75)

自主智能体

**何时使用智能体：** 智能体可用于开放式问题，这类问题难以或无法预测所需的步骤数，且无法硬编码固定路径。LLM 可能会运行多个回合，并且你必须对其决策有一定程度的信任。智能体的自主性使其非常适合在可信任的环境中扩展任务。

智能体的自主性意味着更高的成本，以及错误可能会不断累积。我们建议在沙盒环境中进行广泛测试，并设置适当的防护措施。

**智能体很有用的示例：**

以下示例来自我们自己的实现：

- 一个用于解决 [SWE-bench 任务](https://www.anthropic.com/research/swe-bench-sonnet) 的编码智能体，这些任务涉及根据任务描述对多个文件进行编辑；
- 我们的 [“计算机使用”参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) ，即 Claude 使用计算机来完成任务的情况。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&w=3840&q=75)

编码智能体的高级流程

## 组合并定制这些模式

这些构建模块并非规定性的。它们是常见的模式，开发人员可以对其进行塑造和组合，以适应不同的用例。与任何大语言模型（LLM）功能一样，成功的关键在于衡量性能并对实现方式进行迭代。再说一次：只有在能显著改善结果时，才应考虑增加复杂性。

## Summary

在大语言模型（LLM）领域取得成功，并非在于构建最复杂的系统。而是要构建一个符合你需求的 *正确* 系统。从简单的提示开始，通过全面评估进行优化，只有在更简单的解决方案无法满足需求时，才添加多步智能体系统。

在实现智能体时，我们尝试遵循三个核心原则：

1. 在智能体的设计中保持 **简洁性** 。
2. 通过明确展示智能体的规划步骤来优先考虑\*\*透明度\*\*。
3. 通过全面的工具 **文档记录和测试** 来精心设计你的智能体-计算机接口（ACI）。

框架可以帮助你快速上手，但在进入生产阶段时，不要犹豫减少抽象层并使用基本组件进行构建。遵循这些原则，你可以创建出不仅强大而且可靠、可维护且受用户信任的智能体。

### 致谢

作者：埃里克·施伦茨（Erik Schluntz）和巴里·张（Barry Zhang）。这项工作借鉴了我们在 Anthropic 构建智能体的经验以及客户分享的宝贵见解，对此我们深表感激。

我们与客户的合作揭示了人工智能智能体的两个特别有前景的应用，它们展示了上述模式的实际价值。这两个应用都说明了智能体如何为需要对话和行动、有明确成功标准、能实现反馈循环并融入有意义的人工监督的任务带来最大价值。

### A. 客户支持

客户支持通过工具集成将熟悉的聊天机器人界面与增强功能相结合。这对于更具开放性的智能体来说是很自然的契合，因为：

- 支持性交互自然地遵循对话流程，同时需要访问外部信息并执行操作；
- 可以集成工具来提取客户数据、订单历史记录和知识库文章；
- 诸如退款或更新票务等操作可以通过编程方式处理；并且
- 可以通过用户定义的分辨率清晰地衡量成功与否。

几家公司已经通过基于使用量的定价模式证明了这种方法的可行性，这种模式仅对成功解决的问题收费，显示出对其智能体有效性的信心。

### B. 编写代码智能体

软件开发领域已展现出 LLM 功能的巨大潜力，其能力从代码补全发展到自主解决问题。智能体尤其有效，原因如下：

- 代码解决方案可通过自动化测试进行验证
- 智能体可以利用测试结果作为反馈来迭代解决方案；
- 问题空间定义明确且结构清晰；并且
- 输出质量可以客观地衡量。

在我们自己的实现中，智能体现在仅根据拉取请求描述就能在 [SWE-bench 验证](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中解决实际的 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审核对于确保解决方案符合更广泛的系统要求仍然至关重要。

无论你构建的是哪种智能体系统，工具很可能都是你的智能体的重要组成部分。 [工具](https://www.anthropic.com/news/tool-use-ga) 使 Claude 能够通过在我们的 API 中指定其确切结构和定义来与外部服务和 API 进行交互。当 Claude 做出响应时，如果它计划调用工具，将会在 API 响应中包含一个 [工具使用块](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block) 。工具定义和规范应该像对待你的整体提示一样，给予提示工程同等的关注。在这个简短的附录中，我们将描述如何对工具进行提示工程。

通常有几种方法可以指定相同的操作。例如，你可以通过编写差异（diff）来指定文件编辑，也可以通过重写整个文件来指定。对于结构化输出，你可以在 Markdown 或 JSON 中返回代码。在软件工程中，像这样的差异只是表面的，可以无损地从一种格式转换为另一种格式。然而，某些格式对于 LLM 来说比其他格式更难编写。编写差异需要在编写新代码之前知道块头中有多少行在更改。在 JSON 中编写代码（与 Markdown 相比）需要对换行符和引号进行额外的转义。

我们关于确定工具格式的建议如下：

- 在模型把自己逼入绝境之前，给它足够的词元来“思考”。
- 保持格式与模型在互联网文本中自然出现的格式相近。
- 确保不存在格式“开销”，比如无需精确统计数千行代码，也无需对其编写的任何代码进行字符串转义。

一条经验法则是思考在人机界面（HCI）上投入了多少精力，并计划在创建良好的智能体-计算机界面（ACI）时投入同样多的精力。以下是关于如何做到这一点的一些想法：

- 设身处地从模型的角度想一想。根据描述和参数，使用这个工具的方法是否显而易见，还是你需要仔细思考一番？如果是后者，那么模型可能也会如此。一个好的工具定义通常包括示例用法、边界情况、输入格式要求，以及与其他工具的明确界限。
- 你如何更改参数名称或描述以使事情更清晰明了？可以把这想象成是为团队中的初级开发人员编写一个出色的文档字符串。在使用许多类似工具时，这一点尤为重要。
- 测试模型如何使用你的工具：在我们的 [工作台](https://console.anthropic.com/workbench) 中运行许多示例输入，以查看模型会犯哪些错误，然后进行迭代。
- 为你的工具设置防错机制。更改参数，使犯错变得更难。

在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建我们的智能体时，实际上我们在优化工具上花费的时间比优化整体提示更多。例如，我们发现当智能体移出根目录后，模型在使用相对文件路径的工具时会出错。为了解决这个问题，我们将工具改为始终要求使用绝对文件路径 —— 并且我们发现模型能够完美地使用这种方法。