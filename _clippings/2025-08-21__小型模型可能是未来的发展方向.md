---
title: 小型模型可能是未来的发展方向
source: https://www.tarat.space/writings/a-tiny-model
author: 
published: 2025-08-21
created: 2025-08-21
description: tarat's digital garden
tags:
---
小型模型可能是未来的发展方向

微调 Gemma 270M 使其表现得像个人教练

### The beginning

谷歌最近发布了 Gemma 模型家族的最新成员，一个参数仅有 2.7 亿的超小型模型。我最初的反应是，它太小了，没什么用。我非常怀疑。以至于我在推特上发了些调侃的内容。

![Image](https://www.tarat.space/assets/posts/tinymodel/x.png)

收到了一些回复，告诉我我错了。当你想在特定任务上微调模型时，这些模型相当有用。

但如你所知，我不会轻易相信在网上读到的所有东西。所以我决定对其进行微调，看看它是否真的有用，哈哈。

### 在什么上面对其进行微调？

然后我陷入了一个难题，就是要弄清楚用什么来对它进行微调。我的意思是，如果只是为了学习的目的，我可以从 Hugging Face 上获取任何现有的数据集，然后在上面进行微调。

公平地说，这甚至不会花费超过 10 分钟，因为 unsloth 在谷歌协作平台上提供了完整的流程来完成这件事。

但我想做一些个性化的东西。一些能让我对这些模型的可用性有信心的东西。于是我想了又想，想了好一会儿。

一些显而易见的选择有：

- 对其进行微调，使其表现得像一个个人智能体，然后将其与“Lumi”合并，赋予 Lumi 超能力。
- 对其进行微调，以便在“Lumi”中自动为我的笔记添加标签，使其更有用。
- 对其进行微调，使其表现得像一只“猫”，只说与猫相关的内容，等等。

**但我最喜欢的是对它进行微调，以便在 Strava 上吐槽我的跑步记录：）**

### The how?

说实话，这部分相当简单。

我首先下载了我在 Strava 上跑步的完整数据集。（谢天谢地，Strava 允许你这么做）

然后我用 Gemini 闪速功能来生成我跑步记录的总结。我特意让表述带有一点无礼和讽刺的意味。这样模型就能调侃我了。

经过这两个步骤，我得到了一个包含200多次运行的数据集，如下所示：

```javascript
{
"input": 
    {
        "date": "2024-01-07", 
        "activity": "Run", 
        "distance_km": 3.08, 
        "pace": "5:54/km", 
        "elevation_gain_m": 4, 
        "recent_runs": 
            [
                {"distance_km": 3.06, "pace": "6:14/km"},
                {"distance_km": 3.04, "pace": "6:01/km"}
            ]
    },
"output": 
    {
        "summary": 
            "Another short 3km run completed. 
            The pace shows minor improvement, but remains uninspiring.", 
        "reflection": 
            "You've barely managed to shave off a few seconds per kilometer from previous slow efforts. 
            This is not progress; this is just proving you can run 3km at a mediocre pace. 
            Focus on real speed."
    }
}
```

然后我在谷歌 Colab 上使用 unsloth 在这个数据集上微调模型。完成整个过程只花了大概 5 分钟。非常感谢 ChatGPT 帮助我找出合适的 LoRA 集合并对模型进行微调。

以下是用于微调模型的定制代码。

```python
trainer = SFTTrainer(
    model = model,
    tokenizer = tokenizer,
    train_dataset = dataset,
    eval_dataset = None, # Can set up evaluation!
    args = SFTConfig(
        dataset_text_field = "text",
        per_device_train_batch_size = 8,
        gradient_accumulation_steps = 1, # Use GA to mimic batch size!
        warmup_steps = 5,
        num_train_epochs = 5, # Set this for 1 full training run.
        learning_rate = 2e-5, # Reduce to 2e-5 for long training runs
        logging_steps = 1,
        optim = "adamw_8bit",
        weight_decay = 0.01,
        lr_scheduler_type = "linear",
        seed = 3407,
        output_dir="outputs",
        report_to = "none", # Use this for WandB etc
    ),
)
```

完成后，就该进行测试了。以下是一个示例响应：

```javascript
{
    "summary": "You ran 5.29 km at an 18:22 pace, which is acceptable, 
                but your pace was so slow you were unimportable.", 
    "reflection": "This pace is a tad slow for your form today. You need to work on your form."
}
```

![Image](https://www.tarat.space/assets/posts/tinymodel/response.png)

对于一个我可以在手机上本地运行的模型来说还不错吧？这做起来如此快速又简单，以至于我在想，我是否应该针对我的每个个人用例微调这个模型的一个版本，并创建一批 Gemma 模型，以便在我需要时能在我的手机上本地运行。

对不起，谷歌。我之前不熟悉你的游戏。希望这篇文章能有所弥补。

附言：如果你想自己尝试一下，这是谷歌科拉布的 [链接](https://colab.research.google.com/drive/1pwAkDF5Q5J9EVt01GUMrqS0DhI_dqn0V?usp=sharing) 。