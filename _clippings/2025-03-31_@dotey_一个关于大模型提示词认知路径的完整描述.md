---
title: "一个关于大模型提示词认知路径的完整描述"
source: "https://x.com/dotey/status/1906193740588367938"
author:
  - "[[@dotey]]"
created: 2025-03-31
description: "“一个完全的提示词新手可能要经历的提示词认知路径: 从清晰表达认识到结构化表达的“高效性”熟练掌握结构化表达后，再次回到简洁的表达。 详细来说: 一个新手可能最初会把大模型当做“搜索引擎”或者“问答机器人”，询问的问题过于简单和具体，大模型并不能发挥它带给用户超预期回答的能力。"
tags:
  - "@dotey"
---
**宝玉** @dotey 2025-03-30

“一个完全的提示词新手可能要经历的提示词认知路径:

从清晰表达认识到结构化表达的“高效性”熟练掌握结构化表达后，再次回到简洁的表达。

详细来说:

一个新手可能最初会把大模型当做“搜索引擎”或者“问答机器人”，询问的问题过于简单和具体，大模型并不能发挥它带给用户超预期回答的能力。

经历一个阶段关于“清晰表达、充分提供背景信息、提供示例”的学习之后，提示词学习者学会了结构化表达，此时可能陷入过度结构化或者把提示词看做某种标准框架的阶段，例如各类结构化提示词模板。

再经过这个阶段之后，学习者会慢慢领悟到如何“压缩”用清晰简洁的表达直接描述需求(但这是建立在对大模型能力的信任和原理的了解之上的)

初始简洁是因为不知道如何表达

高阶简洁是因为知道什么不需要表达

初始简洁缺乏关键信息，高阶简洁保留了所有必要信息高阶简洁建立在对AI能力边界的理解上，知道什么可以省略，什么必须说明”

—— by 小七姐

> 2025-03-30
> 
> 在和团队分享 AI 工具后，我发现在后续的具体使用上，产生了两种分化：
> 
> 1.一部分人，问AI的问题，prompt，极其简单，懒得多输入一个字，比如：
> 
> “写一个什么文档”
> 
> “分析一下什么问题”
> 
> 然后当AI回答的内容，和预期的内容，不完全匹配时，就说，AI不好用，AI也就这样，不太行啊，然后使用频率越来越低。
> 
> ![Image](https://pbs.twimg.com/media/GnQozRNXoAEtRrW?format=jpg&name=large) ![Image](https://pbs.twimg.com/media/GnQeEqtaMAAqXYJ?format=jpg&name=large)

---

**Robinson · 鲁棒逊** @python\_xxt [2025-03-30](https://x.com/python_xxt/status/1906200665241653545)

我又学到了，感谢宝玉

---

**宝玉** @dotey [2025-03-30](https://x.com/dotey/status/1906201304344502444)

我只是转发小七姐的

---

**Robinson · 鲁棒逊** @python\_xxt [2025-03-30](https://x.com/python_xxt/status/1906203294718132428)

依然感谢，是你的筛选＆分享，让信息得以流动，让我得到了价值

筛选和分享，可能是未来，最大的价值

---

**Jason Young** @Jason\_Young1231 [2025-03-30](https://x.com/Jason_Young1231/status/1906205689959366793)

学习提示词的过程可以重塑一个人的表达能力

---

**冷面一碗** @jatdipcoengfan [2025-03-30](https://x.com/jatdipcoengfan/status/1906292924683333847)

如果已经有相对清晰的想法，只是懒得组织成结构化的提示词，最近我的一个方法还挺好用的，就是用chatgpt的语音输入模式（不是语音模式）先把提示通过口述输入进来，让模型输出一个清晰的提示词，再进行输入。

至少自己的体验来讲，ChatGPT的语音识别率非常高。

---

**gm365** @gm365 [2025-03-30](https://x.com/gm365/status/1906202460701774175)

见山三阶段，异曲同工之妙。

初期的简单，和最终的简洁看似相似，其实还是有很大不同的。

简洁，却直达本质，一针见血

---

**Jason Chao @Think.As.Model** @qianli [2025-03-30](https://x.com/qianli/status/1906209085315555751)

这也是李继刚所一直倡导和追求的吧，不过，有一点我没想明白，看过一些大模型或AI产品的系统提示词，比如Claude，都相当复杂，似乎并不符合简洁直接的原则

---

**宝玉** @dotey [2025-03-30](https://x.com/dotey/status/1906209799022289371)

应用场景不一样，它们需要考虑很多不同的情况

---

**加密要饭人** @zhang\_baoqing [2025-03-30](https://x.com/zhang_baoqing/status/1906214975137357856)

用的啥截图软件

---

**纤云水谣** @junzilan1204 [2025-03-30](https://x.com/junzilan1204/status/1906220026023022624)

每次來都能學到新知識，很有收獲

---

**一箱抽纸** @orangeburncgw [2025-03-30](https://x.com/orangeburncgw/status/1906233251624026170)

其实不用那么麻烦，把9年义务教育的语文书重新拿出来复习，重新学会如何写议论文就好了

---

**@ASI\_超智量子模型之父** @j8inhell [2025-03-30](https://x.com/j8inhell/status/1906292479923495076)

Ai對於人來講已經沒有邊界，ai的槓桿率取決於個體的認知邊界。

---

**G.G. W.** @wgx\_dev [2025-03-30](https://x.com/wgx_dev/status/1906297051735789986)

那么应该如何表达呢？

---

**贱贱 dream-seeker** @dreamseeker6666 [2025-03-30](https://x.com/dreamseeker6666/status/1906308047112474770)

还有个维度，觉醒，人类分不出ai是程序是机器人……就语言来说，过往的测试，已经没用……

---

**坂本龍馬** @uKojM8ohdy4xy5j [2025-03-30](https://x.com/uKojM8ohdy4xy5j/status/1906376999645634619)

人类的知识来自于与世界的接触，类似婴儿。所以提示词再好不能与实际场景做连接而产出可迭代的效果，不如不研究。

---

**vewin** @lawgpts [2025-03-30](https://x.com/lawgpts/status/1906386111301292098)

我反对李玉刚那种 lisp 编程方式的提示词编写方式。那是违背人类自然语言表达的方式。提示词应该能够泛化表达

---

**lianm** @lukewarmzen [2025-03-30](https://x.com/lukewarmzen/status/1906446883939086685)

有实际的例子吗