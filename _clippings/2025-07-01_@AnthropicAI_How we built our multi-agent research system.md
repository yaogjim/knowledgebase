---
title: "How we built our multi-agent research system"
source: "https://www.anthropic.com/engineering/built-multi-agent-research-system"
author:
  - "[[@AnthropicAI]]"
published:
created: 2025-07-01
description: "On the the engineering challenges and lessons learned from building Claude's Research system"
tags:
  - "clippings"
---
[Anthropic 公司的工程团队](https://www.anthropic.com/engineering) ![](https://www-cdn.anthropic.com/images/4zrzovbb/website/094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000.svg)

## 我们如何构建多智能体研究系统

Claude 现在具备了研究能力，使其能够在网络、谷歌工作区以及任何集成应用中进行搜索，以完成复杂任务。

这个多智能体系统从原型到生产的历程，让我们在系统架构、工具设计和提示工程方面学到了至关重要的经验教训。多智能体系统由多个智能体（LLMs 在循环中自主使用工具）协同工作组成。我们的研究功能涉及一个智能体，它根据用户查询规划研究过程，然后使用工具创建并行智能体以同时搜索信息。具有多个智能体的系统在智能体协调、评估和可靠性方面带来了新的挑战。

本文详细介绍了对我们有效的原则，希望你在构建自己的多智能体系统时能发现它们很有用。

### 多智能体系统的优势

研究工作涉及开放性问题，很难预先预测所需的步骤。你无法为探索复杂主题硬编码一条固定路径，因为这个过程本质上是动态的且依赖于路径。当人们进行研究时，他们倾向于根据发现不断更新方法，顺着调查过程中出现的线索展开研究。

这种不可预测性使得人工智能智能体特别适合研究任务。研究需要在调查展开过程中灵活转向或探索相关联系。模型必须自主运行多个回合，根据中间结果决定要探索哪些方向。线性的一次性流程无法处理这些任务。

搜索的本质在于压缩：从海量语料库中提炼见解。子智能体通过在其自身的上下文窗口中并行操作来促进压缩，在为牵头研究智能体浓缩最重要的标记之前，同时探索问题的不同方面。每个子智能体还实现了关注点分离——不同的工具、提示和探索轨迹——这减少了路径依赖，并能够进行全面、独立的调查。

一旦智能达到某个阈值，多智能体系统就会成为提升性能的关键途径。例如，尽管在过去十万年里个体人类变得更加智能，但由于我们的集体智慧和协调能力，人类社会在信息时代的能力呈指数级增长。即使是一般智能的智能体，作为个体运行时也会面临局限；而智能体群体能够完成的任务要多得多。

我们的内部评估表明，多智能体研究系统在涉及同时探索多个独立方向的广度优先查询方面表现尤为出色。我们发现，以 Claude Opus 4 为主智能体、Claude Sonnet 4 为子智能体的多智能体系统在我们的内部研究评估中比单智能体 Claude Opus 4 的表现高出 90.2%。例如，当被要求识别标准普尔 500 信息技术指数成份股公司的所有董事会成员时，多智能体系统通过将此任务分解给子智能体找到了正确答案，而单智能体系统通过缓慢的顺序搜索未能找到答案。

多智能体系统之所以能发挥作用，主要是因为它们有助于花费足够的令牌来解决问题。在我们的分析中，三个因素解释了 [BrowseComp](https://openai.com/index/browsecomp/) 评估中 95%的性能差异（该评估测试浏览智能体定位难以找到的信息的能力）。我们发现，仅令牌使用就解释了 80%的差异，工具调用次数和模型选择是另外两个解释因素。这一发现验证了我们的架构，即通过具有单独上下文窗口的智能体来分配工作，以增加并行推理的能力。最新的 Claude 模型在令牌使用上起到了巨大的效率乘数作用，因为升级到 Claude Sonnet 4 带来的性能提升比将 Claude Sonnet 3.7 的令牌预算翻倍还要大。多智能体架构有效地扩展了令牌使用，以处理超出单个智能体限制的任务。

存在一个缺点：在实际应用中，这些架构消耗令牌的速度很快。在我们的数据中，智能体通常比聊天交互多使用约 4 倍的令牌，而多智能体系统比聊天多使用约 15 倍的令牌。为了实现经济可行性，多智能体系统需要任务的价值足够高，以支付性能提升带来的成本。此外，一些要求所有智能体共享相同上下文或涉及智能体之间许多依赖关系的领域，目前并不适合多智能体系统。例如，大多数编码任务中真正可并行化的任务比研究任务少，并且 LLM 智能体在实时协调和委托给其他智能体方面还不够出色。我们发现，多智能体系统在涉及大量并行化、超出单个上下文窗口的信息以及与众多复杂工具交互的有价值任务中表现出色。

### 研究架构概述

我们的研究系统采用了一种具有协调器-工作器模式的多智能体架构，其中一个主导智能体协调流程，同时将任务委托给并行运行的专门子智能体。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png&w=3840&q=75)

运行中的多智能体架构：用户查询流经一个主导智能体，该智能体创建专门的子智能体以并行搜索不同方面。

当用户提交查询时，主导智能体对其进行分析，制定策略，并生成子智能体以同时探索不同方面。如上图所示，子智能体通过迭代使用搜索工具来收集信息（在这种情况下是关于2025年的人工智能智能体公司），从而充当智能过滤器，然后将公司列表返回给主导智能体，以便它能汇编出最终答案。

使用检索增强生成（RAG）的传统方法采用静态检索。也就是说，它们获取与输入查询最相似的一些文本块集，并使用这些文本块来生成响应。相比之下，我们的架构使用多步搜索，动态地找到相关信息，适应新发现，并分析结果以形成高质量的答案。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png&w=3840&q=75)

展示我们多智能体研究系统完整工作流程的流程图。当用户提交查询时，系统会创建一个首席研究员智能体，该智能体进入迭代研究过程。首席研究员首先思考研究方法，并将其计划保存到内存中以保留上下文，因为如果上下文窗口超过 200,000 个标记，它将被截断，保留计划很重要。然后，它会创建具有特定研究任务的专门子智能体（此处显示了两个，但可以是任意数量）。每个子智能体独立进行网络搜索，使用 交错思考 评估工具结果，并将发现返回给首席研究员。首席研究员综合这些结果，决定是否需要更多研究——如果是，它可以创建更多子智能体或完善其策略。一旦收集到足够的信息，系统就会退出研究循环，并将所有发现传递给一个引用智能体，该智能体处理文档和研究报告，以确定引用的具体位置。这确保了所有主张都能正确归因于其来源。 然后，带有引用的最终研究结果会返回给用户。

### 用于研究智能体的提示工程与评估

多智能体系统与单智能体系统有显著差异，其中包括协调复杂性的迅速增长。早期的智能体出现了一些错误，比如针对简单查询生成50个子智能体、无休止地在网络上搜索不存在的来源，以及用过多的更新相互干扰。由于每个智能体都由一个提示引导，提示工程是我们改进这些行为的主要手段。以下是我们在提示智能体方面学到的一些原则：

1. **像你的智能体一样思考。** 要迭代提示词，你必须了解它们的效果。为了帮助我们做到这一点，我们使用我们的 [控制台](https://console.anthropic.com/) ，用我们系统中完全相同的提示词和工具构建了模拟，然后一步一步地观察智能体的工作。这立即揭示了失败模式：智能体在已经有足够结果时仍继续，使用过于冗长的搜索查询，或选择错误的工具。有效的提示词依赖于建立一个准确的智能体思维模型，这可以使最有影响力的变化变得显而易见。
2. **教会协调器如何进行任务分配。** 在我们的系统中，主导智能体将查询分解为子任务，并向子智能体进行描述。每个子智能体都需要一个目标、一种输出格式、关于所使用工具和信息来源的指导，以及明确的任务边界。如果没有详细的任务描述，智能体就会重复工作、留下空白，或者无法找到必要的信息。我们一开始允许主导智能体给出简单简短的指令，比如“研究半导体短缺问题”，但发现这些指令往往不够明确，以至于子智能体误解任务，或者与其他智能体进行完全相同的搜索。例如，一个子智能体研究了 2021 年的汽车芯片危机，而另外两个则重复工作，调查 2025 年当前的供应链，没有进行有效的分工。
3. **根据查询复杂度调整工作量。** 智能体难以判断不同任务所需的适当工作量，因此我们在提示中嵌入了调整规则。简单的事实查找仅需 1 个智能体进行 3 至 10 次工具调用，直接比较可能需要 2 至 4 个子智能体，每个子智能体进行 10 至 15 次调用，而复杂的研究可能会使用 10 多个职责明确的子智能体。这些明确的指导方针有助于主导智能体有效地分配资源，并防止在简单查询上过度投入，这是我们早期版本中常见的失败模式。
4. **工具设计与选择至关重要。** 智能体与工具的接口和人机接口一样关键。使用正确的工具效率更高——通常，这是绝对必要的。例如，一个在网络上搜索仅存在于 Slack 中的上下文的智能体从一开始就注定要失败。通过让模型能够访问外部工具的 [MCP 服务器](https://modelcontextprotocol.io/introduction) ，这个问题变得更加复杂，因为智能体会遇到描述质量差异极大的未知工具。我们为智能体提供了明确的启发式方法：例如，先检查所有可用工具，使工具使用与用户意图相匹配，在网络上进行广泛的外部探索，或者优先选择专用工具而非通用工具。糟糕的工具描述可能会让智能体走上完全错误的道路，因此每个工具都需要有明确的用途和清晰的描述。
5. **让智能体自我改进** 。我们发现 Claude 4 模型可以成为出色的提示工程师。当给出一个提示和一种失败模式时，它们能够诊断出智能体失败的原因并提出改进建议。我们甚至创建了一个工具测试智能体——当给它一个有缺陷的 MCP 工具时，它会尝试使用该工具，然后重写工具描述以避免失败。通过对该工具进行数十次测试，这个智能体发现了关键的细微差别和漏洞。这种改进工具易用性的过程使得未来使用新描述的智能体任务完成时间减少了 40%，因为它们能够避免大多数错误。
6. **先宽泛搜索，再逐步细化。** 搜索策略应效仿专业的人类研究方式：在深入研究具体细节之前先全面探索。智能体常常默认使用过长、过于具体的查询，结果返回的内容很少。我们通过提示智能体从简短、宽泛的查询开始，评估可得信息，然后逐步缩小关注点来应对这种倾向。
7. **引导思维过程。** [扩展思维模式](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking) 可使 Claude 在可见的思维过程中输出更多标记，它可以充当一个可控的草稿区。主导智能体通过思考来规划其方法，评估哪些工具适合该任务，确定查询复杂度和子智能体数量，并定义每个子智能体的角色。我们的测试表明，扩展思维提高了指令遵循、推理和效率。子智能体也会进行规划，然后在获得工具结果后使用 [交错思维](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking) 来评估质量、识别差距并完善其下一个查询。这使得子智能体在适应任何任务时更有效。
8. **并行工具调用提升速度和性能。** 复杂的研究任务自然涉及探索多个来源。我们早期的智能体执行顺序搜索，速度极其缓慢。为了提高速度，我们引入了两种并行化方式：(1) 主导智能体并行启动 3 - 5 个子智能体，而非串行启动；(2) 子智能体并行使用 3 个以上工具。这些改变将复杂查询的研究时间缩短了多达 90%，使研究团队能够在几分钟内完成原本需要数小时的工作，同时涵盖比其他系统更多的信息。

我们的提示策略侧重于灌输良好的启发式方法，而非严格的规则。我们研究了熟练的人类如何处理研究任务，并将这些策略编码到我们的提示中，比如将难题分解为更小的任务、仔细评估信息来源的质量、根据新信息调整搜索方法，以及识别何时应专注于深度（详细研究一个主题）与广度（并行探索多个主题）。我们还通过设置明确的防护栏来主动减轻意外的副作用，以防止智能体失控。最后，我们专注于一个具有可观测性和测试用例的快速迭代循环。

### 智能体的有效评估

良好的评估对于构建可靠的人工智能应用至关重要，智能体也不例外。然而，评估多智能体系统存在独特的挑战。传统评估通常假设人工智能每次都遵循相同的步骤：给定输入 X，系统应遵循路径 Y 以产生输出 Z。但多智能体系统并非如此运作。即使起点相同，智能体也可能采取完全不同的有效路径来实现其目标。一个智能体可能搜索三个来源，而另一个可能搜索十个，或者它们可能使用不同的工具来找到相同的答案。由于我们并不总是知道正确的步骤是什么，我们通常不能仅仅检查智能体是否遵循了我们预先规定的“正确”步骤。相反，我们需要灵活的评估方法，来判断智能体是否在遵循合理过程的同时实现了正确的结果。

**立即使用小样本开始评估** 。在早期的智能体开发中，由于有大量容易解决的问题，更改往往会产生巨大影响。一个提示调整可能会将成功率从 30%提高到 80%。对于如此大的效应量，只需几个测试用例就能发现变化。我们从一组约 20 个代表实际使用模式的查询开始。测试这些查询通常能让我们清楚地看到更改的影响。我们经常听说人工智能开发团队推迟创建评估，因为他们认为只有包含数百个测试用例的大型评估才有用。然而，最好立即用几个示例开始小规模测试，而不是推迟到能够构建更全面的评估时。

**当执行良好时，基于大语言模型（LLM）的评判评估尺度。** 研究成果很难通过编程方式进行评估，因为它们是自由形式的文本，而且很少有唯一正确答案。大语言模型非常适合对成果进行评分。我们使用了一个大语言模型评判器，它根据一份评分标准中的标准来评估每个成果：事实准确性（主张是否与来源相符？）、引用准确性（引用的来源是否与主张相符？）、完整性（是否涵盖了所有要求的方面？）、来源质量（是否使用了原始资料而非质量较低的二手资料？）以及工具效率（是否合理次数地使用了正确工具？）。我们尝试使用多个评判器来评估每个组件，但发现使用单个提示进行一次大语言模型调用，输出 0.0 至 1.0 的分数以及通过/未通过等级，是最一致且与人类判断相符的。当评估测试用例 *确实* 有明确答案时，这种方法特别有效，我们可以使用大语言模型评判器来简单检查答案是否正确（即它是否准确列出了研发预算排名前三的制药公司？） 使用一个语言模型（LLM）作为评判器使我们能够可扩展地评估数百个输出结果。

**人工评估能发现自动化评估遗漏的问题。** 测试智能体的人员能找到评估未能发现的边缘情况。这些情况包括对不寻常查询的幻觉答案、系统故障或细微的来源选择偏差。就我们的情况而言，人工测试人员注意到我们早期的智能体始终选择经过 SEO 优化的内容农场，而不是像学术 PDF 或个人博客这样权威但排名较低的来源。在我们的提示中添加源质量启发式方法有助于解决这个问题。即使在自动化评估的世界中，手动测试仍然至关重要。

多智能体系统具有涌现行为，这些行为无需特定编程即可出现。例如，对主导智能体的微小更改可能会不可预测地改变子智能体的行为方式。成功需要理解交互模式，而不仅仅是单个智能体的行为。因此，针对这些智能体的最佳提示不仅仅是严格的指令，而是定义了分工、问题解决方法和工作量预算的协作框架。要做到这一点，需要精心的提示和工具设计、可靠的启发式方法、可观测性以及紧密的反馈循环。有关我们系统的示例提示，请参阅 [我们的 Cookbook 中的开源提示](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts) 。

### 生产可靠性与工程挑战

在传统软件中，一个漏洞可能会破坏某项功能、降低性能或导致系统中断。在智能体系统中，微小的变化会引发巨大的行为变化，这使得为在长时间运行过程中必须维护状态的复杂智能体编写代码变得极其困难。

**智能体是有状态的，错误会不断累积。** 智能体可以长时间运行，在多次工具调用中保持状态。这意味着我们需要持久地执行代码并在这个过程中处理错误。如果没有有效的缓解措施，轻微的系统故障对智能体来说可能是灾难性的。当错误发生时，我们不能简单地从头开始重启：重启对用户来说成本高昂且令人沮丧。相反，我们构建了能够从错误发生时智能体所在的位置恢复运行的系统。我们还利用模型的智能来优雅地处理问题：例如，当某个工具出现故障时告知智能体并让它进行调整，效果出奇地好。我们将基于 Claude 构建的人工智能智能体的适应性与诸如重试逻辑和定期检查点等确定性保障措施相结合。

**新方法有助于调试。** 智能体做出动态决策，即使提示相同，每次运行之间也具有不确定性。这使得调试变得更加困难。例如，用户会报告智能体“找不到明显的信息”，但我们不清楚原因。是智能体使用了错误的搜索查询？选择了不佳的信息源？还是遇到了工具故障？添加完整的生产跟踪使我们能够诊断智能体失败的原因，并系统地修复问题。除了标准的可观测性之外，我们还监控智能体的决策模式和交互结构——所有这些都不会监控单个对话的内容，以保护用户隐私。这种高层次的可观测性帮助我们诊断根本原因、发现意外行为并修复常见故障。

**部署需要仔细协调。** 智能体系统是由提示、工具和执行逻辑构成的高度有状态的网络，几乎持续运行。这意味着每当我们部署更新时，智能体可能处于其运行过程中的任何位置。因此，我们需要防止善意的代码更改破坏现有智能体。我们不能同时将每个智能体更新到新版本。相反，我们使用 [彩虹部署](https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/) 来避免干扰正在运行的智能体，方法是在保持新旧版本同时运行的情况下，逐渐将流量从旧版本转移到新版本。

**同步执行会造成瓶颈。** 目前，我们的主导智能体同步执行子智能体，等待每组子智能体完成后再继续。这简化了协调工作，但在智能体之间的信息流中造成了瓶颈。例如，主导智能体无法引导子智能体，子智能体无法协调，并且在等待单个子智能体完成搜索时，整个系统可能会被阻塞。异步执行将实现更多的并行性：智能体可以并发工作，并在需要时创建新的子智能体。但这种异步性在结果协调、状态一致性以及跨子智能体的错误传播方面增加了挑战。随着模型能够处理更长、更复杂的研究任务，我们预计性能提升将证明这种复杂性是合理的。

### 结论

在构建人工智能智能体时，最后一公里往往占据了大部分旅程。在开发者机器上运行的代码库需要大量工程工作才能成为可靠的生产系统。智能体系统中错误的复合性质意味着传统软件中的小问题可能会使智能体完全脱轨。一步出错可能会导致智能体探索完全不同的轨迹，从而产生不可预测的结果。出于本文所述的所有原因，原型与生产之间的差距往往比预期的要大。

尽管存在这些挑战，但多智能体系统已被证明在开放式研究任务中很有价值。用户表示，Claude 帮助他们发现了未曾考虑过的商业机会，梳理复杂的医疗保健选项，解决棘手的技术故障，并且通过揭示他们自己无法独自发现的研究联系，节省了多达数天的工作时间。通过精心设计、全面测试、注重细节的提示和工具设计、稳健的运营实践，以及研究、产品和工程团队之间紧密协作（这些团队对当前智能体能力有深入理解），多智能体研究系统能够在大规模情况下可靠运行。我们已经看到这些系统正在改变人们解决复杂问题的方式。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png&w=3840&q=75)

一张关于 Clio 的嵌入图，展示了当下人们使用研究功能的最常见方式。主要用例类别包括跨专业领域开发软件系统（10%）、开发和优化专业及技术内容（8%）、制定业务增长和创收策略（8%）、协助学术研究和教育材料开发（7%）以及研究和核实有关个人、地点或组织的信息（5%）。

### 致谢

作者：杰里米·哈德菲尔德、巴里·张、肯尼斯·连、弗洛里安·朔尔茨、杰里米·福克斯和丹尼尔·福特。这项工作体现了 Anthropic 多个团队的共同努力，是他们让研究功能成为可能。特别感谢 Anthropic 应用工程团队，他们的奉献使这个复杂的多智能体系统得以投入生产。我们也感谢早期用户提供的出色反馈。

## 附录

以下是关于多智能体系统的一些其他杂项提示。

**对在多轮中改变状态的智能体的终态评估。** 评估在多轮对话中修改持久状态的智能体带来了独特的挑战。与只读研究任务不同，每个动作都会改变后续步骤的环境，从而产生传统评估方法难以处理的依赖关系。我们发现专注于终态评估而非逐轮分析很有成效。与其判断智能体是否遵循了特定过程，不如评估它是否达到了正确的最终状态。这种方法认识到智能体可能会找到通往同一目标的替代路径，同时仍确保它们能产生预期的结果。对于复杂的工作流程，将评估分解为离散的检查点，在这些检查点应该发生特定的状态变化，而不是试图验证每一个中间步骤。

**长期对话管理。** 生产代理常常会参与长达数百轮的对话，这就需要精心的上下文管理策略。随着对话的延续，标准的上下文窗口会变得不够用，因此需要智能压缩和记忆机制。我们实施了一些模式，即代理在进入新任务之前总结已完成的工作阶段，并将重要信息存储到外部记忆中。当接近上下文限制时，代理可以生成具有干净上下文的新子代理，同时通过精心的交接保持连续性。此外，它们可以从记忆中检索存储的上下文，比如研究计划，而不是在达到上下文限制时丢失之前的工作。这种分布式方法可防止上下文溢出，同时在长时间的交互中保持对话的连贯性。

**子代理输出到文件系统以尽量减少“传话游戏”。** 对于某些类型的结果，直接的子代理输出可以绕过主协调器，从而提高保真度和性能。与其要求子代理通过主导代理传达所有信息，不如实现工件系统，让专门的代理可以创建独立持久化的输出。子代理调用工具将其工作存储在外部系统中，然后将轻量级引用传递回协调器。这可以防止在多阶段处理过程中信息丢失，并减少通过对话历史复制大型输出所产生的令牌开销。这种模式对于结构化输出（如代码、报告或数据可视化）特别有效，在这些情况下，子代理的专门提示比通过通用协调器进行过滤能产生更好的结果。