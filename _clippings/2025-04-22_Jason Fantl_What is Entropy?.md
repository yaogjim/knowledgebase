---
title: "What is Entropy?"
source: "https://jasonfantl.com/posts/What-is-Entropy/"
author:
  - "[[Jason Fantl]]"
published: 2025-03-21
created: 2025-04-22
description: "People say many things about entropy: entropy increases with time, entropy is disorder, entropy increases with energy, entropy determines the arrow of time, etc.. But I have no idea what entropy is, and from what I find, neither do most other people. This is the introduction I wish I had when first told about entropy, so hopefully you find it helpful. My goal is that by the end of this long post we will have a rigorous and intuitive understanding of those statements, and in particular, why the universe looks different when moving forward through time versus when traveling backward through time."
tags:
  - "clippings"
---
人们对熵有很多说法：熵随时间增加，熵是无序，熵随能量增加，熵决定时间之箭等等。但我不知道熵是什么，而且据我所知，大多数其他人也不知道。这就是我希望在第一次被告知熵的时候就有的介绍，所以希望你觉得它有帮助。我的目标是，在这篇长文结束时，我们能对这些说法有一个严谨且直观的理解，特别是，为什么宇宙在时间向前推进时与时间向后推移时看起来不一样。

这段旅程始于对熵的定义和理解。在多个学科领域——热力学、统计力学、信息论——中都有熵的多种形式定义，但它们都有一个核心思想：熵量化不确定性。对熵最简单的介绍是通过信息论，这将引出物理系统中的熵，最终引出熵与时间之间的关系。

## 信息论

想象一下，你想向你的朋友传达一些随机事件的结果，比如掷骰子的结果或彩票中奖者，但你想用尽可能少的比特（只有 1 和 0）来做到这一点。你可以使用多少个比特呢？

信息论的创始人克劳德·香农在贝尔实验室工作期间一直在试图回答诸如此类的问题。他当时正在发展通信和压缩的数学基础，最终他发现一条消息所需的最小比特数与该消息的不确定性直接相关。然后他得以推导出一个方程来量化一条消息的不确定性。当他与贝尔实验室的物理学家同事约翰·冯·诺伊曼分享这个方程时，冯·诺伊曼出于两个原因建议将其称为熵：

> 香农报告称，冯·诺伊曼提出，将该函数称为“熵”有两个很好的理由。“这个名字已经在使用了，”据说他这样说道，“此外，这会让你在辩论中占据很大优势，因为反正没人真正知道熵是什么。”香农将该函数称为“熵”，并将其用作“不确定性”的度量，在他的著作中不加区分地互换这两个词。  
> —— 哈罗德·A·约翰逊（编），《传热、热力学与教育：博尔特周年纪念文集》（纽约：麦格劳 - 希尔出版公司，1964 年），第 354 页。

稍后我们将看到，香农熵与先前存在的熵的定义之间的关系并非巧合，它们紧密相连。

但现在让我们看看香农是如何为这些通常模糊的“信息”和“不确定性”术语找到定义的。

在信息论中，观测状态的信息被正式定义为传达该状态所需的比特数（至少对于具有等概率结果且为 2 的幂的系统而言，我们很快就会看到如何对此进行推广）。以下是一些信息的示例：

- 如果我抛一枚均匀硬币，要告诉你结果需要一位信息：我用 `0` 表示正面，用 `1` 表示反面。
- 如果我掷一个公平的八面骰子，我可以用 3 位来表示结果：我用 `000` 表示 1， `001` 表示 2， `010` 表示 3，依此类推。

一个系统可能产生的结果越多，就需要越多的比特（信息）来表示其结果。如果一个系统有 $N$ 个等概率的结果，那么表示该系统的一个结果将需要 $log2(N)$ 比特的信息。

熵被定义为表示系统状态所需的信息比特数的期望值（这是个谎言，但目前这是最有用的定义，我们稍后会修正它）。所以一枚硬币的熵是 1，因为平均而言，我们预计需要 1 比特信息来表示硬币的结果。一个八面骰子的熵将是 3 比特，因为我们预计平均需要 3 比特来表示结果。

最初看来，熵似乎是一个不必要的定义，因为我们可以只看表示系统结果需要多少位，并使用该值，但这仅在所有结果的概率都相等时才成立。

现在想象一下，我有一个加权八面骰子，数字 7 出现的概率为 $50$ %，而其他面出现的概率为 $≈7.14$ %。现在，如果我们够聪明，就可以减少传达骰子结果所需的期望比特数。我们可以决定用 `0` 来表示 7，而其他所有数字将用 `1XXX` 表示，其中 `X` 是一些独特的比特。这意味着 $50$ %的情况下我们只需要用 1 比特信息来表示结果，而其他 $50$ %的情况下我们用 4 比特，所以期望比特数（骰子的熵）是 2.5。这比公平八面骰子的 3 比特熵要低。

幸运的是，我们无需为每个可能的系统想出巧妙的编码方案，对于用概率 $p$ 表示一种状态需要多少位信息，存在一种模式。我们知道，如果 $p=0.5$ ，比如硬币正面朝上的情况，那么表示该结果需要 1 位信息。如果 $p=0.125$ ，比如公平的八面骰子掷出数字 5 的情况，那么表示该结果需要 3 位信息。如果 $p=0.5$ ，比如我们的不公平八面骰子掷出数字 7 的情况，那么和硬币一样，表示该结果需要 1 位信息，这表明重要的只是结果的概率。由此，我们可以推导出一个关于概率为 $p$ 的状态所需信息位数的方程。

$$
I(p)=−log2(p)
$$

此值 $I$ 通常称为信息内容或意外程度，因为状态发生的概率越低，当它实际发生时意外程度就越高。

当概率较低时，惊喜度较高；而当概率较高时，惊喜度较低。这是一个比“所需比特数”更通用的公式，因为它允许存在极有可能出现的状态（例如 $99$ % 的可能性），其惊喜度小于 1，如果我们试图将该值解释为“表示结果所需的比特数”，这就不太说得通了。

现在我们可以修正我们对熵的定义（我之前撒的谎）。熵不一定是用于表示一个系统的预期比特数（尽管当你使用最优编码方案时它是），但更一般地说，熵是系统的预期惊奇度。

现在我们可以计算像骰子、硬币或任何其结果具有已知概率的系统的熵。一个具有 $N$ 种可能结果且每种结果的概率为 $pi$ （所有概率之和为 1）的系统的预期惊喜度（熵）可以计算为

$$
(Shannon entropy)∑i=1Npi⋅I(pi)=−∑i=1Npi⋅log2(pi)
$$

并且注意到，如果所有的 $N$ 概率都相同（即 $pi=1N$ ），那么熵方程可以简化为

$$
−∑i=1Npi⋅log2(pi)⇒log2(N)
$$

以下是一些使用 $(Shannon entropy)$ 的基本示例。

- 公平硬币的熵为
$$
−(0.5⋅log2(0.5)+0.5⋅log2(0.5))=log2(2)=1
$$
- 一个公平八面骰子的熵是
$$
−∑i=180.125⋅log2(0.125)=log2(8)=3
$$
- 一个不公平的八面骰子的熵，其中骰子落在某一面的概率为 $99$ %，落在其他面的概率相等，各约为 $1$ %，其熵为
$$
−(0.99⋅log2(0.99)+∑i=170.0014⋅log2(0.0014))=0.10886668511648723
$$

希望现在熵代表不确定性这一点能更直观一些。一个八面骰子的熵会比一枚硬币更高，因为我们对八面骰子结果的不确定性比对硬币结果的不确定性更大（八个等可能的结果比只有两个等可能的结果更具不确定性）。但是一个高度不公平的八面骰子的熵甚至比一枚硬币还低，因为我们对不公平骰子的结果有很高的确定性。现在我们有了一个实际的方程来量化关于一个系统的那种不确定性（熵）。

目前尚不清楚这种熵的定义与无序、热量或时间有何关系，但这种将熵视为不确定性的观点对于理解我们即将探讨的宇宙熵至关重要。作为参考，这种熵的定义被称为香农熵。

我们现在将继续前进，但我建议进一步深入研究信息论。它对数据压缩、纠错、密码学甚至语言学都有许多重要的直接影响，并且几乎涉及任何处理不确定性、信号或知识的领域。

## 物理熵

现在我们将从一个截然不同的视角，即统计力学的视角来审视熵。我们从每个学生都学过的对熵的经典介绍开始。

### 盒子里的球

我会给你一个盒子，里面有 10 个球，从 $p0$ 到 $p9$ ，然后我们来数一数盒子左边和右边各有多少个球。假设每个球在两边的可能性是相等的。我们马上就能看出，数出所有球都在盒子左边的可能性非常小，而数出两边球的数量相等的可能性更大。为什么会这样呢？

嗯，只有一种状态下我们会把左边的所有球都算进去，那就是当每个球都在左边的时候（真的很惊人，但请听我继续）。但是盒子平衡的方式有很多种：我们可以让从 $p0$ 到 $p4$ 的球在一边，其余的在另一边，或者是同样的分组但左右颠倒，或者我们可以让所有偶数编号的球在一边，奇数编号的球在另一边，或者同样颠倒过来，或者是其他许多可能的组合中的任何一种。

这个盒子是一个系统，至少在我告诉你每一边计算了多少个球之后，我们可以测量它的熵。可能需要一些时间才能明白，但想象一下这个盒子，我们左右两边的计数作为一个系统，其结果将是弄清楚盒子里每个球的位置，这类似于掷骰子并查看它落在哪个面上。

这将意味着，我们在左侧对所有球进行计数的盒子只有一种可能的结果：所有球都在左侧。我们会认为这个系统具有 $0$ 熵（没有预期的意外），因为我们已经知道会在何处找到每个单独的球。

具有平衡面（每边各 5 个）的盒子有许多可能的等概率结果，实际上，我们可以将它们一一数出来。组合数学中的一个著名公式是 N 选 k 公式，它正是用于计算这种情况的。该公式告诉我们，有 252 种可能的方式可以在每边放置 5 个球。那么这个系统的熵将是 $−∑i=12521252⋅log2(1252)=log2(252)=7.9772799235$ 。这与计算一个 252 面骰子的熵是一样的。

如果我们增加球的数量，平衡盒子的熵将会增加，因为那时会有更多可能的组合来构成一个平衡的盒子。

我们应该将这些结果解释为：满足大规模测量的方式数量越多（计算每一侧的球数），系统的熵就越高。当所有球都在左侧时，满足该测量的方式只有一种，因此其熵较低。当有多种方式使两侧达到平衡时，它具有高熵。

在这里我们看到 1000 个球在一个盒子里四处弹跳。它们一开始都在左边，所以盒子的熵为 0，但一旦球开始向右穿过并改变两边的数量，熵就会增加。

在统计力学中，大规模测量的正式术语是宏观态，而能够满足该测量的特定状态是微观态。我们会将测量盒子每一侧的球数称为宏观态，将各个球位置的不同组合称为微观态。所以重新表述上述内容：只有一种微观态代表所有球都在一侧被计数的宏观态，而有许多微观态代表盒子平衡的宏观态。

但是我们为什么决定测量左右两边球的数量呢？我们本可以测量一个不同的宏观状态，而熵也会不同。

### 宏观状态

想象一下，我们不是选择盒子的左半部分和右半部分来计算球的数量，而是计算盒子每个像素中有多少个球。在这种情况下，熵几乎总是最大化的，因为球很少共享一个像素。即使所有的球都在盒子的左侧，它们可能仍然各自占据不同的像素，并且测量到的熵与球均匀分布在盒子中的情况相同。

如果我们使用昂贵的仪器来测量盒子并高精度地跟踪球，那么熵很少会改变并且会非常高。相反，如果我们使用一种便宜的仪器，它只能判断球是在盒子的左边还是右边，那么熵会很低，并且如果一些球暂时最终在盒子的同一侧，熵很容易波动。

让我们再次对盒子里 1000 个球进行完全相同的模拟，仍然从左边的球开始。但是，这次我们计算 50x50 网格中每个单元格里有多少个球，而不是前两个单元格（左边和右边的单元格）。熵会很高，因为有许多微观状态表示一堆单元格中每个单元格只有 1 个球，而且熵不会有太大变化，因为两个球很少共享同一个单元格。回想一下，如果两个球共享同一个单元格，计数就会增加，与每个单元格计数为 1 的两个单元格相比，满足计数为 2 的单元格的微观状态更少。

熵并非仅存在于物理系统本身，而是同样存在于我们对它的描述之中——也就是说，我们所测量的宏观状态以及我们观察它的分辨率。

对我们系统的低分辨率版本进行测量的这个过程（比如计算盒子左边或右边有多少个球）被称为粗粒化。

我们如何选择/测量宏观态，也就是我们如何对系统进行粗粒化，取决于我们正在解决的问题。

- 想象一下你有一盒气体（就像我们盒子里的球，但盒子里的球的数量是 $1025$ 个），并且我们在盒子的左侧和右侧放置一个温度读取器。这就给了我们一个宏观状态，即盒子左侧和右侧平均球速的两个计数。然后，我们可以通过比较温度读取器相等时和它们相差 $T$ 度时的情况来计算熵。一旦我们了解了时间和熵是如何相互作用的，我们将使用这个模型来表明，随着时间的推移，两个温度读取器预计会收敛到相同的值。
- 想象一下，你对一群人中许多不同个体的基因组进行测序，你可以根据自己关心的内容选择许多不同的宏观状态。你可以统计所有序列中每种核苷酸的数量，从而量化 DNA 中四种核苷酸的变异程度。你可以通过统计群体中该位置使用的核苷酸类型数量，计算 DNA 序列中每个个体位置的熵，从而识别出个体间恒定或个体间变化的 DNA 部分。

对于同一个系统，你选择如何测量宏观态可以有多种形式，这取决于你能够测量什么以及/或者你关心测量什么。

但是一旦我们有了一个宏观状态，我们就需要一种方法来识别所有的微观状态并为它们分配概率。

### 微状态

当我们观察盒子中大小相同的单元格里球的位置时，很容易看出每个球处于任何一个单元格的可能性是相等的，所以每个微观状态的可能性也是相等的。这使得计算熵变得非常简单，我们只需使用 $(Shannon entropy)$ 的简化版本来发现，对于满足给定宏观状态的 $W$ 个微观状态，系统的熵为 $log2(W)$ 。将这个想法扩展到可能性不相等的微观状态并不太难。

例如，让我们计算一个盒子的熵，盒子左边有 5 个球，右边有 5 个球，但我们将盒子中的一个球换成了一个被磁铁拉向左边的金属球。在这种情况下，每个微观状态的概率不再相等。如果我们假设金属球在左边而不是右边的概率为 $80$ %，那么盒子的熵可以计算如下：对于所有 252 个微观状态，其中 126 个状态金属球在左边，其为真的概率为 $0.8$ ，另外 126 个状态金属球在右边，概率为 $0.2$ 。这意味着使用 $(Shannon entropy)$ 我们得到的熵为

$$
−∑i=11260.2126⋅log2(0.2126)−∑i=11260.8126⋅log2(0.8126)=7.69921
$$

这比装有普通球且具有 $7.9772799235$ 熵的盒子的情况略少。这正是我们所预期的，由于我们知道其中一个球更可能在哪里，所以我们对这个系统的结果更确定一些。

但这就引出了一个微妙的问题：我们为什么选择这组特定的微观状态呢？例如，如果我们有左边 5 个球、右边 5 个球的宏观状态，但我们决定用 50x50 的单元格网格来描述微观状态，那么与我们使用左右 2x1 的网格时相比，满足该宏观状态的微观状态要多得多。

让我们计算这两个例子的熵。请记住，它们都具有相同的宏观状态：左边有 5 个球，右边有 5 个球。

- 如果我们选择使用微观状态，即观察将盒子一分为二的两个单元格之间单个球的位置，那么我们可以使用 n 选 k 来计算两个单元格之间有 252 种可能的球的组合。这给了我们一个熵为 $log2(252)=7.977279923$ 。
- 如果我们选择使用微观状态，即观察单个球在将盒子分成网格的 50x50（2500）个单元格之间的位置，那么我们可以使用 n 选 k 来计算盒子两半部分中球的可能组合有 252 种，对于每一种组合，每个球都可以位于 50x25（1250）个单元格中的任何一个。这给了我们一个熵为 $log2(252∗125010)=110.8544037$ 。

这个结果与我们对熵的信息论理解非常吻合：当我们允许更多的微观状态来表示相同的宏观状态时，我们对系统所处的微观状态就更加不确定。但这个结果确实引发了一些担忧。

如果不同的微观状态给出不同的熵，那么我们如何为我们的问题选择正确的微观状态呢？与宏观状态不同，选择使用哪些微观状态的这个决定不是由我们的仪器或问题的范围决定的，它必须由进行计算的人来决定。对于物理系统，人们通常会使用能够捕捉与宏观状态相关的所有相关信息的微观状态集合。例如，如果我们的宏观状态是关于盒子左边或右边的球，那么我们可能除了球的位置之外，并不关心球的速度、质量或其他任何东西。

另一个问题是，同一个具有相同宏观状态的物理系统，其熵会因我们所使用的微观状态表示不同而不同，这让人感觉不太对。通常，我们期望物理系统的测量结果是不变的，无论我们决定用于测量的内部表示是什么。但熵并非如此。我们需要记住，熵是系统的不确定性，而且熵的定义完全取决于我们不确定的是什么，对于物理系统来说，就是微观状态。这类似于有人问“那台机器由多少个部件组成？”，对此我们应该回答“你如何定义一个‘部件’？”。当我们问“这个宏观状态的熵是多少？”时，我们需要回答“我们使用的是哪些微观状态？”

话虽如此，我们的直觉告诉我们的内容有一些小道理，尽管它并不适用于一般情况。当我们改变微观状态时，系统的熵会发生变化，但如果新的微观状态均匀地乘以旧的微观状态，那么不同宏观状态之间的熵的相对差异将是相等的。也就是说，如果每个原始微观状态被分割成相同数量的细化微观状态，那么每个宏观状态的熵会增加一个常数。我们在术语中迷失了方向，举个例子就明白了。

让我们再次考虑盒子里的 10 个球，我们将针对几种不同的宏观态和微观态表示来计算系统的熵。我们用 `(L, R)` 表示盒子每一侧的球数，其中 `L` 是左侧的球数， `R` 是右侧的球数。然后我们使用 2x1 网格单元（即盒子的左右两半）的微观态以及 50x50 网格单元来计算熵。

|  | (10,0) | (9,1) | (8,2) | (7,3) | (6,4) | (5,5) | (4,6) | (3,7) | (2,8) | (1,9) | (0,10) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 2x1 | 0.00000 | 3.32193 | 5.49185 | 6.90689 | 7.71425 | 7.97728 | 7.71425 | 6.90689 | 5.49185 | 3.32193 | 0.00000 |
| 50x50 | 102.87712 | 106.19905 | 108.36898 | 109.78401 | 110.59137 | 110.85440 | 110.59137 | 109.78401 | 108.36898 | 106.19905 | 102.87712 |

并且如果我们观察，我们会发现 50x50 网格微观状态值中的熵仅仅是 2x1 网格值加上一个常数。两种情况下的相对熵将是相同的。如果我们从数学上展示熵是如何计算的，这会更加清晰。对于 2x1 网格，我们使用方程 $log2((10L))$ ，对于 50x50 网格，我们使用 $log2(125010(10L))=log2(125010)+log2((10L))$ 。从数学上我们可以看到，它与 2x1 网格的熵相同，只是偏移了 $log2(125010)$ 。

你可以想象，如果我们沿着微观状态再增加一个维度，那么我们会再次使熵增加一个常数。例如，如果 10 个球中的每一个都可以是 3 种颜色之一，那么微观状态的数量将增长 $310$ 倍，因此整个系统的熵将增加 $log2(310)$ 。

当我们使用彼此成倍数的不同微观状态时，我们的直觉是正确的，但如果微观状态并非如此整齐地相互成倍数，那么这种直觉就会失效。一个简单的例子是，如果我们将盒子的左侧表示为一个单元格，右侧表示为一个 50x25 的单元格网格，那么熵看起来会非常不同。下面再次列出表格，但增加了一行我们的非均匀微观状态。我们计算宏观状态 $(3,7)$ 的熵的一个例子是：有 120 种等可能的方式将 3 个球放在左侧，7 个球放在右侧，但右侧的球也可以处于 $12507$ 种不同的状态，所以熵是 $log2(120⋅12507)=78.920877252$ 。

|  | (10,0) | (9,1) | (8,2) | (7,3) | (6,4) | (5,5) | (4,6) | (3,7) | (2,8) | (1,9) | (0,10) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 2x1 | 0.00000 | 3.32193 | 5.49185 | 6.90689 | 7.71425 | 7.97728 | 7.71425 | 6.90689 | 5.49185 | 3.32193 | 0.00000 |
| 50x50 | 102.87712 | 106.19905 | 108.36898 | 109.78401 | 110.59137 | 110.85440 | 110.59137 | 109.78401 | 108.36898 | 106.19905 | 102.87712 |
| mixed | 0.00000 | 13.60964 | 26.06728 | 37.77003 | 48.86510 | 59.41584 | 69.44052 | 78.92088 | 87.79355 | 95.91134 | 102.87712 |

需要注意的一件有趣的事情是，当所有球都在左边时，熵为零，但当所有球都在右边时，熵达到最大值。同样，希望从我们对熵的理解来看这是有意义的，即它衡量相对于我们微观状态的不确定性。如果我们知道所有球都在左边，那么我们知道它们一定在左边的单个单元格中，所以没有不确定性。如果我们知道球都在右边，那么它们可以处于 $125010$ 个微观状态中的任何一个，所以不确定性很高。

显然，在测量系统的熵时，我们需要小心并清楚我们所选择的微观状态。幸运的是，对于大多数物理系统，我们使用系统中球（粒子）的位置和动量的均匀网格的标准微观状态。另一个可使用的标准微观状态是位置和动量的连续空间。

### 连续微状态

到目前为止，我们研究的是微观状态的离散集合——比如盒子里的球。但在物理系统中，微观状态通常是连续的：位置和动量可以在一个连续统上变化。在这种情况下我们如何计算熵呢？这与其余的解释无关，但却是一个值得探索的有趣分支。

让我们回到二维盒子中的 10 个球的问题。如果每个球可以占据正方形内的任何位置，那么系统的微观状态就是一个位于 $20$ 维空间中的点（每个球有 2 个维度）。可能的微观状态数量是无限的——而且每个单独的微观状态的概率都是无穷小的。

在此设置中，我们使用概率密度函数 $ρ(x)$ ，并且熵变为一个连续积分：

$$
S=−∫Xρ(x)log2⁡ρ(x)dx
$$

这被称为微分熵。它将香农熵推广到连续系统，不过存在一些微妙之处——它可能为负，并且在坐标变换下不是不变的。

如果密度是均匀的，比如说在体积为 $V$ 的区域上为 $ρ(x)=1V$ ，那么熵变为：

$$
S=−∫X1Vlog2⁡(1V)dx=log2⁡(V)
$$

因此，熵仍然随着可及状态体积的对数增长，就像在离散情况下一样。

这种形式体系在量子力学中特别自然，其中波函数 $ψ(x)$ 定义了一个概率密度 $ρ(x)=|ψ(x)|2$ 。考虑一个一维高斯波函数：

$$
ψ(x)=(1πσ2)1/4e−x2/(2σ2)
$$

其熵（以比特为单位）为：

$$
S=−∫−∞∞ρ(x)log2⁡ρ(x)dx=12log2⁡(2πeσ2)
$$

这表明，正如预期的那样，更宽的分布具有更高的熵：更分散的波函数表明粒子位置的不确定性更大。

例如：

- 如果 $σ=1$ ，那么 $S≈2.047$
- 如果 $σ=3$ ，那么 $S≈3.600$

这同样应该是有道理的：当我们对一个系统的确定性较低时，比如在测量时一个粒子会在哪里，它的熵就越高。

还有一个需要解决的小问题：如果状态空间是无界的，比如经典力学中的动量，那么熵可能会发散。在实际中这不是问题，因为物理系统通常具有概率分布（如高斯分布），这些分布在无穷远处衰减得足够快，以保持熵有限。当情况并非如此时，我们要么将系统限制在一个有限区域，要么关注熵差，即使绝对熵发散，熵差仍然是明确定义的。

但是让我们回到我们的主题，我们将通过一个历史概述重新探讨它。

### 熵的标准用法

在克劳德·香农提出信息论的八十年前，路德维希·玻尔兹曼为理想气体提出了熵的统计定义。他提出，系统的熵 $S$ 与给定宏观状态下的微观状态数 $W$ 的对数成正比：

$$
(Boltzmann entropy)S=kBln⁡(W)
$$

这个方程应该看起来很眼熟：它是我们一直在使用的香农熵的等概率特殊情况，只是底数发生了变化（从 $log2$ 变为 $ln$ ），并且有一个缩放因子 $kB$ （玻尔兹曼常数）。玻尔兹曼统计力学与香农信息论之间的联系不仅仅是历史巧合——两者都对不确定性进行量化，无论是物理状态还是消息中的不确定性。

几年后，约西亚·威拉德·吉布斯（Josiah Willard Gibbs）将玻尔兹曼的定义推广到微观状态概率不相等的情况。他的公式仍然是现代物理学中熵的标准定义：

$$
(Gibbs entropy)S=−kB∑ipiln⁡(pi)
$$

这在形式上与香农熵相同，同样仅在对数底数和物理单位上有所不同。但吉布斯的推广是一个巨大的飞跃：它使热力学能够描述与热浴、粒子库以及其他微观状态概率分布不均匀的环境相接触的系统。这使得熵的应用远远超出了理想气体——涵盖了化学反应、相变以及各种统计系综。

既然我们已经对熵有了形式上的理解，并了解了一些历史背景，那么让我们试着去理解熵是如何与我们的宇宙，特别是与时间相关联的。

### Time

时间在这一切中扮演着怎样的角色？

当你往茶里滴一滴牛奶时，它总会扩散并混合开来，但你永远看不到相反的情况，即牛奶分子自发地分离并变回一个整齐的液滴。当海浪冲击海岸时，浪花和泡沫会散开，但我们从未见过这种混乱重新组合成一个连贯的波浪并退回大海。这些例子取自理查德·费曼关于熵的这次讲座。如果你看到这些事件的倒放视频，你会立刻意识到有些不对劲。乍一听这似乎很明显，但如果仅从物理定律来看，实际上并不清楚为何应该如此。所有已知的物理定律都是时间可逆的（波函数坍缩似乎存在争议），这仅仅意味着它们正向播放和反向播放看起来是一样的。单个分子都遵循这些时间可逆的定律，然而那杯茶却总是因为牛奶的混合而变浑浊。

这凸显了一个基本的悖论：微观物理定律是时间可逆的，但宏观世界却不是。如果你拍摄两个原子相互碰撞的视频并倒放，它在物理上看起来仍然是合理的，但将牛奶与咖啡混合的视频倒放，就会明显看起来不对。

我们希望构建一个时间的简化模型，使其既能反映微观定律的时间可逆性，又能体现宏观行为的时间不对称性。让我们把一个物理系统（比如一盒粒子）的完整状态想象成一个位于名为相空间的高维空间中的单点，其中每个维度对应一个粒子的位置和动量。随着时间的推移，系统在这个空间中描绘出一条连续的轨迹。

物理定律，如牛顿方程、哈密顿力学或薛定谔方程，都支配着这条轨迹。它们是确定性的且时间可逆。这意味着如果你在任何时刻反转所有粒子的动量，系统将在状态空间中沿相反路径回溯其轨迹。

到目前为止，一切都是时间可逆的，包括这种关于宇宙如何随时间演化的观点。但我们将会看到，即使在这个简化模型中，时间似乎也有一个优先方向，即时间箭头。

关键在于粗粒化。当我们观察世界时，我们看不到每一个微观细节。相反，我们测量宏观状态：诸如温度、压力、物体位置或一杯茶中的颜色分布等总体属性。每个宏观状态对应许多潜在的微观状态——而且并非所有宏观状态都是平等的。

例如，考虑一个在地板上滑动并由于摩擦力而静止的盒子。在微观层面，该系统只是粒子在交换动量，并且所有过程都是时间可逆的。但我们肯定不会称这个过程是时间可逆的，我们从未见过一个盒子从静止状态自发地开始加速。但是，如果我们取盒子由于摩擦力而静止后的那一刻，然后反转所有粒子的速度（包括那些将盒子的动能作为热量吸收的地板中的粒子），盒子就会自发地开始移动并滑回其原始位置。这将遵循牛顿定律，但这种情况极其不可能发生。为什么呢？

能量以热量形式分散的微观状态数量（盒子静止，底部分子在振动）远远超过所有能量协同起来推动盒子的微观状态数量。静止的宏观状态具有高熵，而自发运动的宏观状态具有低熵。当系统从低熵状态随机或确定性地演化时，它极有可能朝着更高的熵发展，仅仅是因为存在更多这样的微观状态。

如果你对宇宙中的所有粒子有完美的认知（即你处于微观状态层面），时间似乎就没有方向。但从像我们这样的粗粒化观察者的角度来看，熵往往会增加。这就是为什么一杯茶混合的影片看起来很自然，但反过来的影片看起来很假。在物理定律层面，两者都是有效的。但一个是典型的，另一个则极其罕见，这一切都是因为我们进行了粗粒化。

为了把这一点讲清楚，让我们再看看盒子里的球。我们将通过把盒子划分成一个个单元格的网格，并计算每个格子里有多少个球来定义宏观状态。

现在假设这些球通过随机的小抖动移动（我们的微观动力学玩具模型）。随着时间的推移，系统自然会倾向于探索最可能的宏观状态，因为最可能的宏观状态有更多的微观状态供你进入。也就是说，熵随时间增加，不是因为定律中有任何基本的不可逆性，而是因为高熵宏观状态要常见得多。

如果我们从所有球都堆积在左边开始模拟，那是一个非常特殊的（低熵）宏观状态。当它们散开时，兼容的微观状态数量增加，熵也随之增加。

这导致了一个至关重要的认识：熵增加是因为我们始于一个低熵状态。这通常被称为过去假设，即宇宙始于一个极低熵状态的假设。基于此，热力学第二定律自然成立。时间之箭并非源于动力学本身，而是源于粗粒化后逆转它们的统计不可能性，以及我们始于低熵状态这一事实。

你可以想象，一旦一个系统达到接近最大熵的状态，它看起来就不再是时间不可逆的了。由于熵本质上是一种统计量度，这样一个系统的熵会有微小的波动，但这些波动会小到难以察觉。例如，当播放牛奶倒入茶中的视频（低熵宏观状态）时，很明显视频是正向播放还是反向播放，但对于已经混合的牛奶和茶（高熵宏观状态）搅拌的视频，你无法分辨它是正向播放还是反向播放。

虽然熵存在微小的波动，但这些波动不足以解释那些有时似乎违反我们刚刚确立的熵总是随时间增加这一原理的大规模现象。

### 违反第二定律？

一些现实世界的例子似乎与熵总是增加的说法相矛盾。例如，油和水混合后会分离，尘埃聚集成恒星和行星，而且我们制造像过滤器和冰箱这样的机器来分离混合物质。这些难道不是违反（熵增原理）的情况吗？

问题在于，我们一直只考虑分子的位置，而物理系统具有许多不同的属性，这些属性允许存在更多的微观状态。例如，如果我们开始同时考虑盒子中球的位置和速度，那么即使所有球都在盒子的左侧，熵也可能很高，因为每个球可能具有不同的速度。如果球都在左侧且速度都相同，那么熵就会很低。一旦我们也考虑速度，熵可以因位置分布更分散和速度分布更分散而增加。

当水和油分离时，分子的位置分成上下两层，这似乎降低了位置熵。然而，这种分离实际上增加了系统的总熵。为什么呢？水分子强烈倾向于与其他水分子形成氢键，而不是与油分子相互作用。当水分子在混合状态下被迫靠近油分子时，它们必须采取更受限的排列方式，以尽量减少不利的相互作用，从而减少了可用的微观状态数量。当水和油分离时，水分子可以以更多的构型与其他水分子自由相互作用，油分子也可以更自由地与其他油分子相互作用。分子排列和相互作用的可用微观状态的这种增加，足以弥补位置混合熵的减少。所以，虽然如果我们只考虑分子的大致位置（混合与分离），熵会降低，但当我们考虑所有分子相互作用、取向和局部排列时，总熵会增加。 这说明了为什么我们在计算一个系统的熵时需要考虑该系统的所有属性。

当恒星或行星由太空中漂浮的尘埃颗粒一起形成并因引力聚集在一起时，似乎即使我们考虑这些颗粒的位置和速度，熵也可能在减少。尽管颗粒加速聚集在一起，但它们在碰撞后会减速，这似乎是熵在减少。这是因为我们再次没有考虑整个系统。当颗粒相互碰撞时，它们的速度会因将动能转化为辐射而略有降低，导致光子被发射到太空中。如果我们考虑一个不允许辐射的系统，那么动能就会通过速度的变化从一个颗粒转移到另一个颗粒，并且由于速度更快，系统的熵仍然会增加。一旦我们开始考虑系统中位置、速度和所有颗粒的熵，我们就可以考虑所有等概率的微观状态并计算出正确的熵。

同样，一旦我们考虑冰箱周围的整个系统，熵的减少就会消失。运行冰箱所产生的电能的熵以及从冰箱内部转移到外部的热量的熵，将抵消因冰箱内部冷却而导致的熵的减少。只要整个系统的熵仍在增加，就可以产生局部的熵减少。

在分析系统的熵时，要确保考虑整个系统，包括粒子的位置、速度、其他相互作用，所有粒子都要包含在内，并且确实在分析整个系统。

### 紊乱

熵有时被描述为“无序”，但这种类比并不精确，而且常常具有误导性。在统计力学中，熵有一个严格的定义：它量化了与给定宏观状态兼容的微观状态的数量。也就是说，熵衡量的是在给定一些粗粒度的宏观描述的情况下，我们对系统精确微观构型的不确定性。

那么“无序”这个概念是从哪里来的呢？

从经验上看，我们标记为“无序”的宏观状态通常对应着比我们认为“有序”的状态多得多的微观状态。例如，在一个孩子的房间里，玩具随机散落的配置比所有东西都整齐上架的配置要多得多。由于散落的房间对应更多的微观状态，所以它具有更高的熵。

但熵与无序之间的这种联系并非根本性的。问题在于，“无序”是主观的——它取决于人类的认知、背景和分类。例如，在我们之前关于 1000 个球在盒子里四处弹跳的例子中，由于实现它的可能微观状态数量巨大，一个完美均匀的球格会具有高熵。然而，对于人类观察者来说，这样的球格可能看起来高度“有序”。

关键在于：给定一个宏观态和一组微观态，熵是客观且定义明确的，而“无序”是一个以人类为中心的启发式概念，它有时（但并非总是）与熵相关。依赖“无序”来解释熵有造成混淆的风险，特别是在视觉上的对称性或规则性掩盖了潜在统计结构的系统中。

## 结论

所以，以下是一些关于一些常见的熵相关表述的想法：

- 熵是无序程度的一种度量。
	- “无序”是一个主观术语，用于描述人类认为无用/不理想的系统状态，并且通常比人类创造的“有序”宏观状态具有高得多的熵。因此，当熵增加时，我们最终更有可能处于无序状态，尽管不能保证。
- 在封闭系统中，熵总是增加的。
	- 这是一个在所有实际用途中都成立的统计陈述，但它并非绝对保证，当你观察非常小的孤立系统或深入测量系统的最微小细节时可能会失效。它还假设你起始于一个低熵状态，从而为你的系统提供熵增加的空间。这有一个巧妙的含义，即由于我们观测到宇宙的熵在增加，那么它必然起始于一个低熵状态。
- 由于熵的原因，热量从高温流向低温。
	- 热从高温流向低温，这是因为系统温度不均匀的方式数量远低于温度均匀的方式数量，所以当系统“随机”地转变到新状态时，从统计学角度来看，最终会处于更均匀的状态。
- 熵是物理学中唯一一条时间不可逆的定律。
	- 所有的物理基本定律都是时间可逆的，但通过粗粒化并从低熵状态开始，一个系统在统计上会朝着高熵状态移动。这意味着，如果一个系统已经处于接近最大熵的状态（要么是由于其构型，要么是由于粗粒化的选择），或者我们不进行粗粒化，那么熵看起来就不会是时间不可逆的。

以下是一些进一步的阅读材料，我发现所有这些对于了解熵都极其有帮助。

- [理查德·费曼关于熵的讲座](https://www.youtube.com/watch?v=ROrovyJXSnM)
- [哈佛大学统计力学课程中由马修·施瓦茨讲授的关于熵的课程笔记](https://scholar.harvard.edu/files/schwartz/files/6-entropy.pdf)
- [约翰·C·贝兹所著的一本关于熵的既友好又严谨的教科书](https://math.ucr.edu/home/baez/what_is_entropy.pdf)
- [一个关于熵的 YouTube 视频，其中使用了实际的球在盒子里弹跳的画面](https://www.youtube.com/watch?v=VCXqELB3UPg)