好的，这是根据视频内容生成的简体中文语音文字稿。

---

我的名字是 Beyang，我是一家名为 Sourcegraph 的公司的联合创始人兼首席技术官。我们开发开发者工具，今天我想和大家分享一些我们观察到的、关于如何驾驭编程智能体（coding agents）这一新兴技能的见解。

### 关于编程智能体的争议

几天前，社交媒体上出现了一些关于 AI 编程智能体功效（或者说无效，取决于你的看法）的激烈讨论。

Jonathan Blow，一位非常有才华的开发者，他几乎以一己之力完成了独立游戏《Braid》的编程。他在编程能力上可以说是“神级”人物。他转发了 Alex Albert（我也非常尊敬的一位在 Anthropic 工作的人）的推文，基本观点是，所有围绕编程智能体和代码生成的炒作都只是炒作，毫无实质内容。

随后出现了一系列回应。开发者界的另一位大人物 Jesse Frazelle（Docker 的早期贡献者和维护者）表示，她基本同意 Jonathan 的看法，但补充说：“Jonathan，你属于那顶尖的 0.01% 的程序员。对于我们这些凡人来说，它（AI）实际上帮助很大。”

但也有像 Eric S. Raymond（开源运动的教父之一）这样的人，他给出了一个非常辛辣的回复，大意是：“我认为自己编程还不错，但这些东西帮了我大忙。”

我最喜欢的回应来自一篇 Hacker News 的热门文章，作者是 Thomas Ptacek，一位非常厉害的安全工程师。他的观点截然相反，认为那些对 AI 持怀疑态度的聪明人简直是“疯了”，这些工具非常有用。

我猜在座的各位可能都倾向于认为编程智能体是有实质性作用的。但我认为，即便在这个房间里，关于智能体在何处最有效、它们是仅限于小型编辑还是能用于生产代码库，大家可能也有着不同的看法和最佳实践。

### 大多数人都“用错了”

几个月前，我读了一篇来自 Jeff Huntley 的博客文章。Jeff 当时是 Canva 的一名高级工程师，他的工作很有趣，就是去采访公司内部使用 AI 工具（如 Cursor）的开发者，看他们是如何使用的。他得出的结论是：大多数人都“用错了”（holding it wrong）。

他在文章里列举了各种他看到的“反模式”（anti-patterns）。我对那篇文章的总结是：**现在人们使用编程智能体的头号错误，就是他们试图用六个月前使用 AI 编码工具的方式来使用它们。**

这听起来很疯狂，因为通常一个工具的最佳实践不会在六个月内就发生改变。但我们正处在一个非常有趣的时刻。为什么会有这么突然的变化？我认为这是因为过去六个月里，模型能力经历了一次阶梯式的飞跃。

### AI 的三个时代

我们都经历了自生成式 AI 诞生以来的发展，也就是从“远古”的 2022 年 11 月 ChatGPT 发布算起。我认为，主要由前沿模型能力演进驱动，已经出现了三个不同的浪潮或时代。模型的不同能力决定了应用层的理想架构。

1.  **GPT-3 时代**：所有模型都是文本补全模型。因此，主流的应用是各种“Copilot”或自动补全工具。核心交互就是你输入一些东西，它也输入一些东西。
2.  **ChatGPT 时代 (2023)**：GPT-3.5 经过指令微调，可以像聊天机器人一样交互。人们意识到，不仅可以补全，还可以像和人一样提问。很快，大家发现可以将代码库里的代码片段复制粘贴到聊天框里，让它作为示例进行模式匹配，从而生成更准确的代码。于是，2023 年的应用层几乎人人都在构建“RAG Bot”（聊天机器人 + 检索增强生成）。
3.  **智能体时代 (现在)**：我们现在进入了智能体的时代。新的模型能力要求新的应用架构。

我们在 Sourcegraph 问自己：市场上的许多现有工具都是为 GPT-4 和 Claude 3 的聊天时代设计的。如果我们从头开始设计一个编码智能体，以释放具备工具使用能力的“智能体式”大语言模型（Agentic LLM）的潜力，那它会是什么样子？

### 为智能体时代而生的新设计原则

以下是我的一些“辛辣”观点，这些是在智能体时代我认为更优越、但可能与聊天机器人时代最佳实践相悖的设计决策。

1.  **智能体应直接修改文件**：它不应该在每一步都停下来问你：“嘿，我想做这个修改，可以应用吗？”如果它停下来问你，并且它是错的，那它就已经浪费了你的时间。人类需要更多地“在循环之上”（on the loop）进行指导，而不是“在循环之中”（in the loop）进行微观管理。

2.  **我们还需要厚重的客户端吗？**：我们还需要一个 VS Code 的分叉版本来操控大语言模型吗？当智能体的契约变成了“你让它做事，它就去做事”，那么那些围绕上下文管理、应用变更的复杂 UI 是否还必要？

3.  **超越“自选模型”阶段**：在智能体世界里，大语言模型与智能体逻辑的耦合更深。LLM 是智能体链条的大脑，替换它变得非常困难。很多模型甚至连基本的工具使用都做得不好，所以简单地替换“大脑”并期望得到相似结果是不现实的。

4.  **告别固定价格模式**：智能体消耗大量 token，相对于聊天机器人看起来很贵。但越来越多的人开始比较的是它节省了多少“人类时间”。相对于节省的人类时间，它依然很便宜。固定价格模式反而会产生不良激励：为了降低推理成本，服务商可能会倾向于使用更“笨”的模型，但这只会浪费你更多的时间。

5.  **Unix 哲学胜过垂直整合**：在开发者工具中，能够将简单工具与其他有趣工具良好组合的能力非常强大。对于智能体，由于对 UI 的需求减少，我们将看到更多由命令行驱动的、可组合的工具。

6.  **从头构建新应用**：我们有一个现存的 RAG 聊天助手叫 Cody。但我们决定为智能体世界从零开始构建一个新应用，我们称之为 AMP。因为我们不想被为上一代 LLM 构建的应用层中的所有假设和限制所束缚。

这就像互联网的早期。一开始，人们通过雅虎那样的门户网站来探索网络，它告诉你网上“可以做什么”。但后来，网络的真正力量被一个简单的文本框——搜索引擎——所释放。我认为，智能体化的用户界面也应该朝着这个方向努力。

### 现场演示：用 AMP 改进 AMP

那么，这在实践中是什么样子呢？我们的编码智能体 AMP 有两个客户端：一个极简的 VS Code 扩展和一个命令行工具（CLI）。设计都非常简洁。

我想做一个有点风险的演示：在一个有真实用户的应用上，利用所有现有的约束，对代码库做出贡献。

我现在就在 AMP 的代码库里，我想实现一个小功能。AMP 有一个服务器组件，它提供了与外部服务对话的“连接器”。比如，我们集成了任务追踪工具 Linear，但它的图标是一个通用的网络图标，我很烦这个。我希望当连接到 Linear 时，它能显示一个更合适的图标，比如一个复选框。

我已经为此创建了一个 Linear issue。现在我直接告诉 AMP：

> “请找到关于自定义 Linear 连接器图标的 Linear issue，然后实现它。”

AMP 有一系列工具，包括读写文件、运行 Bash 命令，以及通过一个叫 MCP 的服务连接到 Playwright、Postgres 和 Linear API。

它现在开始工作了。它首先使用 Linear 工具搜索 issue，找到了我提到的那个。然后它开始实现这个功能。它在独立地调用工具，我没有进行干预。界面也保持简洁，不会用大量的底层 API 调用信息来干扰你。

它使用的搜索工具本身就是一个“子智能体”（sub-agent），它会使用多种搜索方法来寻找上下文。它正在阅读前端和后端的文件，非常周到地在动手之前收集足够的信息。这对于保证反馈周期的稳健性至关重要。

在它工作的时候，我通常会做两件事。一是我可以开一个新线程，让它并行处理另一个任务，比如：“你能给我画一张图，解释一下 AMP 中的连接器和连接是如何工作的吗？”

二是我会花时间审查它所做的更改。我现在使用 VS Code 的差异（diff）视图比使用编辑器视图还多。这是一个非常棒的审查方式，你可以在编辑器里看到完整的上下文，甚至可以跳转到定义。

好了，它似乎已经完成了。我们来看看效果。

（刷新页面）

酷！你看，这里的图标已经更新了。这是在我几乎没有进行任何引导的情况下完成的。

但请注意，在另一个页面（设置页面）上，这个图标没有更新。这并不奇怪，因为生产代码库中的变更往往比表面看起来更微妙。这里的原因是，为了判断这是一个 Linear 连接，它需要读取配置中的 MCP 端点 URL。但配置文件可能包含密钥，所以我们禁止将这些信息发送到非管理员页面。

它第一次尝试没搞定是正常的。现在我稍微引导一下它：

> “我注意到图标在管理员连接页面上变了，但在设置页面上没有。你能调查一下为什么吗？”

（让智能体继续运行）

... 稍后的结果是，它成功了。它查看了周围的代码，发现了一个已有的机制，可以将配置中非敏感的部分传递给前端 UI。它完全复用了这个模式，只将需要的端点 URL 传递过去，完美地解决了问题。这个过程展示了智能体处理生产代码库中细微差别的能力。

### 从“超级用户”身上学到的经验

我们将 AMP 发布给了一个小规模的、由热衷于试验 LLM 的人组成的社区。我们发现一个有趣的现象：用户的使用量差异巨大。顶尖的用户每个月会花费数千美元在推理成本上。起初我们以为这是滥用，但与他们交谈后发现，他们确实在用它做正经事。

我们从这些“超级用户”身上学到了很多，并将其融入了我们的产品设计中。

#### 超级用户的使用模式与最佳实践

1.  **编写长而详细的提示**：超级用户们会写非常长的提示，因为他们意识到大语言模型是高度可编程的。你给的上下文越多，它就走得越远。为了鼓励这种行为，我们将 AMP 输入框中的“回车键”默认设置为换行，需要按“Command+Enter”才能提交。这会引导用户编写更详尽的提示。

2.  **引导智能体获取上下文和反馈**：对于你代码库中特有的构建或测试方式，直接告诉智能体怎么做。这能帮助它完成反馈循环，从而走得更远。

3.  **构建前端反馈循环**：一个常见的模式是使用 Playwright（一个自动化测试工具）和 Storybook（一个前端组件开发环境）。这能让智能体在修改前端组件后，快速获得视觉反馈，而无需重新加载整个应用。你就像在为你的智能体担任“开发者体验工程师”，思考如何让它的循环更快。

4.  **用智能体更好地理解代码**：与“让程序员变懒”的普遍看法相反，我们发现超级用户用智能体来更好地理解代码。它是一个很棒的入职工具，能帮你快速熟悉新代码库。同样，在代码审查（Code Review）时，你可以让智能体先帮你总结一个大型变更，并指出审查的切入点。这极大地降低了开始审查的心理门槛，让审查更彻底，甚至更有趣。

5.  **为复杂任务使用子智能体**：对于更长、更复杂的任务，使用子智能体是一个好方法。子智能体可以封装特定子任务的上下文，避免污染主智能体的上下文窗口，从而防止因上下文过长导致模型性能下降。

#### 反模式总结

*   **微观管理**：像对待聊天机器人一样，在每一步都去引导它。
*   **提示不足**：对于复杂的任务，只给一个简单的、三言两语的提示。
*   **逃避理解**：把智能体当作一个让你不用读代码的“TL;DR”工具。恰恰相反，你应该用它来更快地进行更深入的代码审查。

### 未来展望：智能体集群

我们顶尖用户中的顶尖用户，已经开始并行运行多个智能体。之前提到的 Jeff Huntley，他会在晚上设置三到四个智能体，让它们分头去实现一个编译器的不同部分，然后他就去睡觉了。他甚至在网上直播这个过程，以证明智能体可以用于像编译器这样严肃、困难的工程项目。

我认为，这就是未来的方向。我们不会一步到位地拥有“智能体舰队”，而是通过构建这些可组合的模块，让像 Jeff 这样的人能够以有趣的方式将它们组合起来。

### 总结

我想留给大家的要点是：

1.  编程智能体是真实存在的，它是一项有很高天花板的技能。我们应该像学习如何使用编辑器或编程语言一样，投入时间去学习如何使用它们。
2.  学习的唯一途径就是实践，并与他人分享。

我们在 AMP 中内置了分享功能，就是为了鼓励知识的传播。如果你想了解更多，我们发布了一本《AMP 用户手册》，总结了这些最佳实践。

谢谢大家。
