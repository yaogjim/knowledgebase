好的，这是根据您提供的 YouTube 视频生成的简体中文语音文字稿。

---

## 准备工作与环境设置

大家好，随着大家入场，我们这里设置了一台服务器，上面有你们跟着操作所需要的一切。你应该已经拿到了一张便利贴，如果没有，请举手，我的同事 Alex 会过来给你一张。基本上，你要做的就是，如果你的编号是 160 或以下，就访问这个链接，上面也有二维码。如果你的编号是 201 或以上，就访问第二个链接或二维码。之后我会给你一些指示，你需要克隆一个仓库，然后快速地把一个环境文件移动过去。

另外，关于这个演示文稿里的所有内容，我创建了一个名为 `workshop-graph-intro` 的 Slack 频道。所以如果你是 AI Engineer Slack 群组的成员，也可以去那里获取这个演示文稿，获取链接，或者用你喜欢的方式来做。我们再过几分钟就开始。

好的，你的编号会给你你的用户名和密码。基本上是全小写的 `attendee` 加上你的编号，这将是你的用户名和密码。当你登录时，你还应该尝试打开另一个链接，就是那个浏览器预览链接，但我稍后会带你们过一遍。

我再给大家一分钟时间，让大家都能进来并安顿好。

（观众提问：用户名和密码是什么？）
用户名和密码是全小写的 `attendee`，然后加上你的编号。用户名和密码是一样的。

（观众提问：这些 notebook 在会议结束后还能用吗？）
服务器在会议结束后会关闭，但是你有 GitHub 链接可以回去看。所以代码是留给你用的，只是那个环境之后就不可用了。

好了，我要开始了。我先把这个屏幕留一会儿，如果你想扫二维码，现在是时候了。当然，你也可以去 Slack 频道获取这个演示文稿。

## 课程介绍

今天我们要做一个图（Graph）入门工作坊。我一直在纠结这次工作坊到底要放些什么内容，因为所有东西都变化得太快了。我的一些同事说服我不要搞得太复杂，所以这个课程将是非常入门级的。如果你想了解更高级的图技术，比如与 LangChain 等的集成，你可以在我们的展位找到相关内容，我们还有其他活动，明天会讲到一些这方面的东西，我会在后面给出所有相关的链接。

基本上，我们将先完成所有设置，希望这只需要几分钟。然后我们有三个模块：
1.  **图基础知识**：我们会介绍一些图的基础知识。今天我们会使用 Neo4j 这个图数据库，学习如何查询它，如何构建逻辑来检索数据。
2.  **非结构化数据处理**：我们会讲一下非结构化数据，以及如何做实体提取。
3.  **构建简单智能体**：在第三个模块，我们会使用 LangGraph，构建一个非常简单的智能体（Agent），它会使用一些检索工具，你会看到它是如何工作的。

最后我们会用一些资源来收尾。请随时提问，举手就好，我会不时停下来。但我们只有80分钟，所以如果你有问题，请马上提出来，我们会解答，因为我们会比较快地过一遍材料。

### 环境设置回顾

就像我之前说的，我们设置了两个 Jupyter 服务器，所以你不需要 `pip install` 任何东西。
你的用户名和密码就是 `attendee` 加上你的编号。编号 160 及以下的去第一个链接，201 及以上的去第二个链接。

另外，请打开 `browser.neo4j.io/preview` 这个链接。稍后我会告诉你，你也要登录那个，这样当我们开始往里面放数据时，你就能更好地可视化图。

一旦你进入了你的环境，我希望你执行这两条命令。你可以在 Jupyter 中打开一个终端窗口，按那个小加号就行。我希望你 `git clone`，这个命令应该在 `README` 文件里，它会给你需要克隆的仓库链接。完成之后，我希望你把那个 `ws.env` 环境文件复制到 `genai-workshop-talent` 文件夹里。这个文件包含了连接到一个已经设置好的数据库的信息，里面还有一个我们工作坊要用的 OpenAI key。

这个 `browser.neo4j.io/preview` 链接，能让你可视化图。当你看到一个连接界面时，那个 `ws.env` 文件里会有你的用户名和密码，对你们来说应该也是 `attendee` 加上你的编号。请确保完成这一步，因为这样你才能更好地可视化图。

## 什么是 GraphRAG？

在大家设置的时候，我先简单讲讲什么是 GraphRAG，来引出我们要做的事情。

这是一个架构，代表了我们一些客户正在做的事情，是 GraphRAG 用户一个非常常见的通用架构。基本上，左边是你的智能体、AI 模型和 UI，这些都是你构建一个知识助手时会想到的常规东西。但中间有一个“知识图谱”。你可以把非结构化数据（如文档、PDF）和结构化数据（如 CSV 表格、关系型数据库数据）都录入到这个知识图谱里。

那么问题来了，我们为什么需要中间这个知识图谱呢？我们有智能体，可以有工具，可以从数据源里拿东西。这里的想法是，如果你有一个使用场景，并且你大概知道你想让智能体回答什么类型的问题，通过把你的数据分解成一个（哪怕是简单的）知识图谱，你就能通过你的数据模型，暴露出很多你想应用的领域逻辑。

当我们构建一个技能图谱时，我们会建立关于“人”掌握“技能”的关系。通过把这个模式（schema）和相应的工具提供给智能体，你将能更好地控制数据如何被检索，更准确地解释检索逻辑。我们认为这在迈向智能体世界的过程中尤其重要，因为它不再是一次性的向量搜索。当问题或提示被交给一个智能体工作流时，它们会被以各种方式分解。而当你有一个知识图谱时，它能让你以一种更简单、在我看来也更好的方式，提供检索逻辑来辅助这个过程。

今天，我们将关注一个技能和员工图谱。我们要看的用例是，你正在构建一个知识助手，来帮助完成诸如人才搜索、组织内技能对齐与分析、人员配置、团队组建和替换等任务。

## 模块一：图基础知识

我们先从一些结构化数据开始，简单点。稍后我会介绍非结构化数据。我们会讲一些基础的 Cipher 查询、一些算法，以及一些向量搜索和语义相关的东西。

知识图谱，通常被定义为一种组织和访问相互关联数据的设计模式。在 Neo4j，我们用所谓的“属性图”（Property Graph）来建模数据库中的数据。它包含三个主要元素：
1.  **节点（Nodes）**：就像你的名词，比如人、地点、事物。
2.  **关系（Relationships）**：表示事物之间是如何关联的，通常是动词。比如“人-认识-人”、“人-住在-某个地方”、“人-拥有一辆-车”。
3.  **属性（Properties）**：节点和关系都可以有属性，就是一些附加信息，可以是字符串、数字、数组，也可以是向量。

我们用来访问数据库的查询语言叫做 **Cipher**。我知道很多人举手表示熟悉，但对于不熟悉的，Cipher 看起来有点像 ASCII 艺术。它的感觉有点像 SQL，但你可以写出像 `MATCH (person)-[:KNOWS]->(skill)` 这样的语句。基本上，你正在通过一个 `KNOWS` 关系连接一个 `Person` 节点和一个 `Skill` 节点。它的读法和写法非常直观。

节点有“标签”（Label），类似于 SQL 数据库里的表名，表示实体的类型。它们还有属性，比如你可以通过 `name` 属性来识别。你还可以用像 `p` 和 `s` 这样的变量来在查询中引用实体。

我们今天不打算深入讲解如何写 Cipher，但我们会逐步讲解这些查询，所以希望你能对它如何工作以及返回什么样的数据有个基本感觉。

我相信在座各位对向量搜索都很熟悉了。我们都知道嵌入（embeddings）是什么，它是一种数据压缩方式，可以应用在文本、音频，甚至图上。它通常是一个数字向量，你可以用它来在那个领域空间里寻找相似的东西，比如寻找语义上相似的文本。

在 Neo4j 中，你有包括向量在内的多种搜索索引。你可以进行文本搜索，我们也有近似最近邻（ANN）向量搜索，我们将会把它和我们刚才看到的 Cipher 查询结合起来，进行图遍历。

另外，除了查询数据库，我们还有分析功能。我们有基于数据库的图分析能力，可以让你做不同类型的数据丰富化和更全局的图分析。比如，找到根据不同算法最中心的节点、做社区检测来聚类图、寻找节点间的路径、做不同类型的嵌入等等。我们今天会在第一个模块非常简要地触及这些算法。

好了，带着这些概念，我们进入第一个 notebook。

### Notebook 1：实践操作

我们从加载一个技能数据集开始，这是一个表格，有三个字段：邮箱、姓名和这个人的技能列表。

后面有一些步骤是整理数据以便加载。然后我们开始创建我们的图。我们会先创建一个约束（constraint），这非常重要。我们在这里说，对于所有的 `Person` 节点，`email` 属性必须是唯一的且非空。这会让基于 email 匹配人和进行合并操作变得非常快。很多人说 Neo4j 慢，通常就是因为没设置约束这样的简单错误。我们对 `Skill` 也做同样的操作。

之后，我们开始加载我们的节点和关系。这里的查询逻辑是：我们遍历数据，对于每条数据，`MERGE` 一个 `Person` 节点（基于 email），设置他的名字；然后对于他的技能列表，`MERGE` 一个 `Skill` 节点（基于技能名），最后 `MERGE` 一个 `(person)-[:KNOWS]->(skill)` 的关系。

运行之后，你可以在浏览器里看到你的数据。比如，你可以 `MATCH (p:Person)` 看到所有的人物节点。你也可以匹配路径，比如 `MATCH p = ()-[]-() RETURN p LIMIT 25`，这会返回一个图，让你看到各种关系，比如某个人 `KNOWS` API Design、Tableau、Flask 等技能。

（观众提问：这里的 KNOWS 是我们自己编的关系类型吗？）
是的，这是我们自己定义的数据模型的一部分。我们的模型是 `(Person)-[:KNOWS]->(Skill)`。你也可以叫它 `HAS_SKILL`。你使用的语言实际上也像是给大语言模型的一个注解，这变得越来越重要。

接下来我们看一些 Cipher 查询。比如，我们可以统计每个技能有多少人掌握。我们可以问一些多跳（multi-hop）问题，这很有趣。例如，我们可以找到一个叫 Lucy 的人，并问哪些人跟她在技能方面比较相似。查询会找到 Lucy，她掌握的所有技能，以及所有其他掌握这些相同技能的人。我们还可以进一步扩展，找出这些相似的人还掌握哪些其他技能。这会返回一个非常大的图。但重点是，一旦我们有了这个逻辑，我们就能以更精细的方式控制我们如何定义“相似的人”，因为我们可以在图上遍历。

（观众提问：大语言模型在生成 Cipher 查询方面表现如何？）
它们正在变得越来越好。这很大程度上取决于你模式的复杂性。对于简单的聚合查询或经过大量提示工程优化的特定路径查询，它们表现不错。但我们通常建议，如果你有非常复杂的遍历逻辑，最好还是有自己的专家工具，比如自己写 Python 函数。

为了加速查询，我们可以创建一个 `SIMILAR_SKILL_SET` 关系。如果我们知道我们经常要查找相似的技能集，我们可以预先计算两个人技能的重叠数量，并创建一个关系来存储它。这样就不必每次都做完整的遍历。

接下来，我想展示一下我们的图分析功能。我们使用一个叫做 Leiden 的算法来进行社区检测。这个算法会把图分解成层次化的社区，它试图优化一个叫做“模块度”的指标，目标是创建内部连接紧密、跨社区连接稀疏的集群。我们基于 `SIMILAR_SKILL_SET` 关系运行这个算法，得到的结果是一堆社区，反映了社区内的人们都掌握着相似的技能。运行完后，我们会把社区 ID 写回图谱。通过一个热力图，我们可以看到每个社区中最主要的技能是什么。这在现实数据中可以帮你发现你的数据工程师团队、前端团队和机器学习团队等。

除了社区检测，我们还可以通过语义相似性来思考技能间的关系。我们可以为我们的技能创建嵌入（embeddings）。我们有一个文件，包含了技能、技能的描述以及嵌入。我们嵌入的是描述而不是简短的技能名（比如 'R' 或 'AWS'），因为描述能提供更丰富的信息。

然后，我们在 Neo4j 中创建一个向量索引。设置好之后，我们就能在图上对技能进行向量搜索。比如，我搜索和 'Python' 相似的技能，它会返回像 Ruby、Java、Pandas、PyTorch 等。更有趣的是，我可以搜索一个数据库里没有的词，比如 'API coding'，它会通过嵌入找到语义上相似的技能，如 'API design' 和 'JavaScript'。

我还可以利用这种相似性，在图中创建一个 `SIMILAR_SEMANTIC` 关系，并附上一个相似度得分。这样做的一大好处是可视化和聚类。当我在浏览器中展示所有通过 `SIMILAR_SEMANTIC` 连接的技能时，你会看到一些有趣的集群：云技能（Azure, AWS）聚在一起，数据分析工具（Tableau, PowerBI）聚在一起，JVM 语言（Java, Scala）聚在一起。可视化相似性的能力非常强大。而且，如果我认为比如 Java 不应该和 Python 连接，我可以控制它，移除那个关系。

最后，图数据库的一个特别优势是你可以做变长查询。比如，我可以查找两个人之间的相似性，并允许在技能之间通过 `SIMILAR_SEMANTIC` 关系进行最多两跳的连接。这让你能控制在寻找相似性时可以“走”多远。

## 模块二：处理非结构化数据

我们刚刚看到了使用图和语义相似性的优势，现在我们来谈谈第二个模块。如果我们只有简历，而不是 CSV 文件呢？

这个例子会展示如何从文本中提取数据并放入图中。我们这里有两个人的简介文本。方法是，我们可以用 Pydantic 类来定义我们的领域模型。这里，我定义了一个 `Person`，包含姓名、邮箱和技能列表。

然后，我们创建一个系统消息作为模型的提示，用 GPT-4 来处理这些文档，它会输出包含这两个人的信息的 JSON，包括他们的邮箱和技能。

一旦我们有了这个 JSON，加载它到图里就和上次很类似了。我们遍历每个人，`MERGE` 他们的节点，然后 `MERGE` 他们掌握的技能以及他们之间的 `KNOWS` 关系。

这是一个非常简单的例子。我们有自己的 GraphRAG Python 包，以及一个知识图谱构建器的参考 UI，里面有更复杂的例子，比如带重叠的文档分块、多线程处理等。

（观众提问：我们刚添加了新数据，需要重新运行之前的社区检测和关系创建吗？）
是的，理想情况下，我会先做这个提取步骤，然后再进行聚类和物化新关系。因为我添加了新的人和可能新的技能，所以像 `HAS_SIMILAR_SKILL_SET` 这样的关系需要重新计算，社区也需要重新划分。

## 模块三：构建一个智能体

现在我们进入第三个模块。我们将构建一个非常简单的 LangGraph 智能体。

我们要创建四个工具：
1.  检索一个人的技能。
2.  检索与其他技能相似的技能。
3.  查找与某人相似的人。
4.  根据一组技能检索人员。

这些工具的背后都是我们之前已经讨论过的图查询模式。

*   **工具一（检索技能）**：一个简单的 `(person)-[:KNOWS]->(skill)` 查询。
*   **工具二（查找相似技能）**：我们会使用向量索引和 `SIMILAR_SEMANTIC` 关系。
*   **工具三（查找相似的人）**：这个工具会使用我们之前创建的社区信息，或者那个计算了硬性技能重叠和语义相似性加权的复杂查询。
*   **工具四（根据技能找人）**：入口点是向量搜索，找到语义相似的技能，然后遍历找到掌握这些技能的人。

我们将这些逻辑封装成函数。然后，我们设置智能体。我们使用 LangGraph 的 `create_react_agent`，给它我们的 LLM 和这四个工具。

设置好之后，我们就可以和它互动了。比如我问：“Kristoff 有哪些技能？”智能体会选择并调用“检索个人技能”的工具来回答。如果我问：“哪些技能和 PowerBI、数据可视化相似？”它会选择“查找相似技能”的工具。如果我问：“谁和 John Garcia 的技能相似？”它会知道需要调用“查找相似的人”的工具。

所以，我们在这里做的是提供一堆我们认为是“专家”的工具给模型，然后模型会根据问题去选择合适的工具来提供答案。

在 notebook 的最后，还有一个文本到 Cipher 的例子。这里我展示了如何把一个带注释的 schema 传递给模型。我为 schema 提供了描述，然后让 LLM 自己生成 Cipher 查询。比如，我问它“描述一下社区”，它能够理解需要匹配 `(person)-[:KNOWS]->(skill)`，并获取 Leiden 社区信息，从而生成正确的 Cipher 查询。

## 总结与资源

我知道我讲得很快，我们时间不多了。

（观众提问：Jupyter 服务器会开多久？）
服务器很快就会关闭。但是在演示文稿的最后，我有一个指向代码的链接，数据也都在 GitHub 上。你可以用我们的 Neo4j Aura 云服务，我们有免费试用，你可以设置一个云数据库然后把数据加载进去。

另外，今晚5点有一个 Meetup。我们还有一个工作坊在今天下午1点，会更深入地讲解图分析相关的内容。

如果还有其他问题，欢迎来我们的展位。在那里你可以看到 Neo4j、LangChain 服务器、ADK 示例以及更多关于知识图谱构建的内容。非常感谢大家！
