# AI Ascent

你们都知道吴恩达（Andrew Ng）是一位著名的计算机科学教授，在斯坦福大学任教。他很早就参与了利用 GPU 进行神经网络的开发。当然，他也是 Coursera 的创始人和 deeplearning.ai 等热门课程的创建者。同时，他还是 Google Brain 的创始人和早期领导者。

不过，在你上台之前，有一件事我一直想问你，吴教授。这个问题我想对在座的所有人都很有意义。十年前，在 CS 229 课程的第二份问题集中，你给了我一个 B。

我回头看了看，想知道你当时觉得我哪里做得不对。

开个玩笑，欢迎吴教授。

# 智能体推理

谢谢你，康斯坦丁。我很高兴能和大家分享我对 AI 智能体的一些看法，我认为这是一个激动人心的趋势，每个从事 AI 开发的人都应该关注。

## 什么是基于LLM的智能体？

今天，我们大多数人使用大语言模型（LLM）的方式是这样的：采用一种非智能体的工作流程，你输入一个提示，它就生成一个答案。这有点像你让一个人写一篇关于某个主题的文章，然后你对他说：“请坐到键盘前，从头到尾一次性把文章打出来，不许用退格键。” 尽管这很难，但 LLM 却能出色地完成。

相比之下，智能体的工作流程可能看起来是这样的：让 AI 先写一个文章大纲。然后问，是否需要进行网络搜索？如果需要，就去搜索。接着，写出初稿。然后，AI 会阅读自己的初稿，思考哪些部分需要修改或进一步研究。最后，修改草稿，如此反复。

这个工作流程更具迭代性，你可能会让 LLM 进行一些思考，然后修改它的文章，再进行更多思考，如此循环往复。很多人没有意识到的是，这种方式能带来显著更好的结果。

## 编码基准测试 (HumanEval)

让我们来看一个案例研究。我的团队分析了一些数据，使用的是一个由 OpenAI 几年前发布的名为 HumanEval 的编码基准测试。这个基准测试包含一些编码问题，比如：“给定一个非空的整数列表，返回所有偶数位置上的奇数元素的总和。”

如今，我们很多人会使用“零样本提示”（zero-shot prompting），也就是我们告诉 AI：“写代码”，然后就期望它一次成功。但没有人是这样写代码的，对吧？

事实证明，如果你使用 GPT-3.5 进行零样本提示，它能答对 48%。而 GPT-4 则要好得多，能达到 67%。

但是，如果你围绕 GPT-3.5 构建一个智能体工作流程，它的表现实际上会超过 GPT-4。如果你再围绕 GPT-4 构建这种工作流程，它的表现也会非常好。

你会发现，带有智能体工作流程的 GPT-3.5 实际上胜过了（没有该流程的）GPT-4。我认为这对我们如何构建应用程序有着重要的影响。

## 智能体推理的设计模式

“智能体”这个词被广泛使用，有很多咨询报告都在谈论智能体是 AI 的未来等等。我想更具体地分享一下我所看到的智能体中的一些通用设计模式。

1.  **反思 (Reflection)**
2.  **工具使用 (Tool use)**
3.  **规划 (Planning)**
4.  **多智能体协作 (Multi-agent collaboration)**

我认为前两种是相当成熟的技术。当我使用它们时，几乎总能让它们很好地工作。而规划和多智能体协作，我认为是新兴技术。当我使用它们时，有时它们的效果会让我惊叹不已，但至少在目前，我感觉还不能保证它们每次都能可靠地工作。

### 1. 反思 (Reflection)

我们来看一个例子。假设我让一个系统“为我给定的任务编写代码”，那么一个编码智能体（也就是一个 LLM）可能会写出类似 `def do_task(x)` 这样的函数。

自我反思的一个例子是，你接着用这样的提示来引导 LLM：“这是为某个任务编写的代码，请仔细检查代码的正确性、风格和效率，并就如何改进它给出建设性的批评。” 事实证明，同一个你用来写代码的 LLM，也许能发现像“第 5 行有个 bug，修复它……”这样的问题。或者如果它运行了单元测试并失败了，它可能会说：“单元测试 3 失败了，尝试修改……”

这种自我反思的模式，让 AI 对自己的输出进行迭代，通常能带来更好的结果。

### 2. 工具使用 (Tool use)

第二个设计模式是工具使用。你们中的许多人可能已经见过基于 LLM 的系统使用工具。左边是 Copilot 的截图，右边是我从 GPT-4 中提取的内容。但如今的 LLM，如果你问它“哪种咖啡机最好？”，它会进行网络搜索。对于某些问题，LLM 会生成并运行代码。

事实证明，有各种各样的工具被广泛使用，用于分析、研究、提高生产力或处理图像。

### 3. 规划 (Planning)

对于那些还没有怎么接触过规划算法的人，我觉得很多人都有过那种“ChatGPT 时刻”，当你惊叹道：“哇，从没见过这样的东西”。我认为如果你还没用过规划算法，你可能会经历一个“AI 智能体”的惊叹时刻。

这里有一个例子，改编自一篇关于 HuggingGPT 的论文。你请求：“请生成一张女孩在读书的图片，她的姿势要和 `example.jpg` 图片中的男孩一样，然后用你的声音描述这张新图片。”

如今的 AI 智能体可以决定，第一步是确定男孩的姿势，在 Hugging Face 上找到合适的模型来提取姿势。接下来，需要找到一个“姿势到图像”的模型来合成女孩的图片，并遵循指令。然后使用“图像到文本”模型，最后使用“文本到语音”模型。如今我们已经有了能够做到这些的智能体。

### 4. 多智能体协作 (Multi-agent collaboration)

最后一个设计模式是多智能体协作。这听起来有点滑稽，但效果比你想象的要好得多。

左边是来自一篇名为 ChatDev 的论文的截图，这是一个开源项目。你可能会在社交媒体上看到过一些炫酷的演示，比如 Devin。ChatDev 是一个多智能体系统的例子，你通过提示让一个 LLM 有时扮演软件公司的 CEO，有时扮演设计师，有时扮演产品经理，有时扮演测试员。这些由 LLM 扮演的不同角色的“智能体”会进行协作，展开深入的对话，如果你告诉它“开发一个五子棋游戏”，它们真的会花几分钟时间写代码、测试、迭代，并生成一个复杂得惊人的程序。

另一个设计模式是“多智能体辩论”。让不同的智能体，比如让 ChatGPT 和 Gemini 互相辩论，实际上也能带来更好的性能。

## 结论

我认为这些智能体推理的设计模式将会非常重要。

*   由于智能体工作流程的出现，AI 能完成的任务集合将急剧扩展。
*   我们将不得不习惯于将任务委派给 AI 智能体，并耐心等待回应。
*   快速的 token 生成很重要。即使是质量稍差的 LLM，如果能生成更多 token，也能在迭代中产生好的结果。
*   如果你正期待着用 GPT-5、Claude 4 或 Gemini 2.0（以零样本方式）来运行你的应用，你可能已经可以通过在早期模型上使用智能体推理来获得相似的性能。

我真心认为这是一个重要的趋势。通往通用人工智能（AGI）的道路感觉更像是一段旅程，而不是一个终点，而我认为这种智能体工作流程可以帮助我们在这段漫长的旅程中迈出一小步。

谢谢大家。
