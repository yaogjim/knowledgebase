### 案例研究 + 深度解析：使用 LangGraph/MCP 的远程医疗支持代理

[音乐]

好的，嗯，大家好，非常感谢大家的到来。真的很高兴你们能在这里。嗯，这是一个很棒的展会，我喜欢这个展会。嗯，我去年是作为一名与会者来的。嗯，二月份在纽约的峰会上也发了言，我真的很高兴能再次回来。嗯，所以这次主要是来做一次演示和讲解。我我在 Slack 频道里也说了，所以如果有人还没加入 Slack 频道，欢迎加入。里面有几个链接可能对你有帮助。嗯，那个频道叫 workshop Langraph MCP agents，如果有人需要的话。嗯，但基本上，嗯，我今天就是来介绍一些我团队一直在做的非常有趣的工作，主要是围绕为医疗保健用例构建代理工作流。嗯，这很大程度上是我们做事的方式。嗯，我会详细介绍一些细节，但这不是唯一的方法。嗯，我希望在座的某位观众可能会看着这个说：“这太蠢了，你应该做得更好。”到时请举手告诉我。嗯，但是，但是构建这个过程真的很有趣，我对结果非常非常满意。而且，我真的很兴奋能向大家展示这到底是怎么回事。嗯，好的。那么我将进入演示模式。好了，我们开始吧。

### 关于Stride咨询公司

好的。呃，首先，关于 Stride 的几件简短的事情。嗯，那是我，如果有人需要我的 LinkedIn 的话，不过在其他几个地方也能找到。嗯，我们是一家定制软件咨询公司。嗯，这在实践中意味着，呃，无论你需要什么，我们都会为你构建。我们一直在做大量的 AI 工作。嗯，这大概可以分为几个特定的领域。嗯，我们用很多 AI 来生成代码。嗯，我们有一些产品和服务是用来做比如单元测试的创建和维护。我们还做了一些关于非常老旧、愚蠢的代码库的现代化改造。嗯，你知道，比如，呃，2000 年代初期的 .net 代码是我们专长的领域之一。嗯，但今天我要向大家展示的，主要是我们围绕代理工作流所做的工作。所以，你知道，这个代理工作流的核心思想其实就是，它本可以用传统软件来完成，而且我将要展示的这个东西，在它的第一个版本中就是用传统软件做的。嗯，但我们用一个 LLM 作为核心重构了它，使其更灵活、更强大，并且，你知道，最终，嗯，也酷得多。嗯，所以，真的很高兴向大家展示更多相关内容。

### 演讲大纲

所以，我将从一些背景介绍开始。嗯，我将做一个案例研究，嗯，会很简短，但能让你们了解我们试图解决的问题，以及我认为我们解决得有多好。嗯，然后我们会在它的工作原理方面，根据大家的意愿进行深入探讨。嗯，我想先问一下，如果你们有问题，请举手。我会尽量注意到并回答你们。嗯，我们有一些麦克风可以传递。嗯，但可能你们直接大声喊出来更好，然后我会对着我的麦克风重复一遍。嗯，而且基本上，我也不知道这是否足够讲两个小时，可能够吧，但请大家帮我把握时间。嗯，我会谈论任何与此相关、大家想谈论的话题。

### 案例背景：Aila Science与远程医疗

所以，嗯，这里的客户是 Aila。Aila Science 是一家关注女性健康的，嗯，机构，致力于帮助治疗早期妊娠丢失，嗯，也就是通常所说的流产。嗯，但这具体是一种治疗方法，情况是这样的：你经历了这件事，你最终去了医院或诊所，他们让你带着药回家，对吧，这个药是你必须自己服用的，嗯，而且是在一个对你和你的家人来说都非常痛苦的时刻，在一个你需要记住什么时候该做什么事情的时候。这可能真的很有挑战性。嗯，除此之外还有其他用例，比如化疗，当人们连今天是几号都记不清时，更不用说他们应该做什么了，对吧？你知道，有各种各样的治疗都与此相关。嗯，但 AILA 特别有一套系统，他们用它来帮助人们基本上在家中执行这些远程医疗方案，对吧？而且，那个系统是基于短信的。所以我接下来要展示的所有东西，本质上都是一个基于短信的引擎，带有一些核心业务逻辑，嗯，它帮助人们保持在正轨上，回答他们的问题，关心他们，你知道，确保治疗进展顺利。他们仍然有医患关系，这并不是要取代医生，它只是在大部分时间里，在没有医生直接支持的情况下，帮助人们完成这种治疗。

### 免责声明与方法论

嗯，所以，首先有几个免责声明。第一，我将向你们展示的一大堆东西，都是客户的实际代码。嗯，非常感谢我的客户，感谢 Aila如此开放地分享这些。这真的很棒，我很高兴能向你们展示这么多内容。嗯，我删减了一些东西。嗯，我认为剩下的部分仍然能让你们很好地了解整个事情的特点和它的工作原理。

嗯，Stride，我们是做定制软件的。所以我们构建了定制软件。我我不想隐藏这一点，对吧？很多这类事情可以用现成的工具来完成。嗯，但这个客户有一些特定的需求，坦白说，这使得很多部分最好是定制构建。嗯，所以我们这么做了。但我们尽力使用了，你知道，大块的现成工具，对吧？所以你会看到很多Langraph、Langchain、Lang Smith，你知道，还有很多类似的东西，都在这里，因为我们确实相信这能增加价值，并且它从根本上使系统更具可解释性。嗯，而且，你知道，在托管方式上也有一些限制。这，你知道，至少部分与患者数据以及各种像 HIPAA 和其他隐私要求相关。

嗯，另一件事，就像我之前开始说的，没有绝对正确的方法来做这件事，但我们这个方法确实有效，而且我认为当你看到我们逐步讲解时，你会看到我们做出的一些选择。嗯，你知道，肯定有其他方法可以把这些工具组合在一起。我认为肯定有其他方式可以实现这个工作流。嗯，但是我们喜欢最后的结果，它保留了一些我们知道对客户非常重要的东西，并保留了，你知道，很多人类判断，而不是完全相信那些元素的话。这是一个非常混合的系统，人类在其中扮演着非常重要的角色。

嗯，再提一次，就像我之前提到的，嗯，如果你们看了我们在这里做的事情，然后说那太蠢了，或者说，你有没有想过这个，我会非常乐意。因为，你知道，这是一个我们只工作了几个月的项目，但，你知道，事情已经发生了变化，AI 领域就是这样。所以我确定，而且我知道有几件事，你知道，我们可以用更新、更现代的选择来替换我们做出的某些决定。嗯，同时，你知道，可能有些情况下，我我真的没有正确使用 LangGraph。如果有人举手告诉我，我会非常高兴。所以请务必，嗯，在你们脑子里记着这一点。

### 技术栈与团队

好的。嗯，简单说一下我们使用的技术栈和我们建立的团队。

所以，第一件事，再说一次，这里面有很多 LangChain。嗯，那不是因为其他框架做不到这个。也不是因为我们不能自己构建。我们选择这个的首要原因是因为它向其他人解释这个系统有多么容易，对吧？你知道，如果你看看，我稍后会展示 Langraph 的东西，它真的很直观，可以在项目很早期就去跟客户说，“嘿，这个东西是这么工作的。你可以看到它从这里到这里，这里有循环。像这里，我们正在做我们的，嗯，你知道，流程评估，这里是人类介入的地方。”这样做非常直接。嗯，而且我认为如果用一些不那么可视化、坦白说组织得不那么好的东西，会困难得多。所以，所以我们对这个选择很满意，对吧？LangChain 工具确实有一些权衡，但它们大多是我们能够接受的。

嗯，在我将要展示的例子中，我们使用的是 Claude。嗯，但是我们编写的核心代码也适用于 Gemini 和 OpenAI。嗯，我们认为 Claude 在这方面更好有几个原因，我们后面会谈到。但，你知道，这里并没有什么模型特定的东西。这几乎全是工具调用和 MCP，以及，你知道，其他在大多数模型中都相当可移植的东西。

嗯，整个技术栈不仅仅是 LLM 部分，对吧？LLM 部分是 Python 和一个 LangGraph 容器。嗯，然后，另一部分，也就是短信网关、数据库和一个我将详细展示的仪表盘，是 Node、React、MongoDB 和 Twilio。整个系统托管在 AWS 上。这些都不是必须的，只是我们的选择。嗯，你知道，我们选择 AWS 的主要原因是为了，你知道，这需要支持多个不同地区。我们必须能够在欧洲的几个地方完全部署，对吧？所以我们需要确保我们有，你知道，一套不错的云连接，可以与之合作。

呃，评估。所以，我会展示我们构建的评估系统。嗯，我们没能使用，或者至少我应该说不是没能使用，我们选择不完全使用 Langsmith 的现成工具。这部分是因为我不太想完全被他们锁定。我希望数据能存放在那里，我希望能看到，你知道，当前系统在 Langsmith 中的情况，但我想要一个独立的东西。事实证明，我们为了让评估，嗯，你知道，从根本上可用，需要做大量的预处理。所以我们构建了一个外部的工具集，它基本上从 Langsmith 拉取数据，进行处理，然后通过 PromptFu 运行。嗯，而且我们选择 Prompt Fu 的一个原因，如果有人用过的话，嗯，他们有一个非常灵活的，他们称之为 LLM 评估标准（rubric）。而且，这是一个 LLM 作为评判者，你基本上描述你希望评估如何工作。嗯，你把数据喂进去，然后，你知道，它会给你一个独立的、可视化的结果。所以我们最终对它非常满意。这绝不是唯一的方法。这绝对是，你知道，最适合我们的方式。

呃，团队。所以，曾经有，而且现在仍然有，嗯，两位软件工程师，一位设计师，嗯，还有我。我我不会称自己为软件工程师，所以我没把自己算在那个群体里。你可以想象有两位软件工程师维护着包含网关、仪表盘和短信等功能的核心系统，以及数据库。嗯，我维护并基本上构建了 Langraph 侧的所有东西，对吧？所以想象一下这是两个独立的系统，它们通过一个定义良好的契约相互通信。嗯，那两位软件工程师大致了解我的代码如何工作，但他们并不真的维护它。你知道，几乎完全是我，加上 AI 朋友们。

嗯，关于这一点，所以我要展示的所有东西都是我写的代码，而且我想说清楚。嗯，我已经很久没当真正的软件工程师了。我确实有工程背景，我花了大学毕业后的七年时间，你知道，捣鼓移动应用。嗯，我休息了 15 年，去做产品经理，大约两年前我回来了。但这真正意味着的只是，你知道，基本上你看到的这些东西，或者我将要展示的东西，主要都是，你知道，我用 Klein 写的代码。那是我个人最喜欢的。嗯，所以这里有很多选择，我最喜欢 Klein。嗯，你可以用任何你想要的。代码其实并不那么复杂。我想估算一下，我实际上没数过，但大概有几千行 Python 代码，还有几千行的提示词。它它大概是相等的，对吧？所以我用“凭感觉编码”的方式写了 Python，而提示词则主要是手写的。嗯，不是 100% 对吧，但但这就是思考这里分工的方式。嗯，而且就此而言，我的意思是任何这些工具都可以很棒。我选择 Klein 的主要原因只是因为，你知道，我们不需要一个，你知道，高度优化的，嗯，比如每月 20 美元的流程。我在 token 上的花费远不止每月 20 美元。这就是现实。嗯，你知道，花钱来获得模型在任何给定点的最佳可用上下文是值得的。嗯，Klein 是一个很好的方式来做到这一点。好的。这里还有一些示例代码。所以我确实提到了，这也在 Slack 频道里。如果你想跟着做，你可以通过建立你自己的小型 Langraph 容器和 MCP 来实现。非常欢迎你这样做。嗯，不过我将要展示的所有东西都是专有的客户代码，所以我显然不能把那些链接发给你们。所以如果你想，嗯，随时可以启动它。嗯，我们有两个小时，这是一段很长的时间。如果如果你们有兴趣在最后花点时间，实际操作一下这些真实的代码，我我非常乐意。这样做。嗯，所以，请随时在此期间做好准备。

### 核心概念

好的，首先说几件事，只是为了确保我们在术语和我们讨论这些东西的方式上达成共识。所以，嗯，我确实喜欢 LangChain 这里对代理（agent）的定义。嗯，基本上只是因为，你知道，你会看到我们在这里做的是用一个 LLM 来控制这个应用的流程，对吧？这确实就是它的本质。嗯，我喜欢这个，我不知道 Chris 是不是在这里，他上次在纽约的活动上出现过。我喜欢用这个来解释我们试图构建这个系统架构的方式和原因，对吧？所以，生产环境中的代理这个概念，对吧，你必须知道它们在做什么，你必须知道，你知道，它们能做到，而且你必须能够引导，对吧？如果你只有其中几项，你最终会得到不好的结果，对吧？所以我我就是喜欢这个框架：如果你有能力，但你不知道它在做什么，那它就是危险的。如果你确切知道它在做什么，但你无法控制它，它就会做些奇怪的事情，而你帮不上忙。

呃，请继续。我们很多人都在找那个 Slack 频道。
哦，呃，让我再找一下。其实就在这里：workshop langraph MCP agents。
好的。没问题。

好的，但是，呃，所以，透明而无控制是令人沮沮丧的，而有控制而无能力是无用的。我我就是喜欢这个框架，我认为这正是我们试图解决的问题。我们需要一个能够胜任工作、清楚自己在做什么，并且能够以一种非常明显的方式被人类引导的东西。

### 案例研究：成果与影响

所以，嗯，话虽如此，我将从一个案例研究开始，对吧？这在脱离上下文的情况下会有点奇怪，但希望这能让你们了解我们试图解决的问题。所以这里的想法是，有一个现有的产品，对吧？所以当时有一个产品，它基本上是让人类手动在一个控制台上按按钮，这样就可以发送一条短信，对吧？所以你会读患者说了什么，他们可能会说“我下午3点吃了药”，也可能说“我正在流血，不知道发生了什么，我还好吗？”，他们可能会问关于治疗的其他问题，然后一个人必须进入一个软件，点击一个按钮，这个按钮能准确反映出某人在工作流程中的位置，对吧？因为，你知道，你可以把很多这些都模型化，想象一下有非常复杂的流程图，描绘了医疗治疗期间可能发生的所有事情。嗯，所以 AIA 团队已经构建了这个，对吧？但他们意识到，要扩展人力团队以服务更多患者，成本太高了，对吧？他们需要太多的人去按太多的按钮。他们还意识到，他们无法真正将系统扩展到新的治疗方案，对吧？这是他们想做的事情。这并不是唯一需要支持的方案，他们还有其他的。嗯，所以想法是，他们要么重构旧的软件以使其更灵活，要么基本上重构它，以使用一种不同类型的决策核心。而且，当他们考虑这么做时，你知道，LLM 已经开始，我认为变得足够强大，可以处理这类工作。

嗯，所以，我们构建的，我们做的是，我们为他们构建了一个工作流，并且基本上是一个连接到它的软件，使他们能够灵活地进行新的治疗，对吧？所以，这种基本上定义一个蓝图和一个知识库的想法，是我们思考这个问题的方式。嗯，而且基本上是经过医学批准的语言，对吧？所以，你让人类按按钮而不是输入短信的一个原因是，这是医疗建议，对吧？你知道，你你不是，或者至少不应该给出与这种批准语言有实质性差异的医疗建议，对吧？这些东西之所以这么说是有原因的。嗯，你知道，医生们也有类似的限制。嗯，我们还构建了一个自我评估功能，我稍后会详细介绍。呃，我们想确保我们能捕捉到那些复杂的情况，嗯，并把它们呈现给人类，对吧？因为我们希望有人类在环，但我们试图将那些原来只是操作系统的、点击所有那些按钮的人提升为监督这些代理的管理者，对吧？这确实是我们工作的核心模式。

看到那边有个问题。
是的，你可能说过，这些操作员是……
那么，问题是这些操作员是否受过医学培训？有一位医师助理，她基本上领导着运营团队。所以，你可以这样理解，嗯，每当出现超出蓝图范围的事情时，都会上报给她，对吧？所以，如果你遇到一个情况，他们就是说，我真的不确定该怎么做，一个 Slack 消息就会发到那个有医师助理在的频道，然后她会给出医疗建议。所以，你知道，这也是为什么难以扩展的原因之一，对吧？因为，你知道，在这个特定的团队里，你只有一个这样的人。
当然。

嗯，所以，你知道，稍微跳跃一下，但希望你一会能明白为什么会这样。这大概，而且再次，我们仍在进行测量，对吧？我们仍在试图弄清楚确切的，你知道，容量提升了多少。嗯，我们认为大概是 10 倍。我们认为他们用这种新方法大概可以服务 10 倍的人。嗯，现在，这不是免费的，对吧？我们必须构建软件，我们必须支付 token 的费用。嗯，token 会变得很贵。但如果你想想，你知道，扩大一个团队所涉及的规模问题，以及再次，构建软件以使其对更多治疗更灵活，嗯，我们认为这种容量的增加是非常值得的，也是真正解决问题的关键。

嗯，而且你可以做新的治疗和新的工作流程，而无需编写更多代码。对吧？这是这件事最大的亮点。而且，你会看到我们在这里做的，很大程度上是谷歌文档，对吧？而且，你知道，我们有一些更先进的技术来管理这些东西，并随着时间推移进行版本控制，但但我们谈论的是能够支持全新的治疗和全新的工作流程，而无需返回代码，对吧？这对这些人来说非常有价值。

有个问题，你提到了速度，那如何衡量护理质量呢？
所以，问题是速度提高了，是否有护理质量的衡量标准？嗯，简短的回答是，现在还早，对吧？我的意思是，这仍然是一个正在进行中的系统，它正在被真实的人使用，但仍处于非常早期的阶段。我认为我们看待它的方式是，这会是操作员成为最终裁决者的某种组合，对吧？他们将能够看到这些对话，并在他们批准、审查时判断，嘿，这大部分都做对了吗？然后，还有一些现有的，类似于客户满意度（CSAT）的衡量标准，你可以应用到那些在治疗另一端的人身上。
10倍听起来有点低。这是因为操作员现在还没有批准所有出来的东西吗？
呃，所以他们并不是批准所有出来的东西，而且我同意 10 倍有点，它是一个数量级的概念，而不是一个精确的衡量标准，对吧？但我认为在这种情况下，你会看到一些需要批准的案例，对吧？以及为什么。但批准也非常快，对吧？所以我的论点是，你可能每 10 次交流中只看到一次，而当你看到它时，你花费的时间大致和上次只按按钮的时间差不多，对吧？这就是他们已经在做的事情。所以这大概是我们以此为基准的原因。

### 系统架构与工作流

好的，嗯，那么让我们深入了解一下。所以，呃，这是一个 Langraph 中这个样子的快照。我稍后会给你们看真实的东西，而且自从我拍这张照片以来，它实际上有了一点点演变。嗯，但我们在这里真正讨论的是，嗯，今天操作这个系统的人，我们称他们为运营助理。所以这真正做的是引入一个虚拟运营助理，那个运营助理将评估一个与患者的对话交互的状态。嗯，确定什么是最佳的回应，包括，呃，你可能发送的短信，你可能会问的问题，你可能会采取的行动，因为其中一些是关于为该患者维持一个基本的状态，对吧？你知道，你在任何给定的时刻都试图弄清楚，嗯，这个人什么时候吃药，他们什么时候吃了药，嗯，你知道，他们有什么药，嗯，他们那里现在是什么时间，这实际上比你想象的更重要。嗯，所有这些都必须由系统来维护。所以虚拟助理正在做所有这些工作，然后它基本上把它提出的方案，对吧，它基本上想出了我认为我们应该这样做，然后把它传递给一个评估者代理。

有一个实时的 LLM 作为评判者的过程，与我们稍后会讲到的评估（evals）是分开的。但这个实时的 LLM 作为评判者基本上是在说，好的，鉴于刚刚发生的事情，嗯，这是我们对，呃，LLM 认为自己有多正确的评估。嗯，坦白说，这非常具有挑战性。LLM 很难被说服它们在任何事情上是错的。但是，嗯，它也在看复杂性，对吧？所以即使 LLM 认为它做了所有正确的决定，你也可以让它公正地说，“嗯，我改变了这个，我改变了那个，我正在安排一堆消息，这很复杂，也许应该让一个人看看”，对吧？所以这实际上实现起来要容易得多。嗯，而且这两者都在调用工具。这些工具是 MCP 的混合体。嗯，所以这里有两种版本的 MCP。我将向你们展示一种，它基本上只是查看本地文件，这样我就可以向你们展示我环境中的所有东西。嗯，但也有 MCP 通过网络与更大的软件系统通信，并将所有这些东西保存在数据库中，对吧？所以，这是这两种东西的混合。嗯，其余的工具都是关于维护状态的，因为在对话进行中，LLM 需要知道，你知道，基本上，嗯，我做了这个更新和那个更新，这是我正在处理的当前状态，它必须能够实时地操作这些东西。那不是 MCP，那不会进入任何数据库，这完全发生在实时的线程中。然后一旦它完成，它就会被推送出去并基本上保存起来。好的。嗯，再说一遍，我们会深入探讨很多这方面的内容。我确实想花一分钟时间讲讲系统架构，对吧？所以我知道这有点小。

请讲。当你提到系统状态时，我之前听说 L 具有上下文或某种状态对象。你提到你使用了工具。你是在谈论不同的东西还是……
问题是关于状态在 Langraph 中是如何管理的。所以，嗯，简短的回答是，这可能是我做得不那么优化的事情之一，顺便说一句。但是，嗯，在 Langraph 中，有一个状态对象，我们基本上在请求从一个 JSON blob 进来时加载它，对吧？我们在图运行期间让它保持活动状态，它不能被模型直接访问，对吧？至少不是我们这样做的方式，对吧？所以，你实际上会看到，当我们深入研究这个时，你可以在 Lang Smith 中看到所有状态的进入，对吧？我可以看到，嘿，这是整个被加载的东西。我仍然需要在给 Claude 的第一条消息中重复这个，对吧？它实际上并没有出现在，你知道，同一个地方，然后我调用函数，状态会在图运行内部演变，然后当它输出时，是 Python 代码而不是模型，它基本上获取所有这些状态，然后序列化并发送出去。嗯，所以你会看到它是如何工作的，但就像，这通常是我不确定我是否做得对的事情之一。
还有其他问题吗？是的。
有点相关，你现在有一个节点让那个虚拟代理来回调用工具，对吧？是的。我假设你没有将业务逻辑更多地硬编码到单独节点的原因是，你会失去下一次的工作流程。是这个概念吗？
是的。所以问题是为什么基本上虚拟 A 是一个代理，而不是，你知道，一个预编码的，关于如何执行特定治疗的版本。是的，我认为我们保持简单的原因是，我们不希望架构在如何工作方面过于特定于治疗。但你可以想象做，你知道，一组稍小一些的，调整得更好的代理，它们，你知道，负责处理任务中仍然相当通用的元素。我认为这样做不理想的主要原因是缓存。嗯，这是另一个问题，我，你知道，我认为我这样做是对的，但这里有很多变体。嗯，用一个代理或者用一个代理做大部分工作，缓存整个消息流更容易。嗯，我们用的是 Claude，Claude 有非常明确的缓存机制。嗯，每次我切换系统提示时，我认为缓存就会失效。所以从根本上改变代理身份就会导致这种情况。所以那是我们选择那样做的一个原因。这当然不是，你知道，一个硬性规定、永远不变的选择。
呃，这个持续时间是多久？呃，比如我们是说几个月还是多久？比如有多少条消息？
是的。所以，呃，这个用例，早期妊娠丢失，嗯，它通常是一种需要，我想，三天时间才能完成的治疗，大部分时间是这样，然后之后会有一个回访，对吧？所以想象一下，可能在一周内，与该患者的整个互动就结束了，除非他们后来回来只是问问题，对吧？你知道，有些变体是你在六周后做一次妊娠测试，对吧？所以这些都没问题。嗯，消息历史被保留了，但是生成每条消息的计算却没有，或者至少不是在我们行为的状态下。所以就像，你知道，我见过的最复杂的对话大概有 150 条短信。这对于一个人记在脑子里来说很多了，但对于一个 LM 来说不算太糟，对吧？所以，但就是这个级别。

好的。嗯，所以，再次强调这里的界限，对吧？所以，就像我刚才跑题了，顶部的框是我们今天要看的东西，对吧？它实际上是一个 Python 容器，可以本地访问这些蓝图，这个知识库，对吧？我们还在通过网络在这个蓝色容器中维护一些东西。我将要展示的仪表盘就在那里。短信网关也在那里。嗯，而且我认为我们会把很多上下文都移到那里，对吧？蓝图，所有那些东西真的应该存在于更持久的软件容器里。现在它存在于，你知道，离 Python 很近的地方。

### 现场演示

好的。嗯，那么让我们开始吧。嗯，所以我要做的第一件事是，只是为了向你们展示，呃，从高层次上软件是什么样子的。所以，嗯，这再次是，呃，控制台，仪表盘，对吧？运营助理，也就是人类，将要看的东西。嗯，我将在这里展示几样东西，只是为了给你们一个基准，对吧？所以第一件事是这个“需要注意”。当前的系统基本上让这个“需要注意”一直闪烁。每当有任何患者发来短信，这个东西就会响，对吧？你知道，系统里随时有成百上千的患者。所以，这个“需要注意”以前是需要多个人持续盯着的东西，对吧？只是为了确保他们能捕捉到所有信息，以便在合理的时间内发出消息。现在，“需要注意”真的只是，你知道，一次一件事，对吧？如果我在这里看对话，好了，嗯，你可以看到最上面的这个实际上需要回应。我稍后会讲到。但在任何给定的时刻，对吧，这是我的测试环境。你知道，我已经有一些这样的对话已经排队了。如果我点击这些东西，我能看到的是，基本上，我先回到开头，看整个消息历史，然后我会打开这个“理由”开关。

嗯，你看到的是整个对话。这个能看清吗？我放大一点？这样好点了吗？好的。

嗯，所以这里的想法是，呃，代理的名字叫 Ava，对吧？这是人们互动的角色。嗯，这些语言都来自这些蓝图，对吧？我稍后会展示。所以这第一条消息只是系统发送的一条初始消息，基本上就是为了启动一切。所以想象一下，有人手里拿着一包药，他们扫描一个二维码，输入他们的电话号码，然后他们收到了这条短信，对吧？然后他们开始说话。嗯，所以你可以看到，患者会说的东西是，你知道，自由形式的文本，对吧？你知道，我的意思是，他们可以用无数种方式说“是”。旧系统过去有字面上不同的按钮来表示“是”，比如“是的，我有药了”，“是的，我听到了”。我的意思是，有很多种变体，对吧？因为你你确实需要根据那些东西做出不同的回应。我们在这里能做的，真的只是拿走，你知道，这些自由形式的答案，解释它们，然后基本上为你在特定时间说出特定话语提供一个理由，对吧？这相当于，如果你和一个人这样做，你问那个人，嗯，你为什么这么说？LM 可以提供这种上下文。所以这是 Claude 在看这里的历史记录，而且我我会向你展示这在 Langsmith 中是什么样的，这会让它更明显。然后说，好的，这是我接下来应该说的话。而且我对应该说这句话的信心是 100%，对吧？它它通常非常自信，对吧？但重点是，这个整个过程基本上是自动进行的，对吧？你通常不需要人类参与，因为这是一个非常直接的事情。他们有他们的药。我需要知道的下一件事，这是这个治疗中一个非常有趣的部分，我需要知道现在是什么时间。这些是短信。我们出于各种原因对这些人一无所知。我们对他们了解不多，从某种程度上说这是件好事，对吧？我们不想处理所有关于提供者保密和患者数据的事情，对吧？所以，如果我们要进行这种纵向治疗，我们需要的一件事是弄清楚他们那里是什么时间。然后基本上提取这些数据，找出他们的本地时间是什么。对吧？所以在这种情况下，当我回答这些问题时，我在东部时间。这都是我在我的笔记本电脑上做的。嗯，我告诉它现在是什么时间，它计算出一个与 UTC 的偏移量，然后说：“嗯，我猜你在东部时间，对吧？”然后它在这里设置这个，然后说：“好的，从现在开始，我知道我的病人在东部时间，除非他们告诉我别的。”他们可能会回来告诉你别的情况，对吧？这是旧系统真的没有好办法做到的。嗯，但如果病人回来说，“我在飞机上，对我来说其实是七点。”我们就更新时区，然后继续。对吧？这是一个非常灵活的系统。

嗯，然后我们进入这里，说：“好的，现在我知道是什么时间了，我要问他们是否已经开始治疗了？”对吧？而且，你知道，有一个蓝图，对吧？我们稍后会讲到，它基本上就是有，你知道，他们要吃的药，以及一种非常具体的服用方式，对吧？那个方案。病人说：“嗯，不，我想快点吃。”你知道，Ava 说：“酷，我们准备好时我会发短信给你。”然后它给出了一个方案，在这种情况下，这是一个 SVG，我们在上面标注了时间和日期，对吧？所以，你知道，这相当直接，我们是在软件里做的，LLM 没做这个，LLM 实际上只是传递指令，你知道，它说“发送第一步的图片，并提供，你知道，像这个日期和这个时间”，然后我们把剩下的部分替换进去，这会作为一条 MMS 发送出去，对吧？所以，这是一条短信。嗯，所以我们提供了这个，病人，你知道，说，你知道，在这种情况下，我们我们正在讨论，再次，这都是 LLM 在推理通过这个，对吧？你知道，我我立即发送这个，因为它实际上在你告诉我的我必须发送这些东西的 35 分钟窗口内。这都是业务逻辑，LLM 几乎是即时解释的。

嗯，然后我有这些提醒，对吧？我没有回复它。所以这是一个重要的部分。它给我发了这个东西，它以为我会在 5:45 吃药，但我没有回短信，对吧？这部分是因为我自己在维护系统，然后我忘了。所以我不得不在第二天回来补上。嗯，所以它给我发了一个自动提醒，因为它在发送第一条消息时就安排了一个。所以这部分这表明，只有当病人说话时，LLM 才会被调用。所以如果他们不说话，你知道，你必须确保你保持参与，对吧？我们不会过度这样做，我们不会试图打扰人们超过一两个提醒。这是他们的治疗。嗯，但是这种“催促”功能对客户来说非常重要，对吧？所以我们把它内置了。嗯，所以你可以看到，我第二天回来，说：“是的，对不起，我我确实吃了。”你知道，Ava 确认我完成了第一步。它做的是，它设置了一个叫做“锚点”的东西，对吧？它说，好的，你知道，病人本来要在 5:45 吃药，他们确认他们吃了。所以现在，你知道，我可以回溯到这个，我知道这件事发生了，对吧？如果病人然后说，哦不，我搞砸了，我其实还没吃，我今天吃。我们就改变锚点，我们更新一切。对吧？所以这是一个系统，以前需要人类去做。如果一个病人回来说，我没吃药，你知道，一个人必须进去手动更新所有的时间和所有预定的消息。这这真是个大麻烦。

嗯，是的，请讲。
实现这个功能，即病人报告状态，不完全是。我们处理状态的方式，我会花很多时间讲这个，但我们处理状态的方式真的就是，对于来自病人的任何一条消息，对吧，这个整个系统只有在病人发送消息时才会启动。嗯，我们所做的是，我们说，好的，给定这个状态，什么是最好的回应？那个回应可能是，我改变了一些锚点，我更新了他们的治疗阶段，我安排了一堆消息。所有这些状态都被保留下来，这样下次他们写信来时，然后，你知道，我们就有那个状态可以继续。嗯，但再次，我们不检查，对吧？系统里没有轮询在进行，我们不会说3 小时后，病人给我回短信了吗？我们不这么做。我们依赖预定好的消息来提醒病人。嗯，如果他们选择三天不说话，三天后再回来，我们就从上次中断的地方继续。嗯，再说一次，这是一个选择。这是客户想要的方式。它的目的是既足够低调，不会打扰人，又足够高频，不会失去联系。
当然。

嗯，我在这里暂停一下。到目前我讲的，还有其他问题吗？嗯，我意识到我讲了很多。
是的。你的锚点必须是连续的吗？还是你的用户可以在任何时候进来？
他们可以。很好的问题。所以问题是锚点是否必须是连续的或者说，你是否必须一步一步地走完这些步骤？所以，这个系统最棒的一点，最好的事情之一是，我本可以，而且我很高兴我们稍后可以试试这个，我本可以基本上说：“哦，是的，我已经吃了第一颗药了，而且我正在吃第二颗药的中间。”你知道，就像我跟 Ava 说的第一件事。然后她会说：“好的，酷。这里有个锚点，这是下一件事。”它会跳过，而且不会强迫你走完蓝图中规定的那一部分，而旧系统，至少名义上是这样做的，对吧？就像，你可以跳过，但这个是自动的。你知道，部分指令是，不要问病人已经回答过的问题。句号，对吧？但那很烦人，别那么做。嗯，所以，是的，这确实是其中的一部分。
还有其他问题吗？是的。
那个决定一切的内部状态机有没有概念，还是说那部分外包给了实际的软件？
是的。所以问题是 LLM 是否有状态的内部表示。嗯，有点，算是。所以你会看到的，嗯，当我们进入实际与 Claude 的来回交流时，嗯，在 Langsmith 里你作为一个人类，你可以看到它从哪里开始，对吧？所以每个线程都会显示，好的，这是传入的状态，我们基本上对 Claude 重复一遍，那只是一个我一直没能和 Lang Graph 连接起来的点，对吧？所以我们基本上必须序列化状态然后说这是你的，这是你的起点，但然后 LM 在它的窗口里有那个，然后，你知道，它会引起状态的变化，它会调用更新状态的函数，它总可以再问，它可以说，嗯，当前状态是什么？我可以回去然后检索它。嗯，但在那个上下文里，从病人回应开始，你知道，到我实际上想出我的回应给他们，那整个过程都会在它某一刻的记忆里。
你有没有遇到过状态问题？
嗯，所以，简短的回答是，问题是，嗯，我们有没有遇到过状态过大的问题？呃，总的来说，因为我们是在对话结束时进行压缩和序列化，它从来没有变得 настолько大以至于无法完成它对一个情况的回应工作，对吧？你知道，就像，病人说了这个，现在我准备做这个。我们考虑过有更长运行的线程，你可以从中间接上，而且你已经可以重新加载，比如说，整个之前的对话，那确实会变得很奇怪，对吧？特别是用旧版的 Claude，你会发现它会忘记正确调用工具，而且会有各种各样的 JSON 错误，对吧？我们在里面加入了很多重试逻辑来弥补这一点。嗯，所以这是我们保持它简短的一个原因。我们让它在病人回复我们时，基本上扔掉所有东西然后重新开始。部分原因是因为蓝图可能会改变，对吧？很多事情可能会在此期间改变，这可能会导致奇怪的状态。
那么，在管理状态和决定下一步做什么方面呢？是的。所以这是 100% 由 LLM 驱动的，还是有一些软件逻辑在里面？
这是100%由LLM驱动的。呃，抱歉，问题是，转向是由软件完成的吗？任何转向的答案都是，真的不是。嗯，除非它上报给人类，对吧？所以当它需要人类批准时，人类可以用英语说，是的，把那个词改成那个，那条信息不应该发出去，你知道，诸如此类。所以，我们实际上作为灵活性的一部分，我们没有构建任何管理状态的软件，我们只是想让你和LM对话来做这件事，对吧？我们认为那是一个更好的实践，对吧？这意味着，你知道，你作为一个人只需要和它说话，而你不需要弄清楚如何在这个新控制台上操作所有的开关。
你们有任何 RAG 系统吗？第二，如果病人偏离了旅程，你们如何检测到？
抱歉，第一个问题是什么？
你们有任何 RAG 系统吗？或者 Rex？
抱歉，我只听懂了 Retrieval 哦，哦，好的。抱歉。所以，嗯，问题是是否有 RAG。嗯，没有，没有。而且这实际上只是因为我们真正做的就是，我们为文档设计了一种自引用的结构。所以你读一个非常小的文档，上面写着这是治疗方案，对吧？如果你需要阅读这个阶段的内容，就去这个文件，对吧？如果你需要这个阶段的内容，就去这个文件。如果你有一个不属于任何这些类别的问题，这里有一个 CSV 文件，里面有很多问题和答案。我们没有用 RAG 的方式做，部分原因是我们不相信我们能做得很好，把所有正确的信息都放到窗口里。就像，我们不认为我们能做到足够可靠。我们只想给整个文档，它们并不大。嗯，而且因为这是 Claude，对吧？它的窗口足够大，我们可以把整个东西放进去，你知道，对于大多数治疗来说。所以我们选择这样做。
不过，你第二个问题是什么？病人偏离了典型的旅程，你如何检测并拦截，对吧？
所以问题是如果病人偏离了轨道。所以我们有这个蓝图的概念，但有很多情况下，蓝图可能，嗯，你知道，不能完全回答病人提出的任何问题。嗯，比如一个例子是，蓝图主要是关于提问的，对吧？所以你会说，你吃药了吗？你打算什么时候吃药？病人会说，我肚子疼。好的，所以是的，你肚子疼，你没有回答问题。我们所做的是，病人通常会得到他们问题的答案。所以其中一个原则是永远回答病人的问题，对吧？我们绝不想让他们悬着。但然后再问你的问题。所以这个想法是，在任何给定的时刻，我们都可以回答他们需要的任何事情，并且尽可能温和地，我们会尝试把他们拉回到蓝图上，这样我们就能理解他们在治疗中的位置。嗯，这是一门不精确的科学。
但是，呃，有什么方法可以检测到是否有人……
嗯，LM 通过知道它应该让人们保持在蓝图上，但有一个知识库的“逃生舱口”来有效地做到这一点，我们基本上称之为“triage”或“knowledge base”，你可以随意称呼它。嗯，所以，你知道，我们没有一个明确的位在系统中翻转来说这个病人偏离了轨道。我们只是大致知道他们在治疗中的位置，如果他们想回答，如果他们想问一堆问题，我们我们就一直回答，直到他们满意为止。
好的。呃，是的。
是的。是的。所以问题是我们为什么选择 Langchain，以及我们是否还会选择它。嗯，我会非常坦率地说，我选择 Langchain 的主要原因是我个人对 Langraph 已经非常熟悉，把它作为这些概念的一个演示，对吧？并不是说 crew AI——我们早期做了很多 autogen 的工作，对吧？你知道，我也用过一点 crew AI。所有这些框架在功能上都能做非常相似的事情。Langraph 在向那些不深入这个领域的人解释它是如何工作方面，是绝对最好的。嗯，而且因为有一条从那里通往生产环境的路径，我觉得没有必要重新平台化并改变所有东西。我们当然考虑过，对吧？我们想过，如果我们不用 Langraph 做这个，我们会得到什么？但答案是你仍然需要以某种方式实现可观察性。你知道，你不一定能得到，你知道，如果你最终处在一个地方，你可能会从 Langchain 得到支持。记住，我们也是为客户做的，我们不会永远在那里。嗯，给他们留下一些他们可以打电话寻求支持的东西，也是一个有帮助的方面。所以我想我我不会做得不同。我想真的只是，你知道，最终你知道，我们所有人都在被推向使用原生模型工具来做这个，对吧？你知道，OpenAI 有 responses API，可以让你定义工具，Claude 也有它的新东西，对吧？我我不太想被锁定。嗯，我我在某种程度上现在被 LangChain 锁定了，但老实说，我更喜欢那个，而不是被模型锁定。嗯，我们做的这些事情在软件方面不是性能密集型的，对吧？就像，你知道，我不在乎 LangChain 有时有点慢。嗯，我宁愿有选择权。
所以你说你没有使用 scale，那些是怎么……
呃，只是他们有，抱歉，问题是关于如果不是 RAG我们如何获取文档？文档之间相互引用。所以你会看到我们有一个 overview.md，对吧？这都是用 markdown 写的。嗯，有一个 overview.md 告诉你治疗中涉及了哪些其他文档，对吧？有些提示词说，你总是可以请求一个分诊概览（triage overview），对吧？来尝试处理问题。嗯，它就在那里，对吧？不管治疗是什么。所以它非常像一个文档管理的事情。嗯，RAG 的主要问题只是我我不认为，而且，你知道，当我们深入研究时，这可能会更明显，对吧？我不认为你真的能设计一个 RAG，它能以完美相关的方式拉回所有东西的片段。你你真的需要理解整个治疗的形态，对吧？才能做出一个好的决定，对吧？否则你只会鹦鹉学舌地重复 RAG 偶然带回的特定片段，然后所有的逻辑都必须在 RAG 里。我认为这样做更有意义，也更透明。
也许你稍后会在状态管理中谈到这个。锚点是在蓝图中预定义的，还是它们？
它们大部分是由蓝图预定义的，而且我们会说，作为概览的一部分，你知道，锚点的概念是，它是一件发生过的事情，或者将要发生的事情，这里是这次治疗的例子，对吧？这是这次治疗中将要发生或已经发生的事情。
抱歉。那是关于锚点的问题。
是的。所以当你提到你对话并跟踪……
呃，不。所以那个状态基本上是，嗯，你知道，我们称之为，出于只有工程师才会喜欢的理由，我们称之为“日程文档”（schedule document），对吧？这个想法是，对于任何给定的病人，都有一个他们遵循的日程，而这个文档在某个特定时刻快照了他们的当前状态，对吧？而且它是一个版本化的数据库。所以我们可以回到过去，我们可以看到他们三天前的文档是什么样的。嗯，但它在任何给定的时刻都有已经交换的消息，任何未发送的预定消息，以及足够的关于他们的治疗状态来填充这个视图。
是的。呃，是的。所以，在这种情况下，所有这些东西都被锁起来了，对吧？所以我的意思是，回到这张图一会儿，嗯，整个这个东西都在，你知道，AWS 的 VPC 后面，对吧？所以，就像，没有任何外部可以访问到 LLM。句号。它唯一能交谈的东西基本上是它自己的文档，你知道，在本地文件中，以及那个蓝色的盒子。所以，你知道，肯定有攻击向量，但向量会通过短信，对吧？而不是真的通过其他任何东西。
呃，是的。哦，抱歉，很多人。你先。
问题是关于，我猜是双重的，一是你如何评估模型响应的置信度，二是你们如何防范恶意行为的注入？
是的，好的。所以，呃，问题是关于提示注入和总体的引导。嗯，我的意思是，基本的答案是，你绝对可以尝试通过发送奇怪的短信来欺骗模型，对吧？而且我们确实在我们，你知道，内部的红队演练中这么做。就像，我们有一整个运营助理团队，他们花了数周数月的时间试图欺骗这个东西。嗯，而且当然，他们不是为了揭露专有的个人医疗数据而欺骗它，你知道，我的意思是，有类似的事情。我们也混淆了很多医疗数据。所以到达那个黄色方框的东西不包括电话号码，也不包括除了病人已识别的名字之外的任何东西。嗯，所以有很多很多那类数据只保存在蓝色方框里，这更容易防御。嗯，所以，是的，我们确实非常努力地隐藏了病人的信息。我们没有隐藏治疗方案，对吧？治疗方案对 LM 来说是完全可见的。
是的。好的。是的。是的，请先别急着说，我很快就会讲到那个。
嗯，我们回到那里。呃，抱歉，这只是一个关于指令不明确的问题。
嗯，所以，呃，当情况模棱两可时，LLM 被告知要查看蓝图并选择最佳答案。现在，如果你不相信 LMU，如果你不相信答案是完美的，嗯，你应该在理由中说出来。所以如果我回到这里，这个理由的概念，如果模型方面有不确定性，它可以说，嗯，我选了这个蓝图的回应，但我不确定它是否正确。实际上，它在这方面做得并不好，对吧？但这就是想法。然后评估者也会看这个，然后说，嗯，你实际上是逐字逐句地选择了蓝图的回应，还是你修改了它？你知道，这对你来说似乎正确吗？就像，我们试图至少在接触到人类之前加一层过滤。然后希望我们能捕捉到类似的情况，然后说，嗯，这是一个复杂的情况，应该由一个人来看看。嗯，但这并不是一门精确的科学，就像，这通常是这类事情的普遍情况。
抱歉，你后面那位。是的。
嗯，所以问题只是关于负载和规模。所以，呃，你看，最简短的回答是，这个系统是存在的，对吧？有一个现有的版本，是人类按按钮。嗯，那个规模，你知道，再说一次，假设是数千而不是数百万的病人。嗯，这开启了做更多治疗的可能性，对吧？这就是我们如何获得额外的病人规模。你也可以把这个卖给新的医院、新诊所之类的地方。嗯，所以部分原因是为了扩大规模。我们还没有遇到过，你知道，仅仅是和 Claude 的对话就出现规模问题。你知道，我们正在构建的软件会比数千用户规模大得多，对吧？你知道，短信网关实际上可能是最大的瓶颈。所以，老实说，这是我们想要遇到的问题。
嗯，继续。所以，嗯，你一直说，你们是选择了它们，还是有什么特定的原因让你们选择 35 或其他什么？
是的。呃，所以问题是关于模型选择。嗯，当我们开始这个项目时，对吧？而且，我想，你知道，假设我们在去年年底今年年初启动了这个项目，对吧？嗯，我们必须做出选择，我们的主要标准是，它必须是一个我们觉得在透明度方面很有信心的、可控的模型。嗯，你知道，举个例子，给你一个具体的例子，Mini 在这个工作流程上做得很好，但它不会展示它的推理过程。嗯，就像，我的意思是，这只是一个例子，而且，这也不是一个决定性的因素，就像，我们仍然可以看到理由，就像，它有一些部分，但我喜欢能够进入 LangSmith 看到整个对话，对吧？那真的帮了我大忙。嗯，我们需要，你知道，再次，灵活的托管，但我的意思是，所有的云服务提供商都有点那样。坦白说，我们不想与微软打交道，而且我们更偏爱 AWS 而不是谷歌。这大概就是我们的选择过程。但是，你知道，你可以在任何地方做这个。这真的只是我们必须选一匹马，而且我们基本上没有后悔过，部分原因是我们构建了足够的灵活性，如果我想换，我仍然可以。
是的。是的。呃，所以问题是关于通过短信运营商传输数据的敏感性，以及关于使用数据进行学习。
嗯，我先回答学习的部分。嗯，我们不。我们不会拿任何回应，对我们的模型做任何事情，除非我们看到一些情况，我们作为人类评估后发现有问题。嗯，我们能调整提示和指导方针，对吧？但我们不会把这个以任何持久的形式保存下来。就像，最终，你知道，我们相信这里的正确模式是提供者互动。如果有提供者参与，那就会保留下来，对吧？提供者知道你与系统互动过，他们可以有，你知道，他们需要的任何记录。嗯，否则，你知道，当你的治疗结束后，我们就把你忘了。我们认为这样更好。嗯，关于那个敏感性问题，是的，确实涉及敏感性。同时，再说一次，这些产品是有先例的，对吧？有现有的系统，它们基本上接收，你知道，短信并提供医疗建议。嗯，我们只是试图遵守那个指导方针。再次，这也是为什么我们不希望 LLM 实际上拥有任何非明确必需的数据，只是为了做决策，对吧？它不需要超出那个范围的任何东西来做出一个好的决定。
好的。是的。每个回应都是 100% 决定性的，那是 100% 的。在什么情况下会通知呢？
是的。抱歉，也请稍等一下，因为我马上就会讲到那个。

### 现场演示（续）

嗯，让我继续。呃，请把这些问题带回来，我只是想再讲一点，这样我们就能看到其他一些有趣的东西。嗯，我准备离开这个流程，只是因为你可以想象这会持续几天，对吧？这里还有一步，第二步，那里有更多的药要分发。嗯，然后，你知道，最终我们会到达终点，对吧？然后，你知道，基本上是，你完成了吗？然后，好的，太好了，你知道，接下来会发生什么，你知道，你会看到一些出血。嗯，然后我们有这个回访，对吧？所以想象一下，这现在是，你知道，整整，比如说三四天后，对吧？在治疗开始后。嗯，你知道，我们回访，你知道，病人回复他们，或者不回，对吧？记住，有些病人会想，我做完了，我真的不需要再和这个东西说话了。但如果他们说话了，对吧，我们就继续治疗，我们不打扰他们，我们只是让他们从上次中断的地方继续。再次，我们有这些理由，你知道，我们有这些问题，然后我在这里想做的是，只是为了简要地向你们展示，嗯，抱歉，我得缩小才能看到完整的电话号码，嗯，互动会是什么样子。所以如果我在这里进入我的沙盒，嗯，想象一下，通常这会是一条短信。嗯，所以，你知道，我会在我的手机上做这个。嗯，但在这里，你知道，我可以回答这个问题，如果我之前有任何怀孕的系统，它们减少了吗？就像，是的，呃，它们减少了。好的，所以我发送了这条消息。现在接下来会发生什么呢？正在思考。所以这里没有什么是即时的。

#### 深入LangSmith：状态与处理流程

所以现在我想向你们展示的是，这在 Langsmith 中是什么样子的。嗯，所以，你可以看到这里有几件事。嗯，一个是，这个，这个现在在旋转。嗯，所以，我刚才问它的这个东西现在正在积极处理中。我稍后会向你们展示它完成时的样子。嗯，但我会给你们简单看一下，嗯，我想这个可能在这里比较有用。嗯，这在处理状态方面实际上是什么样子的。嗯，所以，我会把它放大一点，让它再大一点。所以，嗯，你可以想象，这是在使用 sonnet 4。嗯，是这样的，每当有来自病人的消息进来，我就会得到这个。好的。我得到这个描述，关于这里发生的一切。我可以看到这是一个 AVLA 病人。我可以看到我们当前正在执行的线程，对吧？因为你可能需要恢复这些线程，如果你需要给出反馈。嗯，我有一个概念，我正处于为期 3 天的回访阶段。所以这就是我要读的蓝图。嗯，然后我有几样东西。我有这些锚点，对吧？你知道，你可以看到，我想这正是你所看到的之前。嗯，在同一个病人身上。嗯，这些都被定义为，你知道，实际上是 UTC 和东部时间的混合时间戳。嗯，这是很难根除的问题之一。让 LM 很好地处理时间真的很难。

嗯，但然后我有这整个消息队列，对吧？这是迄今为止对话的压缩状态，对吧？这不包括 Claude 在思考时自己发送的每条消息，对吧？那部分包含在这些单独的 Langsmith 线程中。我可以回去，如果我需要的话，我可以看这个。嗯，但我正在做的是压缩，基本上说，我真正关心的只是实际来回的消息。我想要这些理由，因为我希望能够审查它们，对吧？这帮助我理解这里正在进行的决策。嗯，你知道，我想要这些置信度分数，这样我就可以回去看，你知道，它在任何给定时刻是怎么想的，而且我稍后会展示一个置信度低的例子。但这些事情可能会持续一段时间，对吧？这大概是，我不知道，20到25条消息，对吧？所有这些都作为初始上下文进入窗口，对吧？所以如果你有150条消息，所有150条都可能进入。现在我们确实有一个功能，你可以选择性地设置它来压缩，然后说，嗯，只给我看最后50条，对吧？如果我需要请求更多，我可以这么做。有办法做到。嗯，但我不需要把整个东西都放在窗口里。

嗯，所以我到了这里，这是来自病人的最后一条消息，对吧？所以问题是，你注意到血块了吗？我说，是的，一些，对吧？你知道，那是我作为病人说的。Claude 现在要开始处理这个东西了，对吧？所以想象一下，你知道，这所有东西基本上被粘贴到，你知道，一个 Claude 窗口里，然后让它经历这个过程，并且调用工具。所以它开始查看它被允许查看的目录。再次，这是一个版本，它把蓝图都放在本地，而且它和它们这样对话。我们有另一个版本，它通过 MCP 与蓝盒子，也就是更大的系统进行通信。嗯，所以它弄清楚了它有哪些目录，它读取了这些基本的，因为这些在所有情况下都需要被读取。所以这些指导方针，对吧？关于你如何做你的工作的想法，对吧？关于置信度框架是什么样子的想法，治疗的概述，对吧？你知道，那些类型的东西。我们预先读取那些。这些都不大，对吧？所以你读所有这些东西，你知道，它进入了窗口。嗯，然后，你知道，基本上它读取那些描述，然后它说，嗯，我被告知，作为这个的一部分，我必须阅读当前阶段的当前蓝图，对吧？所以我单独读了那个文件。所以很多这些早期的调用只是为了设置上下文。这不是唯一的方法，对吧？我我的意思是，这是我们选择的方式。再次，我们选择不做 RAG，有几个原因，我们就是不认为我们能得到足够好的结果，而且因为这老实说更容易解释，对吧？你可以大致知道它在做什么。

嗯，我到了蓝图，蓝图，而且我们会，我们会在一秒钟内看到更多这些例子，但蓝图基本上是这种结构化的项目符号列表。对吧？这里是所有你可能需要对某人说的话，对吧？而且，你知道，这里是当你知道，用户说了某件事时你该怎么做。这实际上并没有那么规定性，它只是结构化的，对吧？这不是一个 if-then 语句，对吧？它有点像，但它不是一个实际的 if-then 语句。所以像这种格式，你知道，是我们迭代出来的，并且达到了我们实际上能得到非常好结果的程度。嗯，但是，你知道，一开始这并不是 100% 明显应该这么做。嗯，你知道，我们开始时用的是图表。

嗯，所以现在你到了这个点，现在你可以看到，好的，现在我得看看这些，你知道，呃，对话，我得弄清楚发生了什么。这里。所以你可以看到，即使我传入了状态，它也有一个列出消息的函数。所以它基本上说，好的，既然我大概知道发生了什么，让我看看最后五条消息，对吧？然后你可以看到，它要开始发送，你知道，一堆这些消息进来。嗯，所以它这么做了。它看看是否有什么预定的，没有，对吧？所以现在它说，“好的，这这大概是 Claude 做它那个小解释的时候了。我明白发生了什么。病人处于三天回访阶段。我已经问过出血和痉挛的事了。我我问了血块的事，病人，你知道，基本上只是说，是的，他们有血块。所以我我只是要继续前进，对吧？”然后它转到下一个关于怀孕系统的问题。这条信息直接来自蓝图。好的，我稍后会在一个谷歌文档中向你们展示那是什么样子。嗯，所以它安排了，它说你应该发送这条信息，你知道，尽快。

然后我们到了这个评估者流程，对吧？评估者说，“好的，我要看看这个情况，我要看看所有需要置信度评分的东西，对吧？那条新消息是唯一的东西。它它是唯一刚刚发生的事情。嗯，我准备立即发送它。这只是一个立即的时间戳。嗯，然后我得到这种报告，对吧？我们设置框架的方式，嗯，而且我会在代码里展示得更清楚一点，就是，你知道，我们知道用户在说什么吗？我们知道该说什么吗？我们认为我们做得很好吗？再说一次，这是个难题，对吧？嗯，总的来说，LLM，你知道，总是在说，“是的，我知道我在做什么。”而且，你知道，就像，别烦我。

嗯，但我也能说，“好吧，那么有很多情况下，如果我设置了一个锚点，如果我更新了病人的数据，比如我可能改变了他们的时区偏移，可能我改变了他们的名字，对吧？那是个奇怪的事情，你知道，如果发生了，你可能希望有人看看。嗯，我是否发送了多条消息？我是否意外地发送了重复的消息？我是否有对已经发生的事情的提醒？”所有这些事情都会从分数中扣除，并导致需要人工介入，对吧？这这是我们这样做的一部分，就是结合模型是否认为它没问题，对吧？那是顶部的部分。然后总的来说，是否存在一个奇怪的情况我应该试着捕捉到它，对吧？而且我应该试着展示给人们，呃，展示给一个人审查。

嗯，在这种情况下，什么都没发生。我更新了置信度，置信度是 100%。嗯，然后，基本上，虚拟 OA，你知道，作为最后一件事情，很难让 Claude 不总结自己，它会。嗯，它基本上只是说，这是我做的一切，我很好。然后如果你到这里的底部，这是输出状态。所以这个输出状态说，嗯，我有 100% 的信心，再次，是它自己的版本，我做了正确的事情。我，你知道，这里是我的锚点，这里是我的消息，这里是我现在要发送的未发送消息。而且因为它的信心是 100%它就直接发出去了，对吧？它回到短信网关，然后就发出去了。嗯，那是有风险的，对吧？你知道，如果你想做到绝对安全，你就让一个人审查所有这些东西。我们不想这么做，因为我们想扩大规模，对吧？所以我们通常对那些，你知道，返回 100% 置信度的东西感到放心，我们直接把那些信息发出去。

呃，后面有个问题。
是的。是的。稍后会遇到麻烦。
呃，是的。所以问题是，我们如何确定那些可能有置信度问题的情况。嗯，这完全是手动调整的，并且针对这个评估团队。就像，基本上，现在作为人类存在的虚拟 OA 团队。嗯，我们会在抽查中审查，你知道，很多情况，只是为了看看，嘿，这看起来还好吗？嗯，当当一个病人回信时，因为有些情况下病人会回信说，你弄错了，那不是我说的那个时间，就像，你知道，我现在才吃。嗯，置信度系统很擅长捕捉到这种情况，并基本上说，好吧，即使我认为我有信心，但有些地方不对，对吧？你知道，应该让人看看。嗯，但我的意思是，答案是，这更像是艺术而不是科学，这并不是我们即使现在也能做到完美的事情。而且因为我们想要扩大规模，我们选择说，看，最坏的情况基本上是发生了一些奇怪的事情，来回发了几条错误的短信。通常人类会介入并说，这听起来不对劲，对吧？这并不是说病人处于危险之中。嗯，你知道，如果他们说，嗯，我有这些症状，你没有帮到我。就像，一个人会介入。就像，这是我们很擅长标记的事情。
是的。是的。是的。
是的，我的意思是，所以简短的回答是，嗯，我们可以看那些最终被评为低置信度的互动，然后我们可以从那里追溯。对吧？所以我们做的很多事情是，当有东西被标记出来，然后一个人就像，嗯，这里有些奇怪，嗯，你知道，我们在内部分享那些东西，对吧？我之前谈到的那个 Slack 频道，他们和医师助理交谈，那个频道很大程度上被改用于人们说，嘿，这个行为不对劲，你能去看看吗？然后这基本上就进了我的队列，作为，你知道，我得去检查我的评估，我得看看我能做些什么来捕捉到这个，也许是改变这里的行为。但所以，通常是，当我们知道有问题时，我们可以回溯。这就是简短的回答。
呃，这边。我好奇人类也会犯错。
是的。你们有关于人类回应与AI回应百分比的数据吗？
是的。问题是关于人类与AI错误回应的先前数据。所以，是的，很好的问题，而且，是的，答案是我们确实有那些数据，这也是客户对让一个LLM有点失控感到如此放心的原因之一，对吧？就是说，人类现在确实会犯错，当他们被上报时，你知道，这是你可以回顾并说，“哦，是的，那有点偏离了。”你纠正它，然后继续。嗯，这有点独特，而且再次，它它需要，你知道，措辞精确。就像，最大的风险之一就是你给出了某种超说明书的医疗建议。但如果想法是，哦，你误解了，你得回去纠正自己，那没关系，对吧？那不是致命的错误，对吧？所以很大程度上是，你知道，我们认为通过审查这些情况，我们可以更好地利用我们的人力，你知道，而不是仅仅让他们按按钮，因为他们偶尔会按错按钮，对吧？同样的事情也发生在机器人身上。
所以，嗯，说到错误，这个已经运行了一段时间了。是的。你有没有想过用去身份化的消息对模型进行微调，比如把它重新过一遍？
是的，我的意思是，所以，问题是关于，嗯，我们如何考虑微调的。嗯，在我们做这个项目期间，我们已经看到了两次主要的模型发布。嗯，我们通常不认为微调是我们的钱花得值的地方。嗯，它它显然可以更便宜。我，我的意思是，一个例子是，嗯，我们曾经尝试过使用 Haiku。嗯，你知道，Haiku 甚至没有便宜那么多，它可能便宜三分之一，对吧？嗯，我们我们到了一个地步，我们把蓝图做得更好了，部分原因是我们之前有点走捷径，我们不需要对 sonnet 那么精确，对吧？你知道，我们对 hiku 需要更精确。然后它就工作了。Haiku 没有搞定时间问题。Haiku 在弄清楚它需要把什么时间放在什么事情上方面非常糟糕。所以，我们必须在那方面做的事情，就像，它要么就是需要一个更聪明的模型，而且有很多家公司都有更聪明的模型，比如 04 mini 真的两者兼备，你知道，我的意思是，它它的成本比 Haiku 低一点，我想，对吧？而且它和 sonnet 一样聪明。我们选择不用它，部分原因是因为它不够透明。嗯，所以总的来说，我们不相信微调是必要的，因为我们认为模型只会不断变得更好、更便宜，而且我们，你知道，我们会能够进行整体切换，而不是微调某个东西。
所以当你经历那个过程时，你和模型有这种“健谈”的状态，它会描述它的行为，然后调用工具。那是像，那是一个故意的选择吗？我觉得你可以直接跳过那个，直接输出。
嗯，所以，是的，那是个有点故意的选择，对吧？这部分是因为我们已经得到了理由和它行为的总体解释。嗯，但有时候你想知道，看，它为什么这么做？而且，你知道，如果它在自言自语，就更容易发现。嗯，所以，是的，我们有可能可以消除一些那种情况。我们真的不认为那点小事值得花大力气。
你很可能会遭受二次打击。目前的结构是如何设置的，以便你有一个新的锚点来看到这个人？
是的。呃，好问题。所以，问题是关于基本上多次治疗，或者在经历一次治疗后再次回来。嗯，有几种方法可以做到这一点。一种是，嗯，你知道，再次，取决于你如何到达那里，如果你扫描一个二维码，那可以开始一个新的激活，这样我们就能知道你第二次来了。嗯，但人们会在，你知道，两个月后回信说，我有个问题，对吧？而且，所以我们既可以直接重新激活那个对话另一件事是，不同的治疗通常会来自不同的电话号码。所以有几种不同的方法可以区分某人到底在做什么。但是那种概念，比如，你知道，同样的事情又发生在我身上了，我重新开始这个方案。基本上，你只需要解释一下。你只需要说，“嘿，我两个月前流产了，我又流产了。你能帮我吗？”然后它会自己重置，对吧？LM 足够聪明，可以做到这一点。
我能分享一些吗？呃，请吧，因为有很多可以分享的。我的意思是，显然是有意为之的，意图是改善两个意图。我想我对此持怀疑态度。双倍的成本是否能带来更好的结果？你是否有像漏斗一样的数据，显示评估者可能会出现这种情况的频率？第二个问题是，他们两个都对吗？在这种情况下，他们是的，是有意决定坚持使用而不是切换模型吗？在理论上，假设你用一个不同的大脑来看待另一件事。是的。最后一个问题，抱歉。不，不，请讲。嗯，这个评估的加入，除了像，这是一个性能问题，让它变得僵化之外，还有其他影响吗？
是的，所以问题都是关于评估者节点和流程的。所以，呃，最简短的回答是，嗯，是的，我们也很怀疑它。但同时，我们认为尝试仍然有价值，你知道，基本上这是第二次机会，对吧？我们确实认为，在同一次对话中仅仅使用一个不同的系统提示，偶尔会带来更好的结果。但你可以让虚拟 OA 评估它自己情况的复杂性。我不认为你能让它评估自己是否正确，因为通常 LM 无论如何都非常不擅长这个。所以我认为，我认为基本的答案是，我们想要灵活性，部分原因是为了我们可以做一些事情，比如尝试一个完全不同的模型，对吧？或者，你知道，有某些东西，也许你，也许你确实微调了一个模型，专门用来捕捉这些错误，对吧？我觉得那一点也不疯狂。嗯，所以，是的，我们想要那种可选性，而且在这一点上，你知道，现在还早，对吧？再次，它在运行，它已经上线了，就像，你知道，我们还在调整它。嗯，如果我们到了一个地步，我们觉得，看，这唯一的问题是它要花多少钱，或者像，关于它捕捉错误有多好的具体细节，嗯，我们会更努力地解决那个问题。但我们对目前的平衡很满意，它通常会上报需要审查的情况，对吧？它有时会搞砸一些事情，只是因为它认为它很简单，但其实不是。这种情况确实会发生。同样的事情也发生在人类身上，对吧？所以，我们算是达到了我们最初为自己设定的标准。
那是个很好的区别。评估者有不同的任务。
是的，它不是真的把同样的事情做两遍。
对。评估者是以不同的方式看待它，而且它有这个明确的，所以有一件事实际上是，评估者可以看到 VA 应该做什么，对吧？它可以看到指导方针。所以它能够基本上说，你没那么做，对吧？因为我知道你被告知要做什么，但你没做。同样地，虚拟 OA 可以看到评估者的置信度框架，它可以说，嗯，我将根据这些东西被打分，你知道，我最好做对。再次，这更像是艺术而不是科学，但但我的意思是，你问了一个正确的问题，关于我们是否可以有一种更优或更便宜的方法来做这件事。我认为答案是肯定的。

好的，让我继续讲一会儿。请先别急着说。嗯，所以再次，这个想法是，每次互动都像这样。它有一个起始状态，一个对话，一个结束状态，然后返回系统。所以我在这里想向你们展示的是，如果我回到一个对话，对吧？在事实上，让我看看我这里有什么。哦是的。事实上，这个回答了。我说怀孕症状减轻了。蓝图里的下一个问题是，你认为你完成了吗？对吧？你知道，你相信，你知道，流产以及这些药物应该引起的那些变化已经完成了吗？对吧？嗯，基本上在这之后还有一条消息，是确认并说，嘿，如果你有任何问题，请告诉我们。但那种互动，对吧？来来回回，评估当前存在的状态，就是这个系统被构建来做的事情。而且我们每次这些互动之后都会进行压缩，只保留在给定时间内状态发生的变化，对吧？我们不保存，你知道，在 Langsmith 里，我们保存整个对话，对吧？这个数据，抱歉，那不是那个标签页，这个数据，你知道，关于虚拟律师（应为虚拟OA）和评估者之间说了什么，他们调用了什么工具，这些都保存在 Langsmith 里。我们不会扔掉这个，对吧？但我们不会在蓝色方框的状态中保存这个，对吧？那不是病人与我们互动的一部分，而且我们不会每次你用新消息回去时都重新加载它，因为那最终既会混淆事情，也会撑爆上下文窗口。所以这就是我们选择这么做的方式。

#### 处理复杂情况与人工审核

嗯，那么让我现在给你们看这个。嗯，我这里有另一个对话，实际上需要回应。所以我准备把这个拿过来，放到沙盒里，这样你们就能看到这是什么样子了。
抱歉，我只是有持久性。
呃，抱歉。持久性，如果你只有你你刚才说的，不保存模型自言自语的过程，对吧？你有它，你需要时可以参考。它是一个调试工具。
是的。是的。输入和输出是我们快照到更大系统里的所有东西。

好的。那么现在我们来看这个。我想那其实是错的那个。让我去，抱歉。再找找这个。好的。是的。所以这个，这个就在这里，其实，你知道，我可以，我我不用去沙盒看这个。这是一个例子，当事情变得足够复杂，以至于我们请求人工审查时会发生什么。好的。所以在这种情况下，我刚刚开始这个对话。好的。然后我说：“是的，我拿到药了，是从诊所来的。这是我的时间。”现在，这是治疗中的一个时刻，很多事情正在发生。我正在弄清楚他们所在的时区，对吧？然后我把这个保存为病人数据的一部分，对吧？所以在这种情况下，我说我在西海岸时间，所以我的时区偏移是 UTC 前 420 分钟。嗯，我正在进入治疗的新阶段，我有我的药。你知道，现在我不再处于引导阶段，我实际上在吃药，而且我正在发送多条消息。所以在置信度框架中，我想我能找到这个，但呃，在我们到那里之前我不会深入研究。嗯，在置信度框架中我们说，当你同时有所有这些变化时，你应该从你的置信度分数中扣除。所以你看到这里这个置信度70% 的。我把阈值设在 75。所以对于任何低于 75% 的，我都会停下来，然后请求一个人要么批准，对吧？所以如果我批准这个，它就会说，“好的，这些改变没问题。”在这种情况下，这些改变是没问题的。

嗯，或者我可以给出反馈，对吧？我可以比如说，我现在就试试，管它现场演示会不会出问题。嗯，假设，你知道，我想说，请在你的下一条信息中，或者在你的信息中提到病人的名字。所以我会说，提交反馈。好的。而且我正在考虑这个问题，因为它有点像一个操作细节。嗯，这现在正在再次思考。所以我得等一会重新加载这个，看看发生了什么。但这里实际发生的是，如果我再次去 Langsmith我应该能看到，现在发生的是，它正在重新启动一个我已经开始的线程。所以，我们清除它的大脑并重新加载所有东西的唯一例外，就是当你带着这个反馈回来的时候，对吧？因为你基本上希望它能够直接在线程中接上，然后说，“嘿，你刚才做错了，但其他所有东西，就像，你需要能够看到你是怎么到那个地方的，对吧？”你知道，所以做出正确的决定，然后完成它。嗯，所以我想，我们来看看这里。好的，还在思考。嗯，哦，有了。所以你可以看到，唯一的变化这里发生的是它提到了她的名字，对吧？否则就是同样的事情。同样的时区偏移，同样的治疗阶段，同样的提醒。嗯，你可以在这里看到理由。嗯，而且你可以在这里看到理由甚至包括这个，我改变了它以更新名字。

现在你可以想象做一个版本，我只是有一个小小的编辑框，然后我说，“我要改变这条消息。”我们选择不这么做，对吧？我们希望 LM 实际上来驱动这些改变。我们认为，人类像和人说话一样和它们交流会更好。嗯，这是一个有争议的选择，但这是我们做出的选择。嗯，这部分意味着我们可以对治疗方案非常非常灵活，对吧？我们可以只对情况给出反馈，而不需要构建一些能够处理所有不同类型治疗的足够灵活的工具。嗯，但所以在这里，我只想继续说，批准。然后那些消息就会发送出去，并且更改就完成了，对吧？我有了，你知道，我的病人本地时间设置好了，而且我知道我进入了蓝图的下一部分。

### 核心驱动：蓝图与知识库

好的。我准备在这里暂停。我准备跳到代码部分了。我想我们还剩下大概 45 分钟。嗯，到目前为止，有什么问题不是“我只想看代码”的吗？因为我可以做那部分。
在那边。你们有没有听到客户的反馈？
是的。呃，问题是关于来自病人的反馈，以及它是情绪化的。所以，是的，绝对是。所以记住，这是一个病人或客户已经在运行的系统，对吧？所以从根本上说，他们已经相信他们在和人交谈，即使不完全是，对吧？即使是那些按按钮的人，也只是在调用基本上是机器人生成的响应。嗯，当事情变得情绪化时，嗯，人类可以介入。你知道，我们倾向于引导他们使用经过批准的知识库回应。就像，你不希望这变成完全自由发挥的情况。有法律和其他原因不这么做。所以通过介入并让 LM 做决定，并不会真正改变这些治疗的当前背景。他们已经在接受，你知道，基本上这种经过医学批准的反馈，你知道，基于某个流程图。如果它走向了，你知道，有点疯狂的地方，上报点通常是打电话给某人，对吧？而不是，你知道，我们继续在短信里没完没了地聊，因为那很乱。嗯，有很多一些点，我在这里无法演示，基本上就是说，是的，对不起，我无法回答那个问题，打 911，去找你的医生，或者其他什么，对吧？但那通常是事情从那里发展的方向。
蓝图看起来很像那个。
嗯，这是个好问题。所以老实说，部分原因是我们需要有一个病人，或者不是病人，是客户，他们自己能舒服地维护的东西，对吧？因为记住，部分原因是我们不希望这个东西写在代码里，对吧？我们不希望这是一个只有技术人员才能维护的东西。那是他们以前的问题，对吧？所以，只是跳过一下一会儿，我给你们看看这大概是什么样子的。所以这基本上是客户正在维护的东西。我会把这个放大一点。我知道这很小。嗯，但是这里的想法是，我们使用术语，而且，你知道，我们会在代码里看到更多这个。我们使用的术语是在框架中定义的。一个触发器是，你知道，在事件发生后，基本上会发生的事情，对吧？嗯，你知道，我们有这些消息的对话。我们总是告诉 LM 为什么这很重要。如果我们只有这个细节，我们只说这是你发送的消息，我不认为它会表现得那么好。给 LLM 提供它为什么会说某句话的理由，实际上更有帮助。说点什么，因为那样它会做出更好的决定。嗯，众多怪癖之一。

嗯，继续。我不确定这是否是代码，或者不是下一部分，但是，多么复杂，多么简单的陈述，或者如果你有任何，实际上在哦，当然。
是的。所以，所以问题是关于，你知道，基本上为什么我们有这个框架，以及为什么它可能没有更具声明性，对吧？就比如，具体地用 if-then 之类的，对吧？
实际上我我用过类似的，用了一个不同的索引，然后我得到了索引，所以我不能做得非常复杂，不能有很多嵌套，必须是一两个层级。对吧？我的问题是，所以我的答案只是关于，再次，你如何尽可能清晰地定义这些东西，但又可能不那么复杂，对吧？所以，嗯，这个框架倾向于这样工作：你真的只是在说，看，我给你这个批准的语言，我试图给你，在这些粗体陈述中，对吧？主要是，我试图给你一个感觉，你知道，条件到底是什么。但我们这样做的一个原因是，你知道，如果病人在这件事后回信说，你知道，是的，我有药，而且我吃了药，而且我肚子疼，而且我很困惑，对吧？我的意思是，可能是所有这些事情。我们不想用流程图来表示类似的东西。我们真正想做的是说，“看，这就是事情的大纲。你可以看到它。你知道，如果你需要跳过，就跳过，不要问病人他们已经回答过的问题。”事实证明，这个框架在让 LM 做这类事情方面确实效果很好。我知道这有点像一个神奇的答案，但它做得相当好。
嗯，是的。
不，我的意思是，Claude。是的。Claude 基本上做到了。他们大多数都做到了。
是的。包含指令是否能提高响应质量？
呃，抱歉，你说的“包含指令”是什么意思？
包含推理。
哦，推理。我我。所以问题是包含推理是否能帮助提高响应质量？我认为是的，对吧？我的意思是，这是其中一件事，我们也是从借鉴人类文档开始的，对吧？所以这是一个最初向将要按按钮的人类解释的过程。所以我们结合了已有的流程图来解释治疗流程，以及这类，你知道，这是你在这些情况下应该发送的消息，这大概是那两者的混合产物。所以我不会说我们做了积极的测试，关于它是否真的更好，或者只是，你知道，这已经足够好了。更像是就像，我们基于我们拥有的人类资料，从这个框架开始。
关于那个的后续问题。是的。你发现作为一种形式，你不得不做出任何牺牲吗？
是的。所以问题是，维护这个文档作为人类可读的，与 LM 可读的相比，是的，有权衡。我认为它们仍然值得。我们可能在某个时候改变主意，对吧？所以，你知道，想象一下这里的工作流程是，嗯，你知道，这个谷歌文档基本上是由我们的医师助理维护的，对吧？她是蓝图的共同所有者，可能仅次于我。嗯，当我们当我们做改变时，我们一起讨论。我们在这个文档中推荐，然后接受它们，然后我实际上把它导出为 markdown然后把它签入版本库，对吧？这会有点改变。我们会把很多这些工具构建到数据库里，所以那才是你真正要做这个的地方。嗯，但因为这是人工维护的，对吧？因为它基本上，你知道，仍然是由团队驱动的。嗯，是的，我们正在做一个权衡。我不认为这是一个非常具有破坏性的权衡。
根据你目前的设计，刚才你做的那件事，之后改变的是什么？它是一次性的，还是它会改善你未来的答案，甚至改变……
所以，目前没有。问题是关于批准、推迟的反馈机制。嗯，所以实际上，我回去简单展示一下这个现在应该完成了。嗯，好了。嗯，再说一遍，我们正在保存这个，因为我可以在 lang 里看到这个，对吧？我可以看这个，然后可以说，嗯，在这些需要批准的情况下，而且在这种情况下，就像，只是作为一个视觉上的反馈，每当你有这个图的空开始时，对吧？那那正是这些情况之一，你知道，有一个批准、反馈、推迟的选择。嗯，我可以按这个过滤，我可以看所有这些东西，然后可以说，嗯，我们实际上在尝试批准或给出反馈的是些什么东西。嗯，我们不从它们身上学习，对吧？我们作为人类可能会更新蓝图，但我们不会把这个放回训练数据中，同样，出于一些特定于这种情况的原因。

嗯，但是你所以你可以看到，像，我可以一直到这里，我会试着快点找到这个。嗯，然后你会到一个地步，人类说，好吧，是的，就是它。所以我们从，是的，从 humano（人类操作员）那里得到反馈。这基本上是我按下那个按钮，说“给出反馈”时发生的事情，对吧？humano 对你未发送的消息有反馈。反馈是提到他们的名字。嗯，它直接回到正事上。就像，好吧，让我看看那些消息，你知道，我正在发送的。我要用这个更新一下，我可能要删除，不确定，实际上不，它只是在原地更新了那个，我们重新评分了。有一件事我们说过，就是我们不会改变一个经过人类审查的东西的置信度分数，我们让它保持原样，对吧？我们让他们再审查一次，对吧？所以在所有这些情况下，这这也是一个快得多，更简单的操作，对吧？所以你可以看到，这里的评估者基本上就像，是的，那条消息没问题，但我们不会做任何事情，你知道，真的去改变总分。嗯，所以，你知道，那是那种东西，你知道，我们可以之后再看。对吧？但我们目前至少，你知道，真的不打算把这个反馈给模型。这真的只是为了蓝图。
只是为了了解一下你的指标。嗯，很多这些都超过一分钟了，而且它说大概有几十万。你如何看待这像一个必要的恶，时间成本？
不，不，我的意思是，它是一个必要的恶，而且实际上，只是为了指出，嗯，这些成本我认为是不正确的。嗯，Langmith 的一个缺点，我想他们在各种场合都承认了，就是他们没有真正考虑到缓存。嗯，所以这些成本应该比你在这里看到的要低。嗯，但但从根本上说，是的，这些是昂贵的操作，而且，你知道，我们可以改变，我们可以改变其中一些，但可能会以更高的错误率为代价，对吧？就像，我们可以尝试缓存更多，让你继承正在进行的线程，这样会更快，对吧？因为你已经加载了所有东西，它会，你知道，可能你没有重新加载任何上下文，所以，你知道，你你在 token 上的花费可能会更少，但你的错误率可能会更高，而且，你知道，那是我们在权衡的事情。
有没有某种知识库你的模型是根据药物来决定的吗？
呃，是的。所以问题是关于知识库的。

### 实现细节：指导方针、置信度与工具

所以让我让我实际上跳过去，快速展示一下这个。所以我提到了这些蓝图。嗯，我我现在真的要跳到实现的样子。所以你可以看到这边，你知道，这个关于 VA 的想法，对吧？我们这里有一堆文档，再次，被导出为 Markdown。嗯，我会把这个放大，因为我知道这些很小。嗯，让我把这个缩小一下。好的，所以这里的想法是，你知道，我有很多这种，呃，框架数据，对吧？定义我说的蓝图是什么意思的想法，对吧？我们每次都在定义这个，不是在提示中，对吧？我们是作为上下文窗口的一部分来做的，部分原因是我们确实希望这个非常灵活。如果你想改变术语，嗯，你应该能做到，对吧？我们不希望治疗方案被我们用于其他治疗方案的术语所束缚。我定义了锚点，我谈论了日程，我谈论了预定消息，对吧？所以所有这些东西的存在，部分原因只是为了打下基础。然后这个框架，对吧？现在引用了特定的文档，对吧？所以你可以看到这里，像，我再次，这些文档都是相互引用的。所以我可以在这里浏览，我可以看，而且点击这些链接，如果我想做一些关于知识库的事情，就可以直接转到其他东西。

所以我们做那个的方式是这个“分诊”（triage）的想法。嗯，所以，你知道，如果发生了蓝图没有涉及的事情，对吧？所以我们处理它的方式是，首先检查蓝图。如果你有批准的语言，就用它，对吧？发送它，把它发回给人类审查，无论你需要做什么，对吧？但要用那个批准的语言。如果你认为你无法回答那个问题，你就去看这个，现在再次，这是自引用的。我们不会一次性读取所有经过医学批准的知识范围。我们让 Ellen 决定他们是在抱怨胃痛还是出血？对吧？你知道，如果我在这些里面都找不到任何东西，我有一个更大的知识库，对吧？那基本上就是一个杂乱无章的问题清单，人们问的随机问题。嗯，我们选择这样做，部分原因是因为它对人类可读，它模仿了客户已经基本拥有的东西，对吧？他们已经有很多这些结构了。嗯，而且，你知道，我们从根本上不相信过度处理，你知道，像 RAG 这样的东西是有意义的。现在我得说，对于我们有的那个，像，一个备用的，你知道，知识库，它几乎完全是一个 CSV，那可能适合用 RAG，对吧？它用RAG来处理会没问题，但它用得不多，对吧？所以在某种程度上，至少现在，用那种方式实现是不值得的。

好的，嗯，是的。
是的，那是提示级别的。所以我们，虚拟 OA 和评估者都有相对较小的提示，我可以展示。所以让我看看我是否能在这里找到它们。嗯，那些提示是，它们确实相互引用，对吧？所以想象一下这个是，嗯，你知道，再次，建立在 line chain 的东西上。所以基类代理类，嗯，这个提示基本上意识到另一个代理，对吧？所以在这个例子中，只有两个。所以提示确实互相提及。评估者知道虚拟环境，反之亦然，对吧？你知道，我们尝试做的事情，而且，你知道，我认为这是那些真正玩过这个的人的正常提示工程的东西。你必须告诉它如何轮流。你必须告诉它，你知道，如果它被叫到，它必须说话，对吧？就像，你知道，我们遇到的一个问题，我们必须经常重试，就是 LM 认为所有事情都完成了。它什么也不说，然后整个事情就死了。嗯，所以，你知道，你必须说话，但然后你可以完成，对吧？你只需要说点什么。嗯，我们有一个基本的想法，你必须确定这个总体置信度得分，但我们不把这个包含在提示中，因为我们希望能够也向虚拟 OA 展示它，对吧？所以你如何评分的细节是分开的，但关于你是谁、这个其他人是谁以及你们如何合作的概念，是在提示中的。

好的，实际上关于那个，让我跳过去，实际展示一些置信度的东西和指导方针。所以，嗯，我从置信度开始，然后我会讲到指导方针，那个要长得多。这个再次，是，你知道，主要是为了让 LLM 可读。这不是客户通常维护的东西，对吧？所以这和那些蓝图不在同一类别。但这里的想法是，你知道，我有了这个置信度分数，而且，你知道，我试图在这些多个维度上弄清楚，我知道发生了什么吗？你知道，这里有一些例子。我们我们试图尽可能规范地给出这些不同情况的例子。嗯，我知道，你知道，我需要知道的知识吗？这里有一个例子，可能可以回答你那边的问题，你知道，关于我们是否希望 LM 用它的世界知识来弄清楚，当我谈论一种抗生素时，我给了一个特定的抗生素，它适用于整个那一类药物。是的，那是一个我们愿意承担的风险，对吧？我们不需要明确规定这种特定的抗生素对这种治疗是安全的，对吧？那会很快失控。所以我们确实有几个地方，我们要求它，用你自己的判断，但要参考，你知道，知识库和蓝图作为你的基准。

嗯，然后，在我讲完这些类别之后，我有了这个扣分的想法，对吧？这里的扣分，嗯，是具体的事情，比如，你知道，你应该从总分中扣分，而不是单个消息，对吧？因为一个单独的消息可能是，是的，这完全来自蓝图，就像，这是该说的话，但总的来说，这些情况可能很复杂，对吧？所以我们试图解释这一点，以便它能再次，以一种能提交给人类审查的方式，对整体互动进行评分。

嗯，好的。所以我准备继续讲指导方针，因为这里面的内容更多。嗯，这足够长了，我不会全部回顾，但我会试着讲一些最重要的部分。再次，其中一些非常简单，对吧？比如工具调用。嗯，我们随着时间推移肯定遇到的一个问题是，你知道，捏造，而且，你知道，老实说，像这样的指令确实有帮助。嗯，你知道，不要捏造一个工具调用。等待，等你的回合，对吧？调用工具然后退后。嗯，有很多关于时间的东西，对吧？有很多关于，嘿，你需要以正确的方式问，你不要以一种强迫别人告诉你他们在哪里在哪里的方式问，对吧？人们对此非常敏感。他们不希望，你知道，人们知道他们的物理位置，但你需要知道他们的时间，这样你才能为他们安排消息，对吧？嗯，你想要，你知道，当你处理时间时，嗯，你必须使用像，你知道，ISO 时间戳这样的东西。就像，那是系统的工作原理。嗯，但计算这些东西并让它们都保持正确，需要一个相对聪明的模型。所以很多这个，你知道，随着时间的推移，已经发展到只是处理这个想法，你知道，这就是你如何与模型谈论这个，并且做得很好。

嗯，设置锚点，安排消息。再次，这些都是系统的核心部分。这不是特定于治疗的，对吧？所有这些都是为了足够通用，以至于我每次添加新药时都不必重写这个，对吧？这这是核心要求之一，对吧？我们不希望在代码中做这个。
是的。所以这是一个非常大的文档。
是的。呃，你有没有试验过缓存，因为这个不会改变。
是的，没错。不，我们有。所以现在，我稍后会讲到缓存，我只是在管理时间，但我确实有时间讲那个。就像，我们正在做一些明确的系统提示缓存，然后我们明确地缓存，嗯，你知道，消息的多次轮换，这样，你知道，每次操作都是，你知道，我想平均操作，只有基线的东西，大概是 10 到 15,000 个 token，对吧？每轮。所有都缓存了，加起来不少，对吧？所以，你知道，你可能生成单个消息的平均成本在 15 到 20 美分之间，对吧？这不便宜，但我们正在尽可能积极地进行缓存。我们考虑过各种事情，这都是全新的，对吧？Claude 刚刚引入的一小时缓存这个概念，我们不清楚这是否有帮助，因为，你知道，我们不能保证病人在，你知道，五分钟或一小时内会回复我们，对吧？在系统层面冒这个风险有点冒险。嗯，但如果这里有谁比我更了解 Claude 缓存，请和我谈谈，因为，就像，我们理想中希望能缓存很多这些文档。嗯，只是不清楚我们是否能跨会话做到这一点。不清楚我们是否能得到我们想要的好处。所以我们只是试图在单个对话中尽可能积极。
那是一个很长的指导方针列表。你是怎么想出来的，以及你如何优化？
是的，我的意思是，看，真正的答案是，我之前提到过，你知道，有几千行代码和几千行提示。这基本上是那个提示的大部分，对吧？我的意思是，这里面有很多。嗯，这是我们随着时间推移调整过的东西。这是，你知道，我自己以及，你知道，那个医师助理，我们一起想出了我们认为从根本上说，在处理这些通用情况方面相当不错的东西。当我们发现边缘案例时，我们就修改这些提示。再次，它不是完美的。我们绝对可以考虑细分这个。我们可以考虑把一部分移到提示中。嗯，但我们认为这个划分，你知道，大致是正确的，可以保持它的通用性，这样它，你知道，能处理一堆不同的治疗，并且它能很好地处理我们在不同治疗中看到的情况。对吧？你会有一些情况，你做的药物都是在一天之内完成的。那相对不寻常，因为你知道，那只是你把说明书寄回家的事。嗯，你知道，但我我的意思是，我会展示一个关于 ampic 的例子，你知道，那是每周、每月，对吧？就像，有更长的持续时间。我们试图达到一个平衡点，你知道，我们我们最终得到了一个好的结果。
好的。呃，是的，后面那位。
是的。是的。是的。所以问题只是关于提示长度。嗯，所以再次，不是要轻率地否定那个。在 Claude 的术语里，这实际上并不长，对吧？我的意思是，这就像我说的，我想平均是 15,000 个 token。嗯，它仍然留下了很多窗口，你知道，在后面，对吧？它它实际上并没有长到我们开始看到非常疯狂的行为，直到我们开始在一个线程中进行多次轮流，就像，多次对话，对吧？那是它开始爆炸的地方。嗯，所以我们我们真的还没有到一个地步，我们觉得，我的指导方针太长了，你知道，指导方针可以短一点，而且我想我们随着时间的推移在各个地方都优化了它们，但，你知道，我们我们把这个塞进了一个盒子里，我们真的可以，比如说，一口气处理一个情况，而不会感到任何痛苦。
好的。是的。
关于你有的工具，有什么例子吗？你提到了工具，我不确定。
是的。是的。哦，不。所以我我我可以分享一点那个。所以让我，让我到这里的工具代码本身。所以，所以需要注意的一件事是，这是一个混合体，我想我之前很早就提到过，关于，嗯，有一些东西来自一个 MCP 网关，对吧？所以在这种情况下，你知道，我从文件加载，它只是文件系统 MCP。再次，所有都本地化到我们的 VPC。所以没有什么疯狂的事情发生。嗯，但我可以从，你知道，我的数据库加载，对吧？我可以选择让那里成为我们互动的地方。还有很多其他工具，对吧？所以，你知道，这这实际上可能是我应用中大部分代码所在的地方。实际上是。嗯，工具列表基本上在这里。你可以看到它是一些能与状态交互的东西，对吧？所以所有这些查看锚点、消息、置信度、治疗和患者数据的功能，都是我图运行的本地功能。我没有为它设置 MCP。我本可以，只是选择不这么做。嗯，而且，你知道，在这种情况下，就像，这些代码就存在于这个 Python 应用中。你你完全可以重构它。就像，状态仍然可以在这里，而代码可以在别处。这，你知道，这取决于你。嗯，但实际上关于所有这些东西的一个注意事项是，我正在努力寻找一个好例子。所以我正在积极地使用`command` 对象。嗯，对于任何用 Langraph 编程过的人来说，这背后的整个想法是，在任何给定的时刻，你都能够传回一条消息，而这个特定的东西只是一个错误消息，但就像，你知道，你能够传回一条消息和一个去向，对吧？所以你可以说，这是回应，顺便说一句，我知道评估者要了这个，所以回到评估者那里。你实际上可以绕过一些图的路由。所以我们我们确实，你知道，试图把这个应用到我们有的 MCP 工具和状态工具中。
是的。是的。呃，所以问题是关于如何，我们如何改进提示的。所以，嗯，这真的是一个融合。
嗯，我们能够从，基本上，那位最有欺骗经验的医师助理那里得到启发，她会想出一些棘手的情况，对吧？所以我们能够真正地测试很多边缘情况，就靠她，你知道，让她假装是病人。然后我们扩大到整个运营助理团队，他们，你知道，然后尝试在更高层次上欺骗它，对吧？而且，你知道，他们会拿出他们从病人那里看到的东西，你知道，试图，比如说，嗯，你知道，达到这些复杂的情况。嗯，然后，你知道，有了真实的人，你知道，我们能够把这个再推进一步。嗯，但是有了前两个层次，我们我们没有看到，你知道，大量出乎意料的事情。再说一次，这个系统是存在的。如果我们是从零开始做这个，我想我们在想出我们认为的边缘情况方面会困难得多。然而，你知道，这是一个已经存在的系统，有很多对话可以借鉴。我们能够重新运行其中一些。所以我们会看旧系统中的对话，然后在这里重放它们，基本上就是试图弄清楚，你知道，边缘在哪里。
有没有你说的状态？
当然。所以问题是，关于如何决定什么进入状态，什么不进入。嗯，我的意思是，我想简短的回答是，所有在那个初始有效载荷中进来的东西，我再回去那边。嗯，所有这些东西，我想这个可能是一个更好的例子。是的。所以所有这些东西，这都是状态。嗯，并没有真正的区别，就像所有进来预加载对话的东西都是状态。其中一些是可编辑的，嗯，一些不是。我正在努力回想例子，像这里的例子是，你不能改变来源。我不能说你知道，在 LM 操作的上下文中，这不再是一个 Aila 病人了，对吧？那是 LM 不允许做的。嗯，它也不能改变过去的消息。所以 LM 不被允许查看消息队列然后说，第五条消息，三天前发出去的，不再存在了。那个功能不存在。嗯，所以我们只是校准到，它唯一能做的事情就是读取整个状态，修改病人数据，修改消息，修改锚点，就像，未发送的消息。所以它，你知道，这只是一个软件选择，就像，我们就是这么设计的。
如果你有一个会话，它回来了窗口，把它总结一下。
是的。是的。当然。我的意思是，我我。我认为真正的答案是，那对我们来说还没发生过。就像，我们构建它的方式，没有一次单独的思考操作会持续足够长以至于把事情搞砸。嗯，但但我会很快讲讲，嗯，重试。所以我们确实有这个概念，我只会把它弹出来，也许这是一个更容易看的方式。嗯，所以我们确实在图内部有这个概念，你知道，再次，虚拟 OA 与评估者交谈，你知道，在某个特定的点上，每个人都使用工具，但然后有些情况会导致图重试某个操作，对吧？所以其中一个就是，嗯，其中一个代理格式化工具调用时出错了，对吧？它尝试调用一个工具，但用了错误的 JSON，你知道，否则事情就会崩溃。我们可以检测到那个，我们删除那条消息，然后说你搞砸了那个工具调用，再试一次，对吧？那，你知道，让它保持在图内部，对吧？基本上这个重试节点然后能够通过那个，嗯，命令消息循环回来。呃，这没有显示在图上，但通过那个命令对象。它可以说，回到虚拟 OA，再试一次，对吧？我们也有一些情况，再次，你知道，我们期望模型说话，但它没有，对吧？有很多情况，Claude 会过早地结束它的回合。我们检测到那个。我们说你你必须说点什么，对吧？就像，字面上，消息就是，“别什么都不说。即使，即使你要结束你的回合，也得说‘我完成了’”，对吧？那对我们来说足够了，你知道，让逻辑继续下去。所以就是类似这样的事情。
来自评估者的低置信度会触发……
抱歉，再说一遍。
来自评估者的低置信度。
不，不。所以低置信度是我们想传递给人类的东西，对吧？所以低置信度是对图的有效回应，对吧？你知道，就像，我有一个低置信度的消息，我希望有人审查。那没问题。
嗯，是的。建立你的系统提示。它很长。它很复杂。它不是系统提示。
不，不，那是重点。那就是为什么我们把它分开了。所以，是的，指导方针随着时间的推移而扩展。
是的。好的。是的。你如何确保你不会……
是的。是时候谈谈评估了。

### 评估框架

所以我们快结束了。嗯，让我谈谈评估，只是为了让你们了解我们在这里做了什么。所以，嗯，这个，这个有点奇怪，因为如果你去 Langmith，我只是，我不确定我能找到这个确切发生的地方。嗯，但是，它是不是在，也许在数据集下面，我我忘了。这里有一个地方，你可以基本上说，我想运行，你知道，一个针对你知道，这些，这些，你知道，我已经在 lang 中定义的这个数据集进行评估。嗯，我确实在 lang 中定义了数据集。所以我可以在这里看到，假设这个能加载出来，希望它能。所以，我这里有一个我在 lang 中定义的快乐路径数据集。我，这不是全部。再次，其中一些被删减了。但是，嗯，如果我看看这些东西，我真正做的是，我说，好的，这是一个我们过去有过的互动。嗯，你知道，这是我上周运行的一个。嗯，你知道，这里是，你知道，输入，对吧？这是来自病人的最后一条消息。这个对话，你知道，呃，我有了这个初始状态。我可以看看，对吧？所以我可以看到，你知道，最初发生了什么。嗯，我看到这个对话，然后，你知道，我到了最后，我得到一条消息，说，好的，你准备好开始了。好的。所以这是我的快乐路径数据集的一部分。

我正在运行的评估，嗯，从根本上说，它它是一个自定义的工具集。我会把这个放大一点。希望大多数人能看到。嗯，但再次，这里的想法是，我们不能只说，你知道，当我问旧金山的天气是什么时，它给我返回，你知道，又冷又多雾。嗯，它必须是，这里是这些输入的状态，然后，你知道，让我们以一种 LLM 作为评判者的形式来评估它，输出状态是什么样的，但有一个告诫，我们想测试的一件大事是像时间操作这样的东西。我不能把三周前的评估放进去，现在运行它，然后得到相同的时间。我必须要么给它关于如何处理时间非常具体的指导，要么我必须替换所有的时间戳。嗯，我们最终做了两者的混合。嗯，所以这导致了，我的评估套件是一个自定义的 Python 应用，附加到一个 bash 脚本上。这都是客户端编码的。嗯，我我得到了我想要的，但我不能保证比那更多。

嗯，我从 Langmith 加载数据集，对吧？我调用，基本上，医疗代理，通过，在这种情况下，就像，我在本地运行这个，就像，我可以在我的云 Lang graph 实例上运行这个，但我实际上是在我的笔记本电脑上，用 Langsmith 的那个数据集来运行这个，预处理了一堆关于日期、时间的东西，你知道，各种情况，这样当我得到结果时，我不会让作为评判者的 LM 困惑它是否正确。嗯，我正在用这个 LLM rubric 来做这个。所以让我看看我是否能在这里找到我的 rubric。所以，嗯，这里是，这里是几个例子。所以我有了这个，这个 YAML。所以这只是，这是 prompt fu和它的工作原理。嗯，我做的是，我基本上说，看，我正在尝试测试，你知道，这个我准备称之为，你知道，基本上用我的，嗯，你知道，我的自定义工具集，然后我希望你用一个 LLM 来评估它，在这种情况下，我想它用的是 GPT40。嗯，你知道，这个评估标准基本上是，所有东西都基本上一模一样吗？我看到一些微小的差异，但我不认为它们是什么大问题。我的意思是，我们我们保持这个非常模糊。我们真正想知道的是，有没有什么东西完全坏掉了，对吧？然后有些情况下确实是。我不得不在这里放上具体的说明，比如，嘿，别太挑剔，像，你在锚点之类的东西里可能会看到的不同措辞，对吧？有时它会说他们会吃药，有时说他们吃了药，谁在乎呢？在这种情况下，精神是对的。

嗯，所以，你知道，然后时间和日期，就像，这里有一些特定的语言。所以所有这些都变成了基本上这个家伙，就在这里。所以，嗯，当我看到这个时，再次，我知道这里有很多文字。嗯，不值得全部看。我运行了我的数据集中的这三个例子，然后我得到了，你知道， बेसिकली一个及格的成绩，对吧？我会我会进入那个失败的，一个失败一个通过，在一秒钟内，但在每一个这些案例中，对吧？我可以看到作为评判者的 LM 说了什么，对吧？所以如果我到这里，这是 GPT40 在，你知道，评论，嗯，这是你在示例输出中给我的源数据。这是我刚做的运行。差不多，对吧？嗯，你知道，它确实指出了一些事情，对吧？所以如果我运行这些评估，然后我想，嗯，实际上，那个提醒，你知道，未发送的消息没有出现，这是个大问题，对吧？我我可以做出那样的选择。我可以我可以加强我的评估标准。但我们做这个的方式只是说，看，在任何给定的时刻，我们确实需要能够测试系统的当前状态。我们想先针对，你知道，快乐路径来做，然后我们当然可以针对边缘案例。嗯，我们正在积极维护这个。我想一旦我们把这个更完全地交给客户，这可能会改变，对吧？我们希望他们有他们可能需要的所有保护，但就是这种风格，对吧？这种风格的邮件。这或多或少回答了你的问题吗？
好的。
好的。嗯，是的。请讲。
是的。所以，我的意思是，简短的回答是，是的。其中一些我因为几个原因进行了删减，但，是的，或多或少，我们从一个快乐路径开始。我们确实有一些特定的，比如，嘿，这个坏了，而且它经常坏。我们得确保它没坏。嗯，你知道，但那只是一个不同的数据集。
是的。呃，是的。
嗯，所以再说一次，我这里展示的部分完全是 Python 在一个 Lang Graph 容器里。嗯，我猜它大概有，你知道，也许 4000 行代码。嗯，其中大部分老实说都是工具调用，就像，那只是，而且我我确定我也可以重构它让它更短。嗯，它不多。它真的只是足够运行这个图，对吧？你知道，我必须有所有部分之间的路由，我必须有它可以调用的工具。嗯，其他所有东西都在提示和指导方针里，对吧？所以，你知道，它真的更多是英语而不是代码。在另一边，对吧？在那个盒子的另一边，对吧？这个那个蓝色的盒子是，我不知道确切有多少代码，但它完全是，嗯，Node 和 React 和和嗯，而且坦白说，我没怎么参与那个。
抱歉。

### 灵活性展示：扩展至新疗法

是的。我也在行业里。是的。你怎么看这个？
是的。好问题。所以，呃，关于规模的问题。所以让我实际上跳过去，展示一件事，我可能早就该展示了，但我我忘了。我之前提到过我们做不同治疗的想法。所以，嗯，我我我做了，在这个特定的情况下，所以，你知道，再次，我们专注于那个早孕流产。嗯，我做了这个，事实上，我想我这里有这个东西。所以让我缩小找到它，然后我会再放大。所以我拿了这个这个发给 Klein，我基本上对 Klein 说：“嘿，我有了，是的，应该就是这个。”嗯，我说：“我准备做一个新的治疗方案，对吧？我为 Aila 定义了一个。这是结构，对吧？看一下。嗯，这里是，你知道，诺和诺德关于如何给 Ozempic 定量的建议链接。嗯，给我做一个新的，对吧？”嗯，它基本上经历了这个过程，我我我会把这个缩小。嗯，然后创建了，你知道，一个基本的治疗方案，你知道，针对 Ozempic。它读了这些文件，然后决定，好的，我明白了。这是我要做的事情。嗯，我只是说，酷，去吧。这里还有几个基于你说的东西的微调。所以我再次，这是我的客户端流程，我一直用这个。嗯，我最终得到了我认为是一个相当不错的治疗方案，我很快就在这里向你们展示。如果我回到这些对话，我非常确定我把这些人全都命名为 O。所以你看，这是 Oliver 和 Osmpic。嗯，你可以看到，仍然是 Ava。我没有改变那个，对吧？我我我，你显然可以做到让它有不同的个性，但在这个例子中，这是 Ava 带着一个新的治疗方案，问所有关于 Ozmpic 笔的问题，并帮助我弄清楚他们的时间。和我们之前一样。这是一个每周一次的注射。我没有为此改变任何代码。我字面上就把这个扔给 client，得到了一套新的治疗方案，然后它就能工作了。

### 问答环节

是的。在你的图中那个是用来捕捉，呃，重试节点。
问题是，嗯，它是用来捕捉那些关于格式错误的工具调用的错误的，这是图终止的一个简单方法，对吧？所以如果它，你知道，忘记了一个括号，然后，你知道，返回了无效的 JSON。嗯，Claude 现在很少这么做了。像 Sonnet 4 在这方面做得很好，但是，嗯，Sonnet 3.5 没那么好。所以我们可以检测到那个，然后我们可以说，嗯，你正试图进行一次工具调用，因为我在这里看到了一些特定的东西，我既看到了 tool call ID 作为参数，也看到了奇怪的括号，你知道，我们可以在代码中解析那个。嗯，然后再次，我们清除那条消息，然后回到调用它的那个家伙那里，然后说，“嘿，你搞砸了，恕我直言。”嗯，你知道，再试一次。所以那种想法，你知道，重试节点，有少数情况我们不会接管并以某种确定的方式去做，我们只是告诉 LM，你犯了个错误，这是你错误的特点，再试一次。而且我们确实需要清除它对那个错误的记忆，因为它会变得非常困惑。就像，我们早期测试中这种情况发生的一个原因，是它会错误地格式化工具调用，然后幻想出结果，对吧？所以如果你把消息留在那里，它会认为它理解了蓝图，即使它完全编造了整个蓝图，对吧？所以我不想粉饰，就像，有些奇怪的情况，如果你不非常小心地控制，你可能会得到一些非常糟糕的行为。但我们能够捕捉到主要的那些，并基本上给它另一次机会。
我是在找一个循环。
哦，好的。抱歉。没有循环的原因，这完全是，这实际上是我认为 Langmith 和 Lang graph 可以做得更好的一件事。重试节点能够使用 command 对象回调到其他节点，但它没有显示在图上。所以事实证明，就像，他们非常投入，Langmith 或 Lang graph 在图流中，然后他们引入了这个想法，嗯，你甚至不需要在图中定义它，你可以把任何东西发送到任何地方，所以那就是我们正在使用的。
是的。是的。不，当然。但记住，抱歉，问题是关于置信度评分以及我们如何让它变得更高。嗯，我们希望在情况复杂时分数更低，不是因为我们认为它错了，而是因为我们希望有人审查它。
嗯，所以，抱斥，你说的正确是什么意思？
是的。所以如果如果置信度分数高于阈值，意味着比它高，对吧？所以，假设我的置信度分数是 0.9. 那可能意味着，对吧？我一次发送多条消息，但没有其他理由让我认为那些消息是错的。嗯，我们和客户一起选择把阈值设得比那个低，因为他们不希望他们的员工每次有点复杂的事情都得介入。但我们同意，如果低于 0.75，他们就应该介入。这纯粹只是一个校准，对吧？是你你决定，如果你希望你的员工参与所有事情，就把置信度分数设为 100，对吧？你可以看到发生的每一件事。你整天都在点批准。你就是乔治·杰森。但是，嗯，那希望不是人们真正想要的，对吧？你想要一堆这些东西，如果它们是高置信度的，而且你知道，从根本上说是可以恢复的，比如说。就像，你知道，可能在某些情况下，你不想让消息自动发送出去。Hopefully 我们能控制住那个。但总的来说，就像，我们想把它设置在一个我们觉得能从我们的人力中获得一些规模的地方，对吧？这意味着消息自动发送出去，对吧？

呃，是的。
是的，试图评估是否……
是的。是的。所以问题是关于置信度评分和复杂性的混淆。是的，100% 同意。而且再次，这是我认为我们对它现在的运作方式感到满意的事情之一，但我不确定我们是否正确地处理了置信度部分。嗯，但同时，就像这个概念，我认为是好的，对吧？你知道，你有你需要的信息吗？你知道，有没有什么，就像，你理解用户的意图吗？或者，你知道，他们说了些模棱两可的话吗？我们确实看到它触发的情况，对吧？并不是说我们从来没看到它，你知道，正确地评价自己，就像，嗯，我不太确定他们说了什么，但没有我们希望的那么频繁。所以我们把它和复杂性结合起来，部分原因是因为，你知道，我们只是想让它低于那个阈值，这样我们就能让人工审查它。这不是一个完美的系统，但我们认为它是一个能工作的系统。
所以它更像是信心……
正确。
呃，正确。所以，就那一点而言，它它不是对特定回应是否准确、完美、等等的信心，而是对我们不认为在回应是什么以及情况的复杂性方面存在不确定性混合的信心，对吧？这两者中的任何一个都可能把它推到阈值以下。
你们是如何托管的？
呃，所以这全是，呃，问题是关于托管的。所以这全是，嗯，Langraph 有一个预先构建的容器化方案，你可以使用。我们正在使用它，并做了一些修改。嗯，我们基本上部署了这两半，对吧？所以，回到这个，我们用 Terraform 部署这两半。你知道，所有东西都和 GitHub actions 连接起来。我的意思是，就像，你知道，我们我们正在尽可能地自动化，但我们使用的是大部分内置的 Lang Graph 容器化。
我以为有一个平台，你不知道。
我的意思是，我们我们正在和 Langchain 积极地就此进行对话。所以问题实际上也是，嗯，我们需要部署的具体性质。嗯，Langraph 平台目前不支持那个，对吧？所以就像，它它全都在发展中，但是，嗯，我们我们有过那些对话。

### 结语

嗯，让我暂停一下。我们还有 10 分钟。嗯，所以，或者大概 10 分钟，九分钟。嗯，让我自己检查一下我想谈的事情清单，只是为了确保我没有漏掉任何主要的东西。嗯，谈了那个，谈了那个。好的。我我想我们或多或少都讲到了。嗯，所以我很乐意开放提问。嗯，我有一些最后的想法，我会把它们留在这里。嗯，如果有人好奇的话。

还有其他问题吗？
是的。呃，所以问题只是关于，呃，构建这些东西的资源分配。所以，我的意思是，我想最好的说法就是，我们已经构建了一些类似的东西。我们没有为医疗保健做过，对吧？但我们能够引入一些东西，就，你知道，我有一个开源的 Langraph 项目，我很乐意用它作为这个客户代码的基础，对吧？再次，我们我们把它分叉了，我们把它引入了私有库。嗯，你知道，但它让我们你知道，部分地走上了正轨，部分原因是因为这并不是一个完全特殊的雪花，它它是一个带工具的工作流程。所以，你知道，我们，我想，每次做这个，我们在前期脚手架上的花费都更少了。嗯，而且，你知道，我们现在正在看另一个项目，那个会快得多。所以很多都只是，一旦你做了这个，并且你理解了机制，达到，你知道，足够好或者达到一个起点就快多了。嗯，但这确实是，就像，你知道，再次，我们我们仍然在做这个，我们已经做了几个月了，但我认为我们可能构建了本来需要一年的传统软件，甚至更多，对吧？你知道，在那么短的时间内。
还有其他问题吗？
所以你提到你做了很多编码。这个能稍微……我好奇 lang 到底有多少……
嗯，好的。所以，所以，呃，问题是关于“凭感觉编码”以及工具对这些框架了解多少。所以，“凭感觉编码”最大的问题是，当你处理一个新到模型不真正理解的东西时。嗯，你总是可以把 API 文档发给它们，它们通常做得很好。嗯，我在 Langraph 上遇到了很多地方，以前没人试过这么做，没人遇到过这个确切的 bug，我们就是必须来回积极地调试它。嗯，我绝对可以认可 03 是一个比 Claude 更好的调试器。嗯，所以，你知道，我们我们确实有情况需要那么做。嗯，但大部分情况下，就像，我的意思是，只要你能拿到文档，你知道，你你就能达到一个合理的地方。而且再次，就像，我是一个前工程师，我我可能最终会称自己为现任工程师，但但我现在可能不会，对吧？就像，我没有所有相同的实践和那种所有相同的卫生习惯，你知道，我们我们专业的工程师有。但我确实知道如何嗅出那种不好的行为。而且我非常擅长提示以得到我想要的。所以，那大概就是它的运作方式。

嗯，还有……哦，是的，请讲。
在这个例子中，不，有 MCP。MCP 在几个地方，对吧？所以如果你看这个连接，实际上有两个，其中一个我只是没有完全标记出来，顶部的蓝图知识库，那个黄色的盒子，那是在 Langraph 上下文中的一个 MCP 连接，然后垂直地，还有另一组连接回数据库。所以有几个地方它发生了，但再次，它主要是为了状态的交换，以及为了这个，你知道，文档的读取。主要是在那里发生。
是的。是的。当然。是的。是的。
所以问题是关于快速连发的短信。所以，是的，我们处理那个的方式是双重的。所以一个是，嗯，我们有一个可配置的，我不太确定我们是否打开了这个，但我们有这个概念，在实际发送处理之前有一个可配置的延迟。所以如果有人要连续发五条短信，我们先等五秒钟再做任何事，对吧？嗯，那是我们能捕捉到的一种方式。但另一种方式是，嗯，如果有人在之后发短信，我们会使之前正在运行的线程失效，对吧？我们不想要一个正在处理中的回应。我们想要拿走对话的完整上下文，把所有这些都发进去，然后我们一次性回复五条消息，对吧？所以这是智能重试和智能失效的结合。
是的。是的。
嗯，这个问题是关于流氓回应的。嗯，总的来说，我们我们给出了一些非常基本的指导，关于你只在这里回答与治疗相关的问题。如果有人想和你谈论天气，你只要说，“对不起，我帮不了那个。”嗯，你知道，或者其他更糟糕的事情。嗯，所以总的来说，那工作得很好。嗯，我们把它调整得很好，以便升级，对吧？如果有人基本上就是失控了，而你想不出回应，你就说，“对不起，我找人来帮你。”然后它会把置信度调低，然后人类就可以介入了。嗯，实际上这种情况并不多见。我的意思是，再说一次，如果你参与其中，就像，你知道，如果你参与其中，并且你花时间真正地与系统互动，你想要结果，而且你可能想回到你的生活中去。所以我们没有看到大量的这种情况，但但这就是我们在开发过程中的任何时候，如果遇到这种情况会处理它的方式。

你是否曾对 Lang graph 感到足够沮丧？
呃，是的，我是否曾对 Lang graph 感到足够沮丧？嗯，在任何时候，老实说。所以，我想说的一件事，而且我这这完全是一个个人项目。嗯，我在做一个副业，嗯，关于大学咨询。嗯，我只是把这个放在这里，因为我有时会展示有时会这样。重点是，我做这个项目时明确地想避免它。我说，我要做一个非常类似的事情，我有一个 AI 在工作流程中间，我希望它能提问，我希望它能思考，而且我不想用 Lang graph 或者 crew 或者任何其他这些框架，因为我不想依赖它们。嗯，所以我问，你知道，我问 Klein 给我写一个层，它在，你知道，和这些模型对话以及构建一个思考过程方面相当不错，而且它它做得很好。我的意思是，有这个框架的原因，部分是因为，你知道，再次，我们不会永远和这个客户在一起。我们希望他们能有一个可以操作的东西，我们希望他们能有一个可解释且易于使用的东西。就像，这全是，你知道，谷歌云里的日志，就像，这不是最有趣的体验。所以，你知道，这很大程度上是，明智地选择你的工具，你知道，有好有坏。就像，你用其他那些工具能得到更好的体验。
说到那个，呃，非常感谢你问我这个问题。
嗯，我我，所以 clin over cursor。嗯，我我承认 cursor 和 windsurf 很棒，顺便说一句。就像，我的意思是，有几个我真的很喜欢。嗯，cursor 和 windsurf 作为两个例子，它们它们只是想打这个狭窄的，你知道，事情，关于它必须花费每月20美元，因此它必须在如何将 token 发送到不同地方方面进行高度优化，否则他们的经济模型就会崩溃。嗯，Klein 不这么做。它非常简单。它真的，我的意思是，它非常聪明，但就像，它只是给一个聪明的模型提供工具，而那个聪明的模型可以花费任何它需要的成本。Klein 是 Claude code 和 codecs 的精神表亲，对吧？我的意思是，它是那种风格的东西，而不是一个必须达到这个非常狭窄目标并且必须在 token 如何流动方面做大量预优化的 IDE。
是的。是的。所以，我的意思是，老实说，这也是另一个我会举手说，这就是为什么我不是一个真正的软件工程师。我我没有一个健全的 Python 代码测试框架。我我没怎么需要过它，对吧？或者至少，就像，我用评估和系统的整体性能作为更好的基准，对吧？所以评估很重要。我们必须有那些。嗯，我，你知道，代码的另一面，就像，你知道，Stride 是一个 TDD 店铺，就像，我们我们的软件工程师在测试驱动开发方面非常非常擅长，所以蓝盒子测试得很好。嗯，但就我的代码而言，你知道，很大程度上是评估，比如说，代替了测试。嗯，这不是一个很好的答案，但那那大概就是我的想法。

好的。嗯，我想我们到时间了。非常感谢大家。这太棒了。嗯，我会在这里，如果你们想留下来聊聊。

[音乐]
