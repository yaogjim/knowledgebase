好的，我们开始吧！

大家好！我是 Fahd Mirza，欢迎来到我的频道。

虽然在本地测试这些大型语言模型（LLM）很有意义，也能学到很多东西，但它们的真正价值在于解决现实世界的问题。当我们看到这些模型和工具能够处理实际业务场景时，才能体会到它们的强大。

今天，我将向大家展示一个非常实用的真实世界用例：**利用 LlamaIndex 和 LlamaCloud 来审查和验证合同的合规性**。

## 合同审查工作流概览

我们要构建的东西，大致流程是这样的（参考视频中的图示）：

1.  **输入（合同）：** 我们会拿到一份合同文档（比如左侧展示的供应商协议）。这份合同里包含了很多条款、信息，我们需要检查它们是否符合规定。
2.  **知识库（法规）：** 我们有一个包含相关法规和指南的知识库（在这个例子中，我们用的是欧洲的 GDPR 法规）。
3.  **信息提取：** 使用 LlamaIndex 的能力，从合同中提取关键信息和条款，比如供应商名称、生效日期、涉及个人数据处理的条款等，并将它们结构化。
4.  **指南匹配：** 将提取出的合同条款与知识库（GDPR 指南）中的相关规定进行匹配和比对。
5.  **合规性检查与报告生成：** 根据匹配结果，判断合同条款是否合规，并生成一份最终的合规报告，指出哪些地方符合规定，哪些地方存在问题以及为什么。

在这个视频里，我们将主要使用 GDPR 作为合规性检查的标准。但这个流程非常灵活，你可以轻松地把它替换成你所在地区或行业需要遵守的任何其他法规或标准。我会把相关的代码笔记本链接放在视频描述里。

## 使用的技术：LlamaIndex 与 LlamaCloud

正如我提到的，我们将使用 LlamaIndex 来构建这个合同审查的智能工作流（Agentic Workflow）。

LlamaIndex 提供了一个名为 **LlamaCloud** 的托管环境，我们将利用它来简化索引（Indexing）和检索（Retrieval）的过程。当然，使用 LlamaCloud 你需要一个 API 密钥，你可以去 LlamaIndex 官网注册获取。

我假设你已经准备好了 LlamaCloud 的 API 密钥。如果你还不了解 LlamaIndex 是什么，可以搜索我的频道，我之前已经做过很多详细介绍的视频了。

## 代码实战

好了，让我们直接进入代码部分。

### 1. 安装必要的库

首先，我们需要安装 LlamaIndex 相关的库，包括 LlamaCloud 和 LlamaParse（用于解析文档）。

```bash
pip install llama-index llama-index-indices-managed-llama-cloud llama-cloud llama-parse
```

(等待安装完成...)

### 2. 处理异步操作

我们需要导入 `nest_asyncio` 这个库。它允许我们在像 Jupyter Notebook 这样的环境中嵌套运行异步事件循环，这对于 LlamaIndex 的一些异步操作是必需的。

```python
import nest_asyncio
nest_asyncio.apply()
```

### 3. 准备知识库（下载 GDPR 文档）

为了进行合规性检查，我们需要有法规文档。这里我们以下载 GDPR 的 PDF 文档为例，并将其保存在 `data` 目录下。

```bash
mkdir -p data
wget "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679" -O data/gdpr.pdf
```

(等待下载完成...)

### 4. 设置 LlamaCloud 索引

现在，我们需要在 LlamaCloud 上为我们的 GDPR 法规创建一个索引。这能让我们后续高效地检索相关规定。

在代码中，我们导入 `LlamaCloudIndex`，然后需要指定几个参数来初始化或连接到 LlamaCloud 上的索引：

*   `name`: 给你的索引起个名字，比如 "gdpr"。
*   `project_name`: 你在 LlamaCloud 上创建的项目名称。
*   `organization_id`: 你的 LlamaCloud 组织 ID。
*   `api_key`: 你的 LlamaCloud API 密钥（非常重要！）。

这些信息在你登录 LlamaCloud 账户后都能找到。

```python
from llama_index.indices.managed.llama_cloud import LlamaCloudIndex

# 假设你已经获取了 project_name, organization_id 和 api_key
# index = LlamaCloudIndex(
#     name="gdpr",
#     project_name="YOUR_PROJECT_NAME", # 替换成你的项目名
#     organization_id="YOUR_ORGANIZATION_ID", # 替换成你的组织ID
#     api_key="YOUR_LLAMA_CLOUD_API_KEY" # 替换成你的 LlamaCloud API Key
# )

# retriever = index.as_retriever(similarity_top_k=2)
```

**LlamaCloud 界面操作演示:**

（视频展示了如何在 LlamaCloud 网站上操作）

登录 LlamaCloud 后：

1.  选择或创建一个项目（比如叫 `gdprproj`）。
2.  进入 "Index"（索引）部分，点击 "Create Index"。
3.  给索引命名（比如 `gdpr`）。
4.  选择数据源：可以直接上传文件。点击上传区域，选择我们刚才下载的 `gdpr.pdf` 文件。
5.  配置数据接收器（Data Sink）：保持默认 "Managed" 即可，让 LlamaCloud 托管向量数据库。
6.  选择嵌入模型（Embedding Model）：你需要选择一个模型将文本转换成向量。这里需要创建一个新的集成（Integration），选择比如 OpenAI Embedding。你需要提供你的 OpenAI API 密钥，并选择一个具体的嵌入模型（比如 `text-embedding-3-small`）。验证连接有效后保存。
7.  解析设置（Parse Settings）：可以根据需要调整，比如选择更精确（Accurate）的模式。
8.  转换设置（Transform Settings）：可以保持默认的自动设置。
9.  点击 "Deploy Index"（部署索引）。

LlamaCloud 会开始处理你上传的文件，创建向量嵌入并构建索引。你可以在右侧看到索引的状态（In Progress -> Success）和相关信息（Index ID, Project ID 等）。

**回到代码:**

一旦 LlamaCloud 上的索引创建完成，上面的 Python 代码就能连接到这个托管的索引，并创建一个 `retriever` 对象，用于后续查询。

### 5. 使用 LlamaParse 和设置 API 密钥

为了解析合同，我们需要用到 LlamaParse。同样，LlamaParse 也需要 LlamaCloud API 密钥。

```python
from llama_parse import LlamaParse

# 需要设置 LlamaCloud API Key 环境变量或直接传入
# parser = LlamaParse(result_type="markdown")
```

运行上面的代码时，如果之前没有设置 API 密钥，会报错提示需要密钥。最推荐的方式是将密钥设置为环境变量或使用 Google Colab 的 Secrets 功能。

(视频展示了如何在 Colab Secrets 中设置 `LLAMA_CLOUD_API_KEY`)

设置好密钥后，再次运行 LlamaParse 的初始化代码就能成功。

```python
import os
from google.colab import userdata # 适用于 Colab 环境

# 从 Secrets 获取 LlamaCloud API Key 并设置环境变量
os.environ['LLAMA_CLOUD_API_KEY'] = userdata.get('LLAMA_CLOUD_API_KEY')

# 重新初始化 Parser
parser = LlamaParse(result_type="markdown")
```

### 6. 定义数据结构（Schema）

为了让 LLM 能够结构化地输出结果，我们使用 Pydantic 定义一些数据模型（类）：

*   `ContractClause`: 定义单个合同条款需要包含的信息（条款文本、是否提及数据处理、数据传输、是否需要同意、是否明确目的、是否有安全措施等）。
*   `ContractExtraction`: 定义从整个合同中提取的关键信息（供应商名称、生效日期、管辖法律、以及一个包含多个 `ContractClause` 对象的列表）。
*   `GuidelineMatch`: 定义条款与指南匹配的结果（匹配到的指南文本、相似度分数、相关性解释）。
*   `ClauseComplianceCheck`: 定义单个条款的合规检查结果（条款原文、匹配到的指南、是否合规、备注）。
*   `ComplianceReport`: 定义最终合规报告的结构（供应商名称、总体是否合规、摘要备注）。

这些 Schema 能指导 LLM 更精确地完成提取和分析任务。

### 7. 定义工作流和提示

现在，我们来定义整个合同审查的核心工作流。这部分代码会稍微复杂一些，因为它整合了所有步骤。

*   **导入库:** 导入工作流、事件、LLM、提示模板等相关模块。
*   **定义提示（Prompts）:**
    *   `CONTRACT_EXTRACT_PROMPT`: 指导 LLM 从合同文本中提取信息并填充到我们定义的 `ContractExtraction` Schema 中。
    *   `CONTRACT_MATCH_PROMPT`: 指导 LLM 对比单个合同条款和相关的指南文本，进行合规性评估，并填充 `ClauseComplianceCheck` Schema。
    *   `COMPLIANCE_REPORT_SYSTEM_PROMPT` / `COMPLIANCE_REPORT_USER_PROMPT`: 指导 LLM 基于所有条款的合规检查结果，生成最终的 `ComplianceReport`。
*   **定义事件类:** 定义工作流中不同步骤之间传递数据所用的事件类（如 `ContractExtractionEvent`, `MatchGuidelineEvent` 等）。
*   **定义工作流类 (`ContractReviewWorkflow`)**:
    *   `__init__`: 初始化工作流，设置解析器、指南检索器、LLM（这里使用了 OpenAI 的 `gpt-4o-mini`，同样需要 OpenAI API 密钥）等。
    *   `@step` 装饰器定义工作流中的各个步骤：
        *   `parse_contract`: 解析输入的合同文件（这里假设是 Markdown 格式，因为 LlamaParse 输出的是 Markdown）。
        *   `dispatch_guideline_match`: 对提取出的每个合同条款，分发一个匹配任务。
        *   `handle_guideline_match`: 对单个条款，使用之前创建的 `guideline_retriever` 从 LlamaCloud 索引中检索最相关的 GDPR 指南，然后调用 LLM 进行合规性判断。
        *   `gather_guideline_match`: 收集所有条款的匹配和合规检查结果。
        *   `generate_output`: 基于收集到的所有结果，调用 LLM 生成最终的合规报告。

### 8. 运行工作流并查看结果

最后，我们实例化工作流，并运行它。我们需要提供待审查的合同文件路径。

```python
# 假设我们有一个 vendor_agreement.md 文件在 data 目录下
# handler = workflow.run(contract_path="data/vendor_agreement.md")

# 异步处理和打印结果
# (代码片段展示了如何异步迭代事件并打印最终报告)
```

运行后，输出结果会显示：

*   `vendor_name`: 'ACME Office Supply, Inc.'
*   `overall_compliant`: False
*   `summary_notes`: "The contract contains noncompliant clauses regarding subprocessors and data transfer..." （合同包含关于子处理者和数据传输的不合规条款...）

这表明模型成功地分析了合同，并根据 GDPR 指南找出了不合规的地方。

## 总结

你看，使用 LlamaIndex 和 LlamaCloud，我们可以相对容易地搭建一个自动化的合同审查工作流。你可以根据自己的需求，替换其中的法规文件（知识库）和合同模板，适配不同的合规场景。

你需要准备好 LlamaCloud API 密钥和用于驱动 LLM 的密钥（比如 OpenAI API 密钥）。

希望这个真实的用例能给你带来启发！

如果你喜欢这个内容，请务必点赞并订阅我的频道。如果你已经是订阅者，请分享给你的朋友和同事，这对我帮助很大。

感谢观看！
