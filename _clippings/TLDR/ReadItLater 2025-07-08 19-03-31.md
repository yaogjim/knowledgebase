好的，这是对视频《Context Engineering for Agents》的详细文字和图表解读。

---

## 视频核心内容概述

该视频由 LangChain 的 Lance 主讲，系统地介绍了“上下文工程（Context Engineering）”这一概念，尤其是在构建 AI 代理（Agents）时的重要性。视频的核心论点是，上下文工程是构建高效、可靠代理的关键技能，它超越了传统的“提示工程（Prompt Engineering）”。视频将上下文工程的方法论归纳为四大核心策略：**写入（Write）、选择（Select）、压缩（Compress）和隔离（Isolate）**，并结合多个业界知名代理（如 Anthropic、Cognition 的研究）的实例，解释了这些策略的具体应用。最后，视频阐述了 LangChain 的 `LangGraph` 框架如何为这四大策略提供原生支持。

---

### 一、 什么是上下文工程？

**主讲人发言**：

> “你可能最近听过‘上下文工程’这个词。它很好地概括了我们在构建代理时所做的许多不同的事情。当然，代理需要上下文来执行任务，比如指令、外部知识以及工具调用的反馈。**上下文工程，就是一门在代理运行轨迹的每一步，用恰到好处的信息来填充上下文窗口的艺术和科学。**”

**视频内容解读**：

视频开篇首先定义了上下文工程的核心。它强调，与简单地给 LLM 一个提示不同，构建复杂的代理需要在其运行的每一步动态地、智能地管理其“工作记忆”（即上下文窗口）。

#### 1. 上下文工程的定义与起源

视频引用了两位行业领袖的观点来阐述“上下文工程”的由来和重要性。

*   **Tobi Lütke (Shopify CEO)** 的推文：
    *   他更喜欢“上下文工程”而非“提示工程”。
    *   它更好地描述了核心技能：为任务提供所有上下文，使其能够被 LLM 合理解决的艺术。

*   **Andrej Karpathy (前 OpenAI、Tesla AI 负责人)** 的推文：
    *   他赞同 Tobi 的观点。
    *   他将上下文工程定义为：**“在每一个工业级强度的 LLM 应用中，上下文工程是填充上下文窗口的精巧艺术和科学。”**

#### 2. LLM 作为操作系统的类比 (Andrej Karpathy)

视频通过一张图表和讲解，详细阐述了 Karpathy 将 LLM 类比为新型操作系统的观点，这有助于直观理解上下文工程的作用。

| 组件 (操作系统) | 类比组件 (LLM) | 描述 |
| :--- | :--- | :--- |
| **CPU** | **LLM 核心** | 负责处理和推理。 |
| **RAM (内存)** | **上下文窗口 (Context Window)** | 作为“工作记忆”，容量有限，处理速度快。 |
| **内存管理** | **上下文工程 (Context Engineering)** | **核心类比**：决定哪些信息（指令、知识、工具反馈）在何时被加载到“RAM”（上下文窗口）中。 |
| **外设/I/O** | **工具、文件系统、用户输入等** | LLM 通过这些外部接口获取信息，这些信息需要通过上下文工程进行处理后才能进入上下文窗口。 |



#### 3. 上下文的类型与代理面临的挑战

上下文工程需要管理多种信息来源：

*   **指令 (Instructions)**: 包括系统提示、记忆、少样本示例（few-shot examples）、工具描述等。
*   **知识 (Knowledge)**: 包括事实、从记忆中提取的信息等。
*   **工具 (Tools)**: 来自工具调用的反馈（如 API 响应）。

**挑战**：为什么这对代理来说尤其困难？

1.  **任务长期运行**: 代理执行复杂任务时会经历多轮对话和工具调用，上下文会迅速累积。
2.  **反馈信息累积**: 每次工具调用的结果都会被添加到上下文中，导致上下文窗口迅速膨胀。

视频展示了一个流程图，说明在多轮（Turn）交互中，上下文（包括系统消息、用户输入、工具调用、工具反馈）会不断增长，最终可能超出 LLM 的处理极限。



这会导致所谓的 **“长上下文失败 (Longer Context Failures)”**，视频引用了 Drew Breunig 的研究，列举了以下几种失败模式：

*   **上下文中毒 (Context Poisoning)**: 错误的幻觉信息进入上下文，影响后续决策。
*   **上下文分心 (Context Distraction)**: 过多的上下文信息淹没了核心训练数据或指令。
*   **上下文混淆 (Context Confusion)**: 多余的上下文信息影响了最终的响应。
*   **上下文冲突 (Context Clash)**: 上下文中的不同部分相互矛盾。

视频最后引用了 Cognition AI 的观点作为小结：**“上下文工程实际上是工程师构建 AI 代理的头等大事。”**

---

### 二、 上下文工程的四大核心策略

视频的核心框架是将上下文工程分为四大策略，并用一张总结性的图表进行展示。



#### 1. 写入上下文 (Write Context)

*   **定义**: 将上下文信息**保存到上下文窗口之外**，以供后续使用。
*   **类比**: 人类解决问题时会“记笔记”和“形成记忆”。
*   **具体实现**:
    *   **暂存盘 (Scratchpad)**: 在**单次代理会话内**持久化信息。
        *   **例子**: Anthropic 的多智能体研究系统中，主研究员代理会首先思考方法并将其规划保存到内存中，以防在后续步骤中因上下文窗口超出20万token而被截断。
        *   **实现**: 可以是一个运行时的状态对象（State Object）或文件。
    *   **记忆 (Memory)**: 在**多次代理会话间**持久化信息。
        *   **例子**: Generative Agents、ChatGPT、Cursor 和 Windsurf 都会自动从用户与代理的交互中生成长期记忆。
        *   **流程**: 新的上下文和已有的记忆被送入 LLM，LLM 进行处理后，会生成并写入更新后的记忆。

#### 2. 选择上下文 (Select Context)

*   **定义**: 将外部存储的信息**选择性地拉入**到上下文窗口中。
*   **具体实现**:
    *   **从暂存盘/状态中检索**: 比如，在工具调用后，从状态中读取之前步骤的结果。
    *   **从记忆中检索**:
        *   **语义记忆 (Semantic Memory)**: 检索事实。例如，关于用户的事实信息。
        *   **情景记忆 (Episodic Memory)**: 检索过去的经历。例如，过去的代理行为或少样本示例。
        *   **程序记忆 (Procedural Memory)**: 检索指令。例如，`CLAUDE.md` 文件中定义的项目规则。
    *   **从工具中检索**: 动态选择相关工具。有研究表明，对工具描述进行 RAG（检索增强生成）可以将工具选择的准确率提高3倍。
    *   **从知识库中检索 (RAG)**: 这是最常见的知识选择方式。视频提到了 Windsurf 的高级 RAG 策略，不仅仅是简单的嵌入搜索，还包括：
        *   使用 AST（抽象语法树）解析代码，并沿着语义上有意义的边界进行分块。
        *   结合多种检索技术，如 `grep`/文件搜索、知识图谱、嵌入搜索等。
        *   使用重排（re-ranking）步骤来优化检索结果。

#### 3. 压缩上下文 (Compress Context)

*   **定义**: 只保留执行任务所需的关键 token，减少上下文的长度。
*   **具体实现**:
    *   **摘要 (Summarization)**:
        *   **例子1 (Claude Code)**: 当会话达到上下文窗口容量的95%时，触发“自动压缩”功能，对历史对话进行摘要。
        *   **例子2 (Anthropic)**: 对已经完成的子任务工作区进行摘要，只保留关键结果。
        *   **例子3 (Cognition)**: 在将任务传递给线性的子代理时，对父代理的上下文进行压缩。
    *   **修剪 (Trimming)**:
        *   **启发式方法**: 比如只保留最近的几条消息。
        *   **学习式方法**: 训练模型来决定哪些上下文可以被安全地移除（视频引用了 `Provence` 论文）。

#### 4. 隔离上下文 (Isolate Context)

*   **定义**: 将上下文进行拆分，以帮助代理执行任务。
*   **具体实现**:
    *   **多智能体 (Multi-agent)**:
        *   **例子 (Swarms, Anthropic)**: 每个代理（或子代理）拥有自己独立的上下文窗口，并行地探索问题的不同方面。这实现了“关注点分离”，并极大地扩展了整个系统能够处理的总 token 数量。
    *   **环境/沙箱 (Environment/Sandbox)**:
        *   **例子 (Hugging Face DeepResearch)**: 将 token 密集型的对象（如图像、文档）保留在代码执行沙箱中，而不直接将它们的内容放入 LLM 的上下文窗口。只将这些对象的引用（如变量名）或简短的描述返回给 LLM。
    *   **状态分区 (State Partitioning)**:
        *   **例子**: 在一个结构化的状态对象（如 Pydantic 模型）中定义不同的字段来存储不同类型的上下文（如 `messages`, `scratchpad_notes` 等），然后在需要时按需从特定字段中读取。

---

### 三、 LangGraph 如何支持上下文工程

视频最后一部分详细介绍了 `LangGraph` 如何为上述四种策略提供强大的支持。

#### 准备工作：追踪与评估 (Tracing + Eval)

在进行任何上下文工程之前，你需要：
1.  **追踪 (Tracing)**: 能够观察和调试代理的每一步，包括 token 的使用情况。`LangSmith` 是实现这一点的绝佳工具。
2.  **评估 (Eval)**: 有一套评估标准来衡量你的改动是否提升了代理的性能，而不是降低了它。

#### LangGraph 对四大策略的支持

*   **1. 写入 (Write)**
    *   **暂存盘 (Scratchpad)**: `LangGraph` 的 **Checkpointing** 机制可以自动持久化代理的 **State Object**，完美实现了会话内的暂存盘功能。
    *   **记忆 (Memory)**: `LangGraph` 内置了**长时记忆 (Long-term memory)** 组件，可以轻松地将上下文持久化到外部数据库，实现跨会话记忆。

*   **2. 选择 (Select)**
    *   **暂存盘**: 在图的任何节点（Node）中，你都可以从 `state` 对象中读取（检索）信息。
    *   **记忆**: 在任何节点中，你都可以调用 `long-term memory` 来检索信息。视频提到了 DeepLearning.AI 和 LangChain Academy 的相关课程。
    *   **工具**: 视频提到了 `langgraph-bigtool` 这个库，它展示了如何使用 RAG 来动态选择工具。
    *   **知识**: `LangGraph` 是一个低层框架，你可以自由地在节点内实现任何复杂的 RAG 技术。

*   **3. 压缩 (Compress)**
    *   `LangGraph` 提供了一些开箱即用的工具，用于**摘要**和**修剪**消息历史。
    *   由于其低层灵活性，你可以在任何节点内定义自己的压缩逻辑，例如在工具执行后对返回结果进行后处理。

*   **4. 隔离 (Isolate)**
    *   **多智能体**: `LangGraph` 拥有多个预构建的多智能体架构，如 `langgraph-supervisor-py` 和 `langgraph-swarm-py`，并提供了大量教程和视频。
    *   **环境**: 可以轻松集成 `E2B`、`Pyodide` 等沙箱环境，在节点内执行代码，实现环境隔离。
    *   **状态**: `LangGraph` 的核心设计就是围绕一个结构化的 **State Object**。你可以通过定义一个复杂的模式（Schema，如 Pydantic 模型）来自然地将不同类型的上下文隔离在不同的字段中。

---
**总结**

视频系统性地将代理开发中的上下文管理问题抽象为“上下文工程”这一学科，并提出了一个清晰的四象限框架（写入、选择、压缩、隔离）。通过这个框架，开发者可以更有条理地思考和解决代理在处理复杂、长期任务时遇到的上下文溢出、性能下降等问题。同时，视频也展示了 `LangGraph` 作为一个灵活的低层框架，为实现这些高级的上下文工程策略提供了强大的原生支持。
