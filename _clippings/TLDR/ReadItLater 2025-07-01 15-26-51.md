好的，这是一份根据您提供的 YouTube 视频内容生成的简体中文语音文字稿。

### 开场介绍

我的名字是 Beyang，我是一家名为 Sourcegraph 的公司的首席技术官和联合创始人。我们公司主要开发开发者工具。今天，我想和大家分享我们对于一个新兴技能的一些观察和见解，那就是如何驾驭编码智能体（coding agents）。

### 关于“智能体”的争议

首先，让我们来看看关于“智能体”的讨论现状。不知道大家有没有看到，就在几天前，推特上出现了一些关于 AI 编码智能体有效性（或者从某些角度看是无效性）的激烈争论。

Jonathan Blow，一位非常有才华的开发者，他几乎单枪匹马地完成了独立游戏《Braid》的编码，可以说在编码能力上达到了大神级别。他转了一位我也非常尊敬和钦佩的人 Alex Albert 的推文，Alex 在 Anthropic 工作。这条推文基本上是在说，所有围绕编码智能体和代码生成的炒作，都只是炒作而已，并没有实质内容。

随后出现了一些回应，这些回应的观点也很多元。开发者世界里的一些其他大咖也参与了进来，比如 Jesse Frazelle，她是 Docker 早期的贡献者和维护者之一，也非常厉害。她的大意是说：“我觉得你说得对，但 Jonathan，你是站在那金字塔尖 0.01% 的程序员。对于我们这些凡人来说，它实际上帮助很大。”也就是说，如果你不是顶尖高手，这东西很有用。

但同时，也有像 Eric S. Raymond 这样的人物，他是开源运动的教父之一，他的回复就非常尖锐。他基本上是说：“你看，我觉得自己编程还算不错，但这些工具帮了我大忙。”

我个人最喜欢的回应，是当时 Hacker News 上的一篇热门帖子，作者是 Thomas Ptacek，一位非常厉害的安全工程师。他的观点完全相反，他说：“那些对 AI 持怀疑态度的人虽然很聪明，但他们简直是疯了，这些东西真的非常有用。”

我猜，如果你来参加这个会议，你可能也倾向于认为编码智能体是有实质性作用的。但即便是在这个房间里，关于智能体在哪些方面表现出色，大家可能也有不同的看法和最佳实践。比如，它们是只适用于小型编辑、前端应用，还是周末心血来潮的编码项目？它们能否真正用于你的生产代码库？

### 快速变化的技术格局

我认为，这恰恰反映了我们目前所处的动态技术环境。几个月前，我读到了一篇由 Jeff Huntley 写的博客文章。Jeff 当时是 Canva 的一名高级工程师，他在 Canva 的角色非常有趣：他负责采访公司内部所有使用 AI 工具（如 Cursor）的开发者，观察他们的使用方式。他得出的结论是，大多数人“用错了姿势”。

他写了一篇博文，列举了他看到的各种反面模式。而我对那篇博文的总结是：**目前人们使用编码智能体的最大错误，就是他们试图用六个月前使用 AI 编码工具的方式来使用它们。**

这听起来有点疯狂，因为通常情况下，一个工具的最佳实践不会在短短六个月内就发生改变。但我们正处在一个非常有趣的时间点。为什么会有如此突然的变化？

### 生成式 AI 的三个时代

我认为，这是因为在过去六个月里，我们在模型能力上经历了一次阶跃式的转变。我们都见证了生成式 AI 的黎明，也就是古老的 2022 年。ChatGPT 发布后，我们仿佛进入了 AI 的未来。这期间已经出现了三个截然不同的浪潮或时代，主要是由前沿模型能力的演进驱动的。而模型的能力，决定了应用层的主流架构。

1.  **GPT-3 时代**：当时所有的模型都是文本补全模型。这意味着人们构建的应用都是像 Copilot 或自动补全工具。主流的交互范式是：你输入一些东西，它帮你输入一些东西。
2.  **ChatGPT 时代 (2023年)**：随着 GPT-3.5 的出现，模型被指令微调成像聊天机器人一样互动。人们突然意识到，我可以直接向它提问，就像和人对话一样。后来，大家又发现，可以把代码库里的代码复制粘贴到聊天窗口，让它模仿这些模式来生成质量更高、幻觉更少的代码。这基本上意味着，2023 年，所有人都在构建 RAG-Bot，也就是一个聊天机器人加上一个检索增强生成（RAG）引擎。
3.  **智能体时代 (现在)**：现在，我认为我们已经进入了一个新的时代。新的模型能力决定了新的应用架构。

### 为智能体时代设计的原则

在 Sourcegraph，我们问自己：市场上的许多现有工具都是为 GPT-4 和 Claude 3 的聊天时代设计的，它们的功能和用户体验都是围绕着聊天式大语言模型的局限性构建的。那么，如果我们从头开始设计一个编码智能体，来释放这些具备工具使用能力的、有智能体特性的大语言模型（Agentic LLMs）的全部潜力，它会是什么样子？

以下是我的几个“激进观点”。这些是我认为在智能体时代更优越的设计决策，其中许多都与聊天机器人时代出现的“最佳实践”背道而驰。

1.  **智能体应该直接修改文件，而不是频繁请求许可。** 如果它每一步都要问你“嘿，我想做这个修改，可以应用吗？”，那当它问你的时候，如果它错了，就已经浪费了你的时间。人类需要从“循环内部”（in the loop）抽离出来，更多地站在“循环之上”（on the loop），进行引导和指导，而不是微观管理每一个变化。

2.  **我们或许不再需要重量级客户端。** 我们还需要一个 VS Code 的分支版本来操控大语言模型吗？如果智能体的契约是“你让它做事，它就去做事”，那么我们真的还需要所有围绕上下文管理、应用代码变更的复杂 UI 吗？还是说，我们可以直接让它做事，并期望它做对？

3.  **我们将超越“自选模型”阶段。** 在聊天机器人时代，更换模型很容易。但在智能体世界里，你使用的大语言模型本质上是智能体执行链的“大脑”，它们之间存在更深度的耦合。所以，简单地“即插即用”会变得非常困难。许多在座的、尝试过在智能体中混搭不同模型的人可能已经发现，期望不同模型产生相似结果是非常困难的。

4.  **我们将告别固定价格模式。** 智能体消耗的 token 非常多，所以相对于聊天机器人，它们看起来很贵。但越来越多的人开始做的比较是：它节省了多少人类的时间？所以相对于节省的人类时间，它们仍然是便宜的。而固定价格模式实际上引入了一种扭曲的激励机制：如果我按月向你收费，我的动机就会变成尽可能地降低推理成本，最简单的方法就是使用更“笨”的模型，但这只会浪费你更多的时间。

5.  **Unix 哲学将比垂直整合更强大。** 在开发者工具领域，能将简单的工具以良好组合的方式与其他有趣工具一起使用的能力非常强大。特别是对于智能体，由于对复杂 UI 的需求减少，你将开始看到更多由命令行驱动的工具。

6.  **我们从零开始构建新应用。** 我们有一个现存的、基于 RAG 的聊天编码助手叫做 Cody，它仍在被广泛使用。但我们决定为智能体世界从头开始构建一个全新的应用，因为我们不想被为上一代大语言模型构建的那些假设和约束所限制。

我喜欢用一个比喻：早期的互联网。当时人们是通过类似门户网站的界面来上网的。这在当时是正确的，因为它向你展示了互联网能做什么：看名人八卦、买车、看影评等等。但最终，通过一个个链接点击导航变得非常繁琐。而网络的真正力量，被一个简单的文本框释放了——你输入你想要的，然后直达目的地。我认为，在智能体 UI 的设计上，我们也应该追求这种简洁。

### Amp 智能体实战演示

那么，在实践中这是什么样子的呢？我们设计的编码智能体叫做 Amp，它有两个客户端，界面都极其精简。很多人看到后会问：“这是什么？就一个文本框？”这正是我们刻意设计的。

一个客户端是简单的 VS Code 扩展，另一个是命令行工具（CLI）。

我想冒个险，不做那些“构建一个简单应用”的演示，而是展示我们认为它最有用武之地的地方：在一个有真实用户的应用上，处理所有现存的约束，对代码库做出实际贡献。

（演示环节）

我打开了 Amp 的代码库，我想实现一个简单的修改。Amp 有一个服务器组件，其中有个功能叫“连接器”，可以让 Amp 与外部服务对话，比如我们的 issue 追踪工具 Linear。现在，Linear 连接器的图标是一个通用的网络图标，我很不爽，我希望它能根据端点自动显示一个更合适的图标，比如一个复选框。

我已经在 Linear 里提了一个 issue，现在我直接对 Amp 说：
> “请找到关于自定义 Linear 连接器图标的 Linear issue，然后实现它。”

Amp 会使用它能访问的工具集，包括读写文件、运行 bash 命令，以及通过 MCP 服务器接入的 Playwright、Postgres 和 Linear API。它会调用 Linear API 搜索 issue，找到我提到的那个，然后开始实现它。

值得注意的是，它自己调用工具，我没有指定。界面也保持简洁，你不需要看到底层所有的 API 调用细节。我们希望用户感受到的反馈循环是稳健的，无需微观管理。

（演示继续，Amp 开始读写文件，修改代码）

我现在使用 VS Code 的 diff 视图（差异对比）可能比编辑器视图还要多。我大部分时间就是审查它做的修改。

（一段时间后）

好了，大家看，这里的图标已经更新了。这是在我几乎没有进行任何引导的情况下完成的。但是，在另一个页面上，这个图标没有更新。这不奇怪，因为生产代码库中的变更往往比表面看起来更微妙。这里的原因是，这个管理页面需要读取配置才能判断这是一个 Linear 端点，而配置中可能包含密钥，所以我们禁止将这些信息发送到非管理员页面。

它第一次没做对很正常，现在我稍微引导一下它：
> “我注意到图标在 admin/connections 页面更改了，但在 settings 页面没有。请调查一下原因。”

我们让它在后台运行，稍后再回来看结果。

（演示结束，返回幻灯片）

### 从“超级用户”身上学到的经验

我们向一小群用户发布了 Amp，并刻意没有做太多营销。我们想打造一个社区，让大家一起探索未来 6 到 12 个月里，人机交互范式将如何演变。

最有趣的发现之一，是我们观察到用户的使用量存在巨大差异。顶尖用户每个月光是在推理成本上就要花费数千美元。起初我们以为是滥用，但和他们沟通后发现，他们确确实实在做有价值的工作。这让我们好奇：他们到底是怎么用的？

通过这些对话，我们总结出了一系列“超级用户”的最佳实践和新兴模式。

#### 1. 写长而详细的提示（Prompt）
超级用户写的提示非常长。他们意识到，如果你给大语言模型足够多的上下文，它们是可以被编程的，会比你只给一句话走得更远。所以，我们把 Amp 输入框里“回车键”的默认行为改成了换行，提交需要按 `Command + Enter`。这旨在鼓励用户写更长的提示，因为这能带来更好的结果。

#### 2. 主动引导智能体获取上下文和反馈
智能体虽然内置了获取上下文的工具，但在处理特定生产代码库时，有时会遇到“超纲”的情况。普通用户可能会放弃，但超级用户会主动告诉它：“在这个子目录里这样运行构建”或“这样运行测试”，帮助它完成反馈循环，从而走得更远。

#### 3. 构建快速反馈循环
一个非常主流的模式是利用 Playwright 和 Storybook 构建前端的快速反馈循环。Storybook 可以让你独立测试前端组件，而无需加载整个应用。这就像你成为了**为你的智能体服务的“开发者体验工程师”**，思考如何让它的循环速度更快。

#### 4. 用智能体来深入理解代码
有一种说法是智能体会让程序员变懒。但我们发现恰恰相反，超级用户会用智能体来更好地理解代码。它是一个很棒的入职工具，可以帮你快速了解不同部分如何协同工作。

#### 5. 更高效、更深入的代码审查
我们都做过代码审查（Code Review），这本质上也是一种对新代码的“入职”。面对一个巨大的变更请求（PR），我会先让智能体阅读 diff 并生成一个高层总结，然后再问它：“如果你是一个资深开发者，这个 PR 的切入点在哪里？”这极大地降低了我开始审查代码的心理门槛，让审查变得更彻底，甚至有点享受。

#### 6. 用子智能体处理复杂任务
我们看到越来越多子智能体的用例。最佳实践是，在处理长期、复杂的任务时使用子智能体。这可以让子任务的上下文被封装起来，避免污染主智能体的上下文窗口，从而防止模型性能随着上下文变长而下降。

### 总结：反面模式与正面实践

**反面模式回顾：**
1.  **微观管理**：像对待聊天机器人一样，步步引导。
2.  **提示过短**：不给足细节。对于你自己的代码库，你需要提供给它像提供给同事一样详细的信息。
3.  **把智能体当成偷懒的工具**：用它来帮你“TL;DR”（一言以蔽之）代码。恰恰相反，你应该用它来更快地进行更彻底的代码审查。你最终要为你提交的代码负责。

### 未来的展望：并行智能体

我们观察到最顶尖的 1% 用户中，出现了并行运行多个智能体的倾向。Jeff Huntley 就在用这个方法，他同时启动三四个智能体，分别处理他正在开发的编译器的不同部分。他设置好提示和反馈循环后，就让它们跑，然后自己去睡觉。这证明了智能体可以用于像编译器这样严肃的工程项目，但这需要刻意练习。

### 结论

我想留给大家的要点是：
1.  编码智能体是真实存在的，它是一项有很高天花板的技能。我们应该像学习如何使用编辑器或编程语言一样，投入时间去学习如何使用它们。
2.  学习的唯一途径就是实践，并与他人分享。

我们在 Amp 中内置了“对话分享”机制，就是为了鼓励知识传播。如果你想回顾本次演讲的最佳实践，我们发布了一份《Amp 用户手册》。欢迎大家来我们在主展厅的展台，可以领取 10 美元的免费额度来亲身体验。谢谢大家！
