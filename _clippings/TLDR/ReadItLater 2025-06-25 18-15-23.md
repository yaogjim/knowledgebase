好的，这是 Andrej Karpathy 的演讲《软件正在（再次）改变》的简体中文语音文字稿。

***

### 开场：软件正在再次改变

大家好！哇，现场来了这么多人。

今天我很高兴能在这里和大家聊一聊人工智能时代的软件。我听说在座的很多都是学生，比如本科生、硕士生、博士生等等，你们即将进入这个行业。我认为，现在绝对是进入这个行业的一个极其独特和有趣的时刻。

根本原因在于，软件正在再次发生改变。我之所以说“再次”，是因为我以前其实做过这个主题的演讲。但问题是，软件一直在变，所以我总有大量的新材料来创作新的演讲。而且我认为这次的改变是相当根本的。

粗略地说，软件在过去 70 年里，在如此根本的层面上并没有太大变化。但在最近几年里，它迅速地改变了大约两次。因此，有巨量的工作等着我们去做，有巨量的软件需要被编写和重写。

### 软件的三个时代：1.0, 2.0, 3.0

让我们来看一下软件的版图。这是一个很酷的工具，叫做 “GitHub 地图”，它基本上描绘了所有被编写出来的软件。这些都是给计算机的指令，用于在数字空间执行任务。如果你放大看，会发现这些都是不同类型的代码仓库，包含了所有已被编写的代码。

几年前，我观察到软件正在发生变化，出现了一种新型的软件。当时我称之为“软件 2.0”。这个想法是说，软件 1.0 是你为计算机编写的代码；而软件 2.0 基本上就是神经网络，特别是神经网络的权重。你不是直接编写这些“代码”，你更像是在调整数据集，然后运行一个优化器来创建神经网络的参数。当时，神经网络还被看作是一种另类的分类器，就像决策树之类的。所以我认为这种框架划分是更合适的。

现在，我们有了一个相当于软件 2.0 领域的 GitHub，那就是 Hugging Face。它基本上就是软件 2.0 的 GitHub。你也可以在 Model Atlas 上看到所有在那里编写的“代码”的可视化。顺便说一下，中间那个巨大的圆点，是图像生成器 Flux 的参数。每当有人在 Flux 模型之上进行微调，就相当于在这个空间里创建了一个 Git 提交，从而创造出一种不同类型的图像生成器。

所以，我们有了：
*   **软件 1.0**：编程计算机的计算机代码。
*   **软件 2.0**：编程神经网络的权重。

一个例子就是 AlexNet，一个图像识别神经网络。到目前为止，我们直到最近才熟悉的神经网络，都像是功能固定的计算机，比如把图像分类。

而我认为一个相当根本性的变化是，随着大语言模型（LLM）的出现，神经网络变得可编程了。我视其为一种全新的、独特的计算机。因此，在我看来，它值得一个新的称号：**软件 3.0**。

基本上，你的提示词（prompts）现在就是编程大语言模型的程序。而且，引人注目的是，这些程序是用自然语言（比如英语）编写的。这是一种非常有趣的编程语言。

总结一下这三者的区别，以情感分类为例：
1.  **软件 1.0**：你可以编写一段 Python 代码来做情感分类。
2.  **软件 2.0**：你可以训练一个神经网络。
3.  **软件 3.0**：你可以给一个大语言模型写提示词。

所以，我们不仅有了一种新的编程范式，而且令我惊讶的是，它竟然是用我们的母语——英语——来实现的。几年前，当我意识到这一点时，我发了一条推文，它引起了很多人的关注，至今仍是我的置顶推文：令人瞩目的是，我们现在开始用英语来编程计算机了。

当我在特斯拉研究自动驾驶时，我们试图让汽车自己开动。我当时展示过一张幻灯片，汽车的输入在底部，通过一个软件栈，最终输出方向盘和油门的控制。我当时的观察是，自动驾驶系统里有大量的 C++ 代码（软件 1.0），还有一些用于图像识别的神经网络（软件 2.0）。随着我们不断改进自动驾驶系统，神经网络的能力和规模不断增长，与此同时，大量的 C++ 代码被删除了。许多最初用软件 1.0 编写的功能，被迁移到了软件 2.0。例如，将不同摄像头、不同时间的图像信息拼接起来的工作，后来就由一个神经网络来完成，我们得以删掉大量代码。软件 2.0 的栈，可以说是在名副其实地“吞噬”自动驾驶的软件栈。

我认为我们正在再次目睹同样的事情。我们有了一种新的软件，它正在吞噬现有的技术栈。我们有了三种完全不同的编程范式。如果你即将进入这个行业，精通所有这三种范式会是一个非常好的主意，因为它们各有优劣。你需要决定某个功能是用 1.0、2.0 还是 3.0 来实现？你是要训练一个神经网络，还是仅仅提示一个大语言模型？这部分功能应该是一段明确的代码吗？我们都需要做出这些决策，并可能需要在这些范式之间流畅地切换。

### 大语言模型（LLM）：新的计算平台

现在，我想先谈谈如何理解 LLM 这个新范式，以及它的生态系统是什么样的。这个新计算机是什么？它的生态又是什么样的？

我想起了吴恩达（Andrew Ng）多年前的一句话，他说：“人工智能是新的电力。” 我确实认为这句话抓住了非常有趣的一点，因为 LLM 的确感觉像是具有公共事业（utility）的属性。像 OpenAI、Gemini、Anthropic 这样的 LLM 实验室，他们投入资本支出（CapEx）来训练模型，这就像是建设电网。然后他们通过 API 将这些智能服务提供给我们，这是运营支出（OpEx），我们通过按百万 token 计费的方式付费。我们对这个 API 的要求也和对公共事业非常相似：低延迟、高正常运行时间、稳定的质量等。

在电力系统中，你会有转换开关，可以在电网、太阳能、电池或发电机之间切换电源。在 LLM 领域，我们有像 OpenRouter 这样的工具，可以轻松地在不同类型的 LLM 之间切换。因为 LLM 是软件，它们不争夺物理空间，所以同时拥有六个“电力供应商”并随时切换是完全可行的。

有趣的是，就在前几天，很多 LLM 都宕机了，人们感觉被卡住无法工作。这让我觉得，当最先进的 LLM 宕机时，就好像是世界范围内的“智能断电”，就像电网电压不稳一样。我们对这些模型的依赖越深，地球就变得越“笨”。

然而，LLM 不仅有公共事业的属性，说它们有晶圆厂（fab）的属性也同样公平。因为构建 LLM 所需的资本支出非常巨大。技术树和研发机密也正在向 LLM 实验室集中。

但我觉得最有道理的类比是，**LLM 非常像操作系统（Operating System）**。它不仅仅是像水和电一样的商品，它们正日益成为复杂的软件生态系统。有趣的是，整个生态的形态也和操作系统非常相似：你有少数几个闭源提供商，比如 Windows 和 macOS；然后你有一个开源的替代品，比如 Linux。对于 LLM，我们也有几个相互竞争的闭源提供商，而 Llama 生态系统可能是目前最接近于成长为像 Linux 那样的东西。

当我意识到这一点时，我试着画了一张图。在我看来，LLM 就像一个新的操作系统。
*   **LLM 本身**：就像是 CPU。
*   **上下文窗口**：就像是内存（RAM）。
*   **LLM 的角色**：协调内存和计算，利用各种工具（Tool Use）、多模态能力来解决问题。

从这个角度看，它真的很像一个操作系统。再举个例子，你想下载一个应用，比如 VS Code，你可以下载 Windows、Linux 或 Mac 版本。同样地，你可以拿一个 LLM 应用，比如 Cursor，让它在 GPT、Claude 或 Gemini 系列上运行，这只是一个下拉菜单的选择。

还有一个类比让我印象深刻：我们现在仿佛回到了 20 世纪 60 年代。LLM 的计算成本仍然非常高昂，这迫使它们必须集中在云端。我们都只是通过网络与之交互的“瘦客户端”。我们中没有人能完全独占这些计算机，因此采用“分时共享”是合理的，我们每个人都只是云端计算机运行时的一个批次（batch）维度。这和当时计算机的样子非常相似。

个人计算革命尚未发生，因为它在经济上还不划算。但有些人正在尝试。事实证明，Mac Mini 非常适合运行一些 LLM，因为对于批次为 1 的推理，这完全是内存带宽受限的。这些可能是个人计算的一些早期迹象。

还有一个我想提的类比是，每当我在文本界面和 ChatGPT 或其他 LLM 交流时，我感觉就像是通过终端在和操作系统对话。一个通用的图形用户界面（GUI）还没有被真正发明出来。

### LLM 的独特之处和“心理学”

LLM 与早期计算在某些方面有独特的不同。其中一点让我印象深刻的是，**LLM 颠覆了技术的扩散方向**。通常，像电力、密码学、计算机、飞行、互联网、GPS 这些变革性技术，最先的使用者是政府和企业，因为它们新技术昂贵。之后才慢慢扩散到消费者。但 LLM 似乎是反过来的。早期计算机主要用于军事弹道计算，而 LLM 却被用来教我怎么煮鸡蛋。这对我来说太奇妙了，我们有了一个神奇的新计算机，它在帮我煮鸡蛋，而不是帮政府搞什么军事机密。企业和政府在采用这些技术方面，实际上落后于我们普通大众。

所以，在编程 LLM 之前，我们得花点时间思考这些东西到底是什么。我特别喜欢谈论它们的“心理学”。我喜欢把 LLM 看作是**“心智幽灵”或“人类心智的随机模拟”**。这个模拟器碰巧是一个自回归的 Transformer。它是在互联网上所有文本上训练出来的，因此它涌现出了类似人类的心理特征。

**LLM 的超能力：**
*   **百科全书式的知识和记忆**：它们能记住海量信息，比任何单个人类都多。这让我想起电影《雨人》，主角是一个自闭症天才，拥有近乎完美的记忆力。LLM 就像他一样，能轻松记住各种东西。

**LLM 的认知缺陷：**
*   **幻觉（Hallucination）**：它们会编造事实，对自身知识的内部模型还不够完善。
*   **参差不齐的智能（Jagged Intelligence）**：在某些领域它们是超人，但在另一些领域会犯人类绝不会犯的低级错误，比如坚称 9.11 大于 9.9。
*   **顺行性遗忘症（Anterograde Amnesia）**：一个新同事加入你的公司，会随着时间推移了解你的组织，积累背景知识，形成专业技能。LLM 本身不会这样做。它们的上下文窗口就像是“工作记忆”，你必须非常直接地编程这个工作记忆，它们不会默认就变得更聪明。电影《记忆碎片》和《初恋50次》里的主角，他们的权重是固定的，每天早上上下文窗口都会被清空，这给他们的生活带来了巨大的麻烦。LLM 时时刻刻都在经历这个。
*   **安全问题**：LLM 很天真，容易受到提示词注入攻击，可能会泄露你的数据。

所以，长话短说，你必须同时思考这个拥有超能力、但又有一堆认知缺陷和问题的“东西”。我们如何编程它们，既能利用其超能力，又能规避其缺陷？

### 机会（一）：部分自治应用

现在我想谈谈我们如何使用这些模型，以及最大的机会在哪里。

我最兴奋的一个领域是所谓的“部分自治应用”（Partial Autonomy Apps）。以写代码为例，你当然可以直接去 ChatGPT，复制粘贴代码和 bug 报告。但你为什么要直接和操作系统打交道呢？拥有一个专门为此设计的应用要合理得多。

**Cursor** 就是一个很好的例子。它是一个早期的 LLM 应用，具备我认为所有 LLM 应用都应有的实用特性：
1.  **上下文管理**：LLM 应用为你处理了大量的上下文管理工作。
2.  **多模型编排**：Cursor 在后台调用了多种模型，比如用于文件嵌入的模型、聊天模型、将代码差异（diff）应用到文件中的模型。这一切都为你编排好了。
3.  **特定应用的 GUI**：这一点非常重要。你不想只用文本和操作系统对话。看一个红绿色的代码差异，比阅读纯文本描述要容易得多。用 `Command+Y` 接受或 `Command+N` 拒绝，比打字快多了。GUI 让人类能够高效地审查这些易错系统的工作。
4.  **自治程度滑块（Autonomy Slider）**：在 Cursor 里，你可以只用 Tab 补全（你主导），也可以选中一段代码用 `Command+K` 修改它，或者用 `Command+L` 修改整个文件，甚至可以用 `Command+I` 让它在整个代码库里自由发挥。你掌控着这个“自治滑块”，根据任务的复杂性来决定你愿意交出多少控制权。

另一个成功的 LLM 应用是 **Perplexity**，它也有类似的特点：打包信息、编排模型、带有审查功能的 GUI（比如引用来源）、以及自治滑块（可以进行快速搜索、研究，或者深度研究后在10分钟后返回结果）。

我的问题是，我觉得很多软件都会变得部分自治。这会是什么样子？对于那些维护产品和服务的人来说，你将如何让你的产品变得部分自治？LLM 能看到人类看到的一切吗？能像人类一样行动吗？人类如何监督并保持在循环中？

### 机会（二）：人机协作与“拴住 AI”

我想强调一点，我们现在正在与 AI 合作，通常是它们生成，我们人类验证。让这个循环尽可能快地转动，符合我们的利益。

有两个主要方法可以做到这一点：
1.  **加速验证**：GUI 对此至关重要。GUI 利用了我们大脑中的“计算机视觉 GPU”。看东西比读文字更轻松、更有趣，它是通往你大脑的高速公路。
2.  **拴住 AI（Keep the AI on the leash）**：很多人对 AI 智能体（Agent）过于兴奋。但如果它给我一个上万行代码的修改，对我来说没什么用。我仍然是瓶颈，我必须确保它没有引入 bug。

当 AI 变得过于活跃时，就像有一只过于热情的大狗，反而会妨碍我完成工作。在我自己的工作中，我总是害怕得到太大的代码修改。我总是分小步、增量地进行，确保每一步都很好，让这个循环飞速旋转。

我看到一些博客文章也在总结与 LLM 合作的最佳实践。其中一点是，如果你的提示词很模糊，AI 可能不会完全按你的意愿行事，验证就会失败。花更多时间让提示词更具体，可以提高验证成功的概率，从而更快地推进工作。

这个道理也适用于其他领域。比如我正在思考 AI 时代的教育是什么样的。我不认为直接对 ChatGPT 说“嘿，教我物理”是可行的，AI 会在知识的森林里迷路。对我来说，这应该是两个独立的应用：一个给老师用来创建课程，另一个拿这些课程来教学生。中间我们有了一个“课程”这个可审查的产物，确保 AI 被“拴在”教学大纲上，不会跑偏。

这让我想起了我在特斯拉研究自动驾驶的经历，那也是一个部分自治的产品。仪表盘就是自动驾驶的 GUI，它向我展示神经网络看到了什么。在我任职期间，我们为用户增加了越来越多的自动化任务。

我第一次乘坐自动驾驶汽车是在 2013 年，一辆 Waymo 的车。那次 30 分钟的驾驶完美无瑕，零干预。当时我感觉自动驾驶近在眼前了。但 12 年后的今天，我们仍然在研究自动驾驶。所以，当我看到有人说“2025 年是智能体之年”时，我会很担心。我觉得这应该是“智能体的十年”。我们需要人类在环，需要小心行事。

我一直很喜欢“钢铁侠战甲”这个比喻。它既是一种增强工具（Tony Stark 可以驾驶它），也是一个智能体（战甲可以自主飞行）。这就是自治滑块。现阶段，对于这些易错的 LLM，我们应该更多地构建“钢铁侠战甲”（增强工具），而不是“钢铁侠机器人”（自主智能体）。我们应该构建的是拥有定制化 GUI 和良好用户体验的“部分自治产品”，让“生成-验证”循环尽可能快，同时不忘记原则上可以自动化这项工作。

### 机会（三）：为“氛围编程”和智能体而构建

软件的变革不仅在于出现了一种新的编程语言，更在于它是用自然语言编写的。突然之间，每个人都成了程序员。这绝对是前所未有的。过去你需要花 5 到 10 年学习才能在软件领域做点什么，现在不再是这样了。

我不知道有没有人听说过 **“氛围编程”（Vibe Coding）**。我发了一条关于它的推文，没想到成了一个大梗。它为一种大家都在感受但无法言说的东西命了名。Hugging Face 的 Tom Wolf 分享了一个孩子们进行“氛围编程”的视频，我非常喜欢。看到这个，你怎么会对未来感到悲观呢？未来是美好的。

我也试了一下“氛围编程”，因为它太有趣了。当你想构建一个超级定制化、似乎不存在的东西时，它非常棒。我用它构建了一个 iOS 应用，虽然我并不会用 Swift 编程。我还写了一个叫 Menu.gen 的应用，你可以拍下餐厅菜单，它会为菜品生成图片。

但有趣的是，对于 Menu.gen 这个项目，“氛围编程”写代码的部分其实是最简单的。当我试图让它变得真实可用时，比如加入用户认证、支付、域名、部署，那部分才真的难。这些 DevOps 的东西花了我一个多星期，因为我一直在浏览器里点来点去。比如，为了给网站添加谷歌登录，我必须按照 Clerk 库的说明文档一步步操作：“进入这个网址，点击这个下拉菜单，选择那个选项……” 简直疯了，计算机在告诉我该做什么，为什么不它自己做呢？

所以，我演讲的最后一部分，就是关于：**我们能直接为智能体（Agent）构建基础设施吗？**

现在有了一类新的数字信息消费者和操纵者。过去只有通过 GUI 的人类，和通过 API 的计算机。现在我们有了一个全新的东西：智能体。它们是计算机，但又像人。我们能为它们构建软件基础设施吗？

*   **为 LLM 设计的协议**：就像网站有 `robots.txt` 一样，我们可以有 `lm.txt`，用简单的 Markdown 文件告诉 LLM 这个域名是关于什么的。
*   **为 LLM 设计的文档**：大量的文档是为人类编写的，有列表、粗体、图片，LLM 很难直接使用。像 Vercel 和 Stripe 这样的公司已经开始将他们的文档转向对 LLM 更友好的 Markdown 格式。
*   **改变“点击”的思维**：仅仅把文档变成 Markdown 是不够的。每当你的文档中出现“点击这里”时，这都是不好的。LLM 无法原生执行这个操作。Vercel 正在把每个“点击”都替换成等效的 `curl` 命令，这样 LLM 智能体就可以代为执行。
*   **为 LLM 优化的工具**：有一些小工具正在涌现，帮助以 LLM 友好的格式摄取数据。比如 Git-Ingest，它可以把一个 GitHub 仓库的所有文件整合成一个巨大的文本文件，方便你复制粘贴给 LLM。还有像 Deep-Wiki 这样的工具，它甚至能让 AI 分析整个仓库并生成文档。

当然，未来 LLM 也许能学会自己去点击。但这仍然成本高昂且困难。我认为，与 LLM“相向而行”，让它们更容易地访问信息，是非常值得的。

### 总结

这是一个多么激动人心的时代！我们需要重写大量的代码，这些代码将由专业人士和“氛围程序员”共同编写。

*   LLM 像公共事业，像晶圆厂，但最像的是**上世纪 60 年代的操作系统**。
*   它们是易错的“心智幽灵”，我们需要学习如何与它们合作。
*   我们需要构建**部分自治产品**，利用 GUI 和良好的设计，让“生成-验证”循环飞速旋转。
*   我们也需要直接为**智能体**重构我们的基础设施。

回到钢铁侠的比喻，我认为在未来十年，我们将看到这个“自治滑块”逐渐从左（增强工具）滑向右（自主智能体）。我很期待看到那会是什么样子，也迫不及待地想和大家一起去构建它。

谢谢大家。
