好的，这是根据您提供的 YouTube 视频生成的简体中文语音文字稿，已移除时间戳并添加了适当的格式。

---

### 语言模型概述

我的名字是 Insop。今天，我想和大家探讨一下智能体AI，即作为语言模型使用方式进阶的智能体语言模型。

这是今天演讲的大纲。我们会先概览语言模型及其使用方式，然后讨论其常见局限性，以及一些可以改善这些局限性的方法。接着，我们会过渡到什么是智能体语言模型及其设计模式。

语言模型是一种机器学习模型，它能根据输入的文本预测下一个词。如此例所示，如果输入是“学生们打开了他们的”，语言模型就能预测接下来最可能出现的词是什么。如果语言模型是用一个巨大的语料库训练的，它实际上是在预测下一个词的概率。在这个例子中，你可以看到“书”和“笔记本电脑”的概率比词汇表中的其他词要高。所以，这个完整句子的补全可能是“学生们打开了他们的书”。如果你想继续生成接下来的内容，我们可以把生成的句子作为新的输入，再次送入语言模型，模型就会持续生成下一个词。

### 语言模型是如何训练的？

这些语言模型是如何训练的呢？主要分为两部分：预训练（pre-training）和后训练（post-training）。

首先，预训练阶段是指语言模型使用从互联网、书籍或不同类型的公开文本中收集的大量语料库进行训练，其目标是预测下一个词元或下一个词。当模型完成预训练阶段后，它在给定输入的情况下，已经相当擅长预测任何下一个词。

然而，预训练模型本身并不容易使用。因此，就有了后训练步骤。后训练阶段包括指令遵循训练（instruction following training）以及基于人类反馈的强化学习（reinforcement learning with human feedback）。

这个训练阶段意味着，我们可以准备一个数据集，其中包含具体的指令或问题，以及用户期望的、与问题和答案更相关的回答或生成输出。通过这种方式训练模型，使其更易于使用，并且能以特定的风格进行回应。

完成这一步后，还有一个额外的训练方法，即通过基于人类反馈的强化学习来使模型与人类偏好对齐，也就是使用奖励机制来调整模型。

让我们快速看一下指令数据集的模板。这是我们在指令遵循训练阶段用来训练模型的模板。如你所见，这里会替换进具体的指令和期望的输出。然后，这被输入到模型中。模型只针对响应部分进行训练，即根据给定的指令生成输出。

一个经过预训练和后训练的语言模型，在根据指令生成文本方面能力相当强。它基本上拥有大量的世界知识，可以轻松生成输出。这些模型发展迅速，并被用于我们日常工作中的各种应用领域，例如AI编程助手、特定领域的AI副驾驶，以及最广为人知的ChatGPT和相关的对话界面。

为了将这类模型用于你的应用程序或特定工具，你可以通过API调用云端的模型提供商或模型服务器。或者，你也可以将模型部署在本地机器上，甚至对于足够小的模型，可以部署在计算资源受限的移动设备上。

### 提示工程的最佳实践

通过API调用意味着什么呢？我们退一步看，语言模型接收自然语言文本输入，然后生成输出。这意味着我们需要准备某种形式的自由文本，即自然语言文本，作为指令或问题，然后将其放入特定格式，以便向模型提供商发起API调用。模型提供商通常在云环境中接收请求，生成输出，并通过API调用将生成的输出响应给你。然后，你基于这个模型构建的软件会解析这个输出，并直接使用它，或者你也可以进行后续的LLM API调用以进一步生成输出。

模型的输入是自由格式的文本。因此，你如何准备输入，也就是所谓的“提示工程”（prompting），至关重要。有一些众所周知的最佳实践策略可以指导你如何准备提示词。

这里是一些例子：
*   **编写清晰、描述性强且详细的指令**，这有助于模型生成你想要的输出。
*   **可以包含几个例子**，展示你期望看到的输出风格或格式。
*   **可以提供参考资料或上下文**，让模型依赖你提供的背景信息。
*   不要直接要求模型立即回答，而是**给模型时间去思考**，例如启用推理，或使用思维链（Chain of Thought, COT）方法。
*   不要让模型处理过于复杂的任务，而是**将任务分解**，并按顺序依次请求，也就是链式处理复杂提示。
*   最后一点是很好的工程实践：**建立良好的系统性追踪和日志记录**，这对你有帮助。同时，**自动化评估**对于推进你的应用开发也总是有益的。

让我们快速浏览一下每一项，以便更熟悉它们。

**编写清晰、描述性强的指令**
例如左边的例子，与其提出简短的请求，不如详细描述，这样模型才知道你要求它做什么，因为模型无法读懂你的心思。你需要描述清楚你希望模型为你生成什么样的输出。这对于所有语言模型的使用都非常有用。

**包含少量示例（Few-shot examples）**
这意味着给模型提供你期望的输入和输出示例。比如在这种情况下，你希望得到某种风格一致的输出。那什么是风格一致呢？你可以提供一个示例输入和示例输出来展示你想要的效果。然后，最后再提出你的原始问题。这样，模型就会根据你给的例子来生成输出。少样本示例对于生成你想要的输出总是有帮助的。

**提供相关背景和参考资料**
这对于许多需要基于事实信息生成文本的场景非常有帮助。LLM很容易生成一些不正确的信息，也就是所谓的“幻觉”（hallucination），尤其是在它不了解或不太自信的主题上。在这种情况下，提供上下文或参考资料总是有帮助的。

这里是一个你可能想在“检索增强生成”（RAG）等场景中使用的提示模板，我们稍后会讲到。模板会说：“请仅根据你提供的文章来回答。如果找不到答案，就说找不到。” 这样，模型就很可能会基于你提供的参考资料来生成答案。

**给模型时间思考**
这是一个重要的部分。换句话说，不要直接问问题，而是要求模型先思考一遍或想出自己的解决方案，最后再进行比较并生成输出。这也被称为“思维链”（Chain of Thought）。

这里有一个例子，在一些中等规模的模型上可能行不通。你可以要求模型评估学生的解法是否正确，并提供解题说明，最后给出学生的解法。由于系统提示或你的原始请求只是说“回答正确与否”，模型可能会答错。然而，对于同一个模型，如果你换一种方式准备提示，它就可能答对。你可以这样要求：“首先，请你自己解决这个问题，然后将你的解法与学生的解法进行比较。”通过这样做，模型会生成自己的解决方案，并在这个过程中有机会充分关注原始输入和它自己生成的所有内容，从而得出正确的答案。因此，推理和思维链对于生成你期望的输出总是有帮助的。

**分解复杂任务**
这可能是一个在你的应用中很容易实现的好方法。与其在一个请求中包含多个任务，不如将你的提示分解成简单的小步骤。具体做法是，准备一个简单的提示并生成输出。然后，将这个输出附加到第二阶段的提示中，再生成输出。接着，再将前一阶段的输出附加到第三阶段的提示中，如此往复，直到最终生成你想要的输出。这样做，你可能需要手动操作，但正如我们将在后面的幻灯片中看到的，这也可以由LLM自动完成。为每个请求设置一个简单、清晰的任务会是一个好方法。

**系统性追踪与评估**
这可能不那么显而易见，但就像许多工程应用开发一样，建立一个好的追踪和日志记录方式，对你的开发、调试和审计都绝对有帮助。同样的原则也适用于基于语言模型的开发。所以，跟踪日志总是个好习惯。

这也关系到在开发的早期阶段就建立自动化评估。换句话说，你需要准备问题和答案对，即标准答案（ground truth），以便将其与模型生成的输出进行比较。你可以用人工来评估，但这通常成本高且耗时。所以，你可以使用语言模型作为“评判者”。也就是说，你可以让语言模型来评估模型生成的输出和标准答案，从而为生成输出的质量打分，你可以用这个分数来衡量你当前正在开发的应用的进展。

这一点非常重要，因为语言模型在持续快速地进步，同时，你用于开发语言模型的方法和工具也在迅速发展。换句话说，没有清晰的评估，就很难取得进展，甚至很难更换模型。因为模型发展迅速也意味着一些模型很快会被弃用，这可能迫使你更换应用中使用的语言模型。所以，从一开始就建立一个好的评估方法绝对有帮助。

**提示路由（Prompt Routing）**
这是一个简单的想法，但对许多应用都很有用。与其直接处理输入的提示，你不如用一些软件或模型来检测用户的意图，然后将其发送给不同的提示处理器。这也被称为“提示路由器”。根据输入查询的类型，你可能需要使用简单的提示和简单的语言模型。这既有助于降低运营成本，又能通过更相关的提示和更适合该类型查询的语言模型来生成更合适的输出。

---

### 问答环节

**Petra:** 非常感谢你，Insop，这真是一场鼓舞人心的演讲。我们很快就会进入关于智能体AI的更多细节。我们确实想为大家提供一些背景知识以及该领域的发展历程。我想，也许我们可以回答一个刚刚出现的问题。这个问题有点具体，但可能很多人都在想。在进行良好训练时，是否有最佳的数据量？或者关于可用数据或使用数据方面，你有什么建议吗？

**Insop:** 我会简短回答。我假设这里的“训练”指的是在开源语言模型的基础上进行额外的微调。这确实取决于你的任务，很难一概而论。但如果你有足够的你希望模型学习的文本数据，你可以创建一些简单的问答对或指令遵循格式的数据集。你也可以利用语言模型来生成更多数据。但我认为，你可以先从几十个数据样本开始，看看模型是否能按照你的预期行事。然后，根据初步快速测试的结果或信号，你可以增加更多的数据集或数据样本，甚至可能使用语言模型来增强或创建合成数据。

---

### 语言模型的常见局限性

到目前为止，我们已经了解了语言模型的概况。外面有很多非常强大的模型，我们也了解了如何使用它们。然而，即使是现有的模型，仍然存在一些局限性，例如：
*   **幻觉（Hallucination）**：这是一个众所周知的问题，模型有时会生成不正确或错误的信息，尤其是在涉及计算或其他特定领域时。这是我们在应用领域中希望避免的问题。
*   **知识截止日期**：模型创建者在准备数据集时，总会在某个时间点截止数据收集。因此，模型可能没有见过最新的信息或新闻。
*   **缺乏溯源性**：模型可以回答许多世界知识问题和常识性问题，但它通常不会告诉你答案是来自哪个具体的数据源。
*   **数据隐私**：模型创建者使用公开可用的数据源来准备数据集，这意味着模型没有见过你所在组织或特定领域的专有数据。
*   **有限的上下文长度**：虽然上下文长度在迅速增加，但这需要一个精细的平衡。提供更长的上下文会给模型更多的信息，但同时也会带来运营成本和文本生成延迟的问题。

### 检索增强生成 (RAG)

为了解决这些常见的局限性，“检索增强生成”（Retrieval Augmented Generation, RAG）是一种有效的方法。它可以：
*   通过使用真实相关的参考资料来**减少幻觉**。
*   因为它知道参考资料的来源，所以可以**解决溯源问题**。
*   它允许你作为应用开发者或系统开发者，准备一个可以使用**自有专有数据**的系统。
*   因为它只选择相关的数据，所以可以**有效利用较短的上下文长度**。

它的工作原理是：你可以预先索引你自己的数据集或文本，方法是将其分成小块文本，然后使用嵌入模型将其转换为嵌入空间（embedding space），并将其存储在你的数据库或向量数据库中。当收到请求或查询时，你可以将查询也转换为嵌入空间，从而进行最近邻搜索，选出最相关的几个文本块，然后将它们作为提示的一部分。就像我们之前看到的幻灯片那样，你把参考资料放进提示中，并要求模型只利用这些参考资料。这是利用自有专有数据的一个好方法。

类似的方法也可以用在实际的AI搜索中，你可以依赖网络搜索或其他类型的搜索来提供信息作为索引。

这里还提到，RAG有很多方法和想法。最常用的方法是我们刚刚提到的，即将文本块转换为嵌入空间，然后进行最近邻搜索。但还有许多其他方法，例如你可以使用基于知识图谱的方法。如果你能从文本源生成知识图谱，那也有助于提取更相关的信息，这也被称为图RAG（Graph RAG）。总之，方法很多，你需要寻找并利用适合你的方法。

### 工具使用

语言模型最广泛的使用形式是文本输入和文本输出，这意味着它可以回答多种类型的查询。然而，它本身无法执行操作或从外部世界提取信息。这就是“工具使用”（Tool Usage）或“函数调用”（Function Calling）发挥作用的地方。通过这种方法，你可以获取实时信息，或者通过生成软件或计算机代码来进行实际的计算。

这是什么意思呢？让我们看一个例子。如果你有一个AI聊天机器人，你问它“旧金山今天天气怎么样？”模型本身是不知道的。但是，如果你在提示中事先告诉模型，如果被问到与天气相关的问题，就生成一个特定格式的输出，以便软件可以解析并调用API。

如此例所示，模型会生成一个表示需要使用工具的输出，格式如下：`get_weather`，以及这个API调用或函数调用的输入参数，即我们询问的地点。然后，软件接收到模型返回的这个文本输出，进行解析，并实际向天气服务提供商发起API调用，获取天气信息。接着，再将这些信息反馈给语言模型。最后，语言模型会基于这个API返回的结果，生成一个更人性化、更有帮助的输出。

在某些情况下，模型还可以生成一段可在语言模型之外的沙盒环境中执行的软件代码，由协调所有这些活动的软件来执行。

### 智能体语言模型

智能体语言模型（Agentic Language Model）可以有多种定义。
*   **定义一：与环境互动**。与简单的语言模型用法（文本输入、文本输出）相比，智能体语言模型可以通过生成工具使用或检索请求来与环境进行交互。然后，环境（即语言模型之外的任何事物）可以提供信息，作为“观察”反馈给语言模型。整个智能体语言模型系统，包括其核心的语言模型和周边的软件，会处理这些信息，并将其存入记忆中，就像对话历史一样。

*   **定义二：推理与行动 (ReAct)**。智能体语言模型可以被定义为既能“推理”（reason）又能“行动”（action）的模型，也称为 ReAct。
    *   **推理**部分，你可以通过思维链等方法鼓励模型进行思考。
    *   **行动**部分，可以通过我们之前幻灯片中看到的方法，如检索、搜索引擎，或通过API调用使用计算器、天气API，甚至生成Python代码在沙盒中运行。

通过结合推理和行动，模型可以完成比简单的输入输出交互复杂得多的任务。

让我们更详细地看一下“推理与行动”的含义。在推理部分，与其直接执行被要求的任务，你可以准备一个提示，让模型先将任务分解并制定一个计划。换句话说，让模型自己来规划行动，而不是像我们之前在链式提示幻灯片中看到的那样由你来分解任务。然后，基于这个分解，模型可以通过API调用或工具使用来生成不同的行动，从而从外部世界提取或收集额外的信息。

最后，它将所有这些信息整合并存入记忆中，这样模型就知道发生了什么，并最终为你得出答案。

让我们看一个具体的例子。如果你有一个客户支持AI智能体，它可能如何工作呢？
当客户问：“我可以为产品‘富’申请退款吗？”
智能体系统会将这个请求任务分解为以下四种不同的行动：
1.  检查退款政策。
2.  检查客户信息。
3.  检查产品信息。
4.  最后，汇总信息并决定如何处理。

在每一步中，语言模型都会输出API调用，以便收集信息。例如，要检查退款政策，语言模型可能会向一个检索系统发出请求，该系统预先索引了公司的退款政策。它从中获取信息，并将其放入自己的上下文中。然后，利用这些信息，它可能会请求客户的订单信息。这可以通过在聊天中向客户询问更多信息，或者在系统中查找，具体取决于聊天系统的设计。对于产品信息也是同样的操作。

最后，它会根据政策、产品信息和客户订单信息得出结论，并将请求作为API调用发送给后续系统，同时准备一份响应草稿，交由人工进行最终审批。

所以，工作流程大致是这样的。从某种意义上说，智能体语言模型系统通常是让语言模型通过审查文档或任务，并调用外部工具来进行迭代调用。

例如，如果你想对某个问题进行研究，你可以让你的智能体去进行网络搜索或其他类型的搜索，然后迭代地进行总结，最后为你或你的系统准备一份报告。

另一个例子可以是软件助手智能体。你可以让这个智能体去处理某个软件bug或问题。这个智能体会查找并审查这个问题，收集相关的代码片段或文件，进行审查，然后提出解决方案。它还可以在自己的沙盒环境中执行代码，测试修复方案，并获取输出。然后迭代地尝试找到修复方法，最后向用户或开发者提交拉取请求（pull request）或变更。

这些就是我们以智能体形式使用语言模型的方式，通过交互式的语言模型调用来实现。

### 智能体AI的设计模式

智能体语言模型的使用之所以越来越广泛，其主要原因和区别在于：对于同一个模型，如果你直接向它提出请求，它可能无法处理。但是，如果你将任务置于这种智能体形式或模式中，模型就能完成更复杂的任务，即使是那些在不使用这种方式时无法完成的模型也可以。这就是智能体语言模型正在推动边界的原因之一，使得我们可以用AI智能体在更复杂或不同的领域完成任务。

以下是一些你可以用来实现智能体语言模型的设计模式：

*   **规划 (Planning)**：这至关重要。通过要求模型将任务分解成更简单、更清晰的子任务，语言模型后续就可以进行API调用或使用工具。
*   **反思 (Reflection)**：模型可以生成一个初步结果，然后下一次模型调用可以对同一个模型生成的输出进行批判。通过这种方式，输出可以得到改进。
*   **工具使用 (Tool Usage)**：当需要语言模型之外的信息，如实时信息或不同类型的数据时，你可以使用这个模式。
*   **多智能体协作 (Multi-agent Collaboration)**：这也是处理复杂任务的一种方式。

**反思（Reflection）**
这是一个易于实现且能带来良好性能的模式。让我们用一个具体的例子来说明。如果你想重构一段程序代码，与其直接要求模型立即改进，不如采用这种模式。
1.  **第一步**：你对模型说：“这是一段代码，请检查它并提供建设性的反馈。”
2.  **第二步**：将这个反馈带入第二个提示中。你可以这样准备提示：“这是一段代码和一些反馈（这些反馈来自模型自己）。请根据反馈重构代码。”
这种反思的方式很可能会为你的代码生成更好的输出或修复。

**工具使用（Tool Usage）**
这是我们之前见过的，要求模型生成API模式，以便你可以用这个API函数原型来编写实际的代码。或者，如果任务涉及实际计算或其他形式，你也可以要求模型生成一段程序作为输出，然后在你的软件或语言模型周边的软件脚手架所提供的安全沙盒环境中运行它。运行后，将执行结果反馈给模型，以便模型进行综合处理。

**多智能体协作（Multi-agent Collaboration）**
这是一种完成复杂任务的有趣方式。你可以将任务分解，并将这些子任务分配给专门负责特定任务的不同智能体。在这种情况下，一个“智能体”可以只是一个不同的提示或不同的“人设”（persona）。通常提示的开头是“你是一个有帮助的AI助手”，你可以为不同的智能体改变这个人设。你也可以根据任务使用相同或不同的模型。

让我们用一个具体的例子。如果你要为智能家居自动化构建一个多智能体系统，你可以创建不同的智能体：气候控制智能体、灯光控制智能体等等。这些都是包含不同人设提示和处理外部触发器的软件模块。这些智能体在内部工作，而一个协调者（本身也是一个带有软件脚手架的模型提示）来协调整个活动。

### 总结

这把我们带到了总结部分。智能体语言模型的使用是现有语言模型使用方法的一种演进和扩展。你在简单场景下使用的语言模型最佳实践，大部分在这里仍然适用。但是，你还可以使用其他额外的方法，例如更多的检索、搜索、工具使用，并准备不同类型的提示和工作流。这样，你就可以将语言模型作为其核心的“推理大脑”或“聪明的实习生”，并使用工具或检索方法与外部世界互动，将这些结果结合起来，从而完成复杂的任务，而不仅仅是简单的输入输出式语言模型用法。

---

### 问答环节

**Petra:** 非常感谢你，Insop。信息量太大了，希望对大家都有用。我们收到了很多问题。第一个问题是关于评估的。除了使用LLM作为评判者之外，你对评估智能体有什么好的策略建议吗？评估智能体似乎应该更复杂一些。

**Insop:** 这是一个很好的问题。LLM作为评判者是一种常用的方法，你用LLM来评估模型生成的输出与标准答案或某些参考信息。这种方法效果很好。我最近尝试过一种“智能体式评判方法”，也就是使用我们之前看到的反思模式。我不是直接向LLM评判者问一个问题，而是先让LLM提供初步的参考和反馈。然后，我再用另一个LLM调用或不同的提示说：“这是一个初级工程师的反馈。如果你是高级工程师，你会如何比较初级工程师的评估和你自己对输出的评估？”我发现这种反思模式有助于获得更好的评估结果，而不是仅仅依赖一次性的LLM评判者输出。我认为在评估阶段，可以有更多创造性的方法来使用智能体模式，因为评估真的非常非常重要。

**Petra:** 我们收到了几个关于针对特定用途增强AI智能体的问题，以确保它们按照你的应用需求来塑造。在技术方面，可以做些什么？

**Insop:** 这也是一个很好的问题。首先想到的是，如果你的任务很简单，那就直接使用简单的语言模型。但是，如果你发现任务稍微复杂一些，你可以尝试简单的智能体任务。你可以用很多不同的方式定义智能体语言模型。但如果你有一个稍微复杂的任务，你可以进行迭代式的语言模型调用，即使这样也能改善你的输出。我认为这完全取决于你的实际应用领域。但与其寻找可以应用语言模型的任务，不如反过来想：这个任务为什么不能用简单的方式解决？先尝试简单的用法，然后尝试用不同的模式来改进它。

**Petra:** 很多问题都涉及伦理考量，如何避免幻觉，如何避免使用可能不道德或背后有问题的的数据。你有什么建议吗？

**Insop:** 这又是一个很好的问题。由于其本质上是概率性生成，幻觉总是存在的，尽管很多人都在努力解决这个问题。所以这是一个问题，同时输出的内容也可能令人担忧。我认为模型提供商本身正在从不同类别检查生成的输出，同时你的应用，也就是应用构建者自己，也应该增加一些“护栏”。“护栏”可以是使用小型语言模型来快速检查输出，或者使用某些标准，比如分类器或其他东西，来过滤掉不合适的内容。这可以在最终生成阶段进行，也可以在输入阶段对查询进行处理，以避免问题。当然这可能会产生反作用，但我认为作为企业或业务，你可能需要采取更安全的方式，确保生成的输入、输出以及被请求的查询更安全或在合理范围内。

**Petra:** 最后一个问题，如何开始？你有什么推荐的开源模型吗？人们可以做些什么来开始测试和玩转这些技术？

**Insop:** 好问题。我想传达的一个信息是：从简单开始，进行实验，然后迭代。智能体语言模型听起来复杂、花哨，但它只是语言模型使用方式的一种演进和扩展。要开始，我认为你可以使用很多语言模型框架和智能体框架。但是，我建议从一个“游乐场”（playground）类型的环境开始。比如，模型提供商通常有他们的游乐场，你可以在那里输入你的提示，并立即看到输出，这样你就可以快速实验。当你熟悉了之后，再使用API从你的代码、你的程序中进行调用，看看会发生什么。通过这种方式，你可以获得见解，并实践准备提示词的最佳实践。一旦你有了这些，你就可以明智地决定是继续使用自己的代码库，还是利用广泛可用的库。简而言之，从简单开始，先在游乐场上工作，然后进行简单的API调用，最后决定是使用更扩展的库还是继续自己的方式。这既适用于普通语言模型，也适用于智能体语言模型。

**Petra:** 最后一个问题，Insop，这个领域发展得太快了。你有什么你关注的学习资源可以推荐给大家，以便在LLM和智能体AI领域保持更新吗？

**Insop:** 难题，但也是好问题。这有点难，但我会选择一些这个领域知名的专家，在Twitter或YouTube频道上关注他们，然后从那里获取最新的信息，再自己深入研究。我认为找到一个好的起点是很重要的。这里的参考资料，你可以截图保存，这可以作为一个很好的起点，因为它包含了一些关于智能体用法的课程，以及来自斯坦福和其他地方的优质课程。
