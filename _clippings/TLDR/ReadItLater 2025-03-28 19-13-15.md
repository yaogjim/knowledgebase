好的，这是根据您提供的YouTube视频文字稿内容整理和修正后的简体中文版本：

**LangGraph CodeAct 介绍**

**(视频内容整理)**

**引言：Manis Agent 与 CodeAct 思想**

过去一个月最激动人心的发布之一是 Manis，一个可以操作你电脑的智能体（agent）。其背后深入的技术研究以及创作者在 Twitter 上透露的信息表明，它受到了 CodeAct 思想的启发并加以运用。CodeAct 的基本思想是，智能体不再进行标准的工具调用（tool calling），而是实际**编写能够调用这些工具的代码**。

**CodeAct 与标准工具调用的对比**

*   **标准工具调用**:
    *   大多数人认为的现成智能体以循环方式工作：接收任务 -> 获取工具列表 -> 决定调用哪个工具 -> 调用工具 -> 获取结果 -> 继续循环直至完成。
    *   它利用许多闭源模型（如 OpenAI, Anthropic 等）支持的内置工具/函数调用（tool/function calling）功能。
    *   模型接收工具列表，生成用于描述如何调用特定工具（可能是一个或多个）的 JSON schema。
    *   开发者需要根据模型生成的 JSON 来实际执行并调用相应的工具或 API。

*   **CodeAct**:
    *   智能体不生成用于调用工具的 JSON，而是直接**编写 Python 代码**来调用这些工具/函数/API。
    *   即使像 `search_web` 只是一个你定义的任意函数或 API，智能体也会像编写普通代码一样去调用它。

**CodeAct 的优势与直觉**

这种方法有效的直觉有两个方面：

1.  **LLM 擅长编码**: 大语言模型（LLM）非常擅长编写代码，这是它们训练的主要目标之一，可以说它们在这方面比编写 JSON 更强。
2.  **代码允许复杂逻辑与状态管理**:
    *   编写代码本身蕴含了思考：执行步骤、函数调用顺序、结果处理等。
    *   当 LLM 编写代码进行函数调用时，它可以**以确定性的方式将多个函数调用链接起来**。
    *   与标准工具调用（调用一个工具 -> 获取响应 -> 再调用下一个）不同，CodeAct 生成的代码可以保存中间结果（如 `results` 变量）并在后续步骤中重用。
    *   整个调用链可以在 LLM 的一次调用中规划好。

**LangGraph CodeAct 包介绍与示例**

为了具体展示，视频介绍了一个名为 `LangGraph CodeAct` 的新 Python 包。

*   **基本原理**:
    *   构建在 LangGraph 之上，实现了 CodeAct 论文的思想。
    *   提示（Prompt）LLM 编写代码。
    *   执行 LLM 生成的代码（即使代码调用了环境中未直接定义的任意函数/工具）。
    *   在一个循环中运行，直到智能体判定任务完成。

*   **示例设置**:
    1.  **定义工具 (Tools)**: 定义一些 Python 函数，它们接收输入并返回输出，具有良好的类型注解。
    2.  **定义代码沙盒 (Code Sandbox)**:
        *   示例中使用了一个非常简陋的本地沙盒，使用 `eval` 函数执行代码。
        *   **警告：这在生产环境中不安全，请勿直接使用。**
        *   沙盒函数接收代码字符串和当前存在的本地变量字典。
        *   执行代码，并返回执行结果（通常是打印到控制台的字符串）以及执行后产生的任何新变量的字典。这是为了让智能体可以在后续步骤中利用这些状态。
    3.  **创建智能体 (Agent)**:
        *   导入所需的聊天模型（示例中使用 `Claude Sonnet`）。
        *   从 `langgraph_codeact` 导入 `create_codeact` 函数。
        *   （可选）导入检查点（checkpoint）功能，以便进行多轮对话。
        *   调用 `create_codeact` 函数，传入模型、工具列表和沙盒评估函数来创建智能体实例。

**示例演示：解决数学问题**

*   **运行与可视化**:
    *   在 `LangGraph CodeAct` 仓库的示例代码中运行。
    *   使用 LangGraph Studio (`langgraph dev`) 进行可视化。
    *   智能体架构很简单：`call_model` (调用 LLM) 节点和 `sandbox` (执行代码) 节点之间循环迭代。
*   **执行过程**:
    *   向智能体提出一个复杂的数学问题。
    *   智能体开始迭代：
        *   **第一次模型调用**: LLM 根据系统提示和用户问题，生成包含多个步骤和工具调用（如 `multiply`, `divide`, `subtract`）的 Python 代码块。代码中包含 `print()` 语句用于输出中间或最终结果。
        *   **第一次沙盒执行**: 执行生成的代码。代码中定义的工具函数（如 `multiply`）会被正确调用。`print()` 语句的输出被捕获。
        *   **第二次模型调用 (自修正)**: LLM 接收到沙盒执行的输出（打印的中间结果）。它分析这些结果，发现其中可能存在不合理之处（"nonsensical"），并决定重新进行计算。它再次生成修正后的 Python 代码。
        *   **第二次沙盒执行**: 执行修正后的代码，得到最终计算结果的打印输出。
        *   **最终模型调用**: LLM 将沙盒返回的最终结果整理成对用户的回复。
*   **LangSmith 追踪**: 演示了如何使用 LangSmith 详细查看每一步的输入输出，包括系统提示、模型生成的代码、沙盒执行的细节和变量变化，便于理解和调试。

**深入 LangGraph CodeAct 包**

*   **`create_codeact` 函数**: 核心函数，接收模型、工具列表、评估函数（最重要，用于执行代码）和可选的提示。
*   **默认提示 (Default Prompt)**:
    *   指示 LLM 输出 Python 代码片段来解决任务或推进步骤。
    *   要求将需要提取的输出通过 `print()` 打印到控制台（这会作为结果返回给模型或用户）。
    *   规定代码需用 Markdown 的围栏代码块（```python ... ```）包裹，以便解析。
    *   告知 LLM 除了 Python 标准库外，还可以使用哪些**额外提供的工具函数**。这些工具函数的定义和描述会被动态插入到系统提示中。

**CodeAct 的好处与总结**

*   **通用性**: 是一种进行工具调用的替代方法，适用于那些本身不支持高级 JSON 格式工具调用功能的模型（因为所有 LLM 都擅长写代码）。
*   **表达力**: 通过编写代码，可以实现比标准函数调用更复杂的逻辑、条件判断、循环和状态管理。
*   **LangGraph CodeAct**: 提供了一个便捷的方式来实现和实验 CodeAct 思想。

**结论**: CodeAct 是一种有趣且强大的技术，利用 LLM 的编码能力以不同的方式实现工具调用，特别适合需要复杂执行逻辑的场景。鼓励大家尝试使用 LangGraph CodeAct 包。
