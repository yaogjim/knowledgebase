好的，这是根据您提供的 YouTube 视频文字稿生成的简体中文语音稿。

# 让大语言模型来写提示：复合式 AI 管道中的 DSPy 入门

在过去的 18 个月里，我一直在思考一句话。你们中任何处理过数据管道，或者处理过需要解释人类创建的数据元素的人，都熟悉这句话：“有些人遇到问题时，会想：‘我知道了，用正则表达式！’然后他们就有了两个问题。” 正则表达式很脆弱，很易碎，你必须不断测试它，非常麻烦。我一直在想这个问题，因为我觉得可以非常轻易地把这句话换成：“我知道了，用提示（Prompting）！”

然后，你就有了两个问题。在过去三年里，提示工程是改变游戏规则的元素，可能是大语言模型（LLM）取得巨大成功和被广泛接纳的原因之一。它们非常神奇，但既是礼物也是诅咒。

说它是礼物，是因为任何人都可以描述程序、函数和任务，特别是那些你需要他们来编写评估数据、确保你的管道按预期工作的领域专家。提示可以快速、轻松地编写。我曾指导一群学生基于 Overture Maps 的数据构建应用。最棒的是，所有东西都先进入大语言模型，然后当你开始开发管道时，再将它优化成更可重复、可扩展的函数。这能让你非常快地起步。提示的另一个好处是它们是自文档化的。你读一下提示，大概就能知道这个程序应该做什么。

但提示也很糟糕。特别是当它们被深埋在应用程序和管道中时。它们在不同模型上的表现也不同。这是提示工程中一个被严重低估的方面：我们可以用一个基准模型的性能，这个模型经过了强化学习的训练，然后我们稍微改变一下措辞，分数就一落千丈。这并非一个离散的一对一交互，模型的微小变化就可能导致结果的巨大差异。

第二个问题是，提示会变成一个“万金油”式的补丁集合。我最近分析了从 Claude 3.7 和 4 中提取的系统提示，我发现 Anthropic 内部的开发周期就是不断地加入热修复来解决问题。就是一些解决小 bug 的单行指令，然后当他们重新训练模型到 4.0 版本时，那些热修复就消失了。它变成了一个无所不包的杂物箱。随着你的应用程序或管道的发展，你的提示也会变成一个杂物箱，里面会有各种你不太明白为什么存在的奇怪语句。你们有多少人在代码库里见过一条注释写着“不要删”？提示里的情况就相当于这个。

另一件让我特别困扰的事情是，当提示仅仅作为格式化字符串被嵌入代码中时，它们包含多个组件，但你完全看不到这些组件。它们是完全不透明的。我们在提示中一遍又一遍地做着相同的任务，但它看起来仍然像一大块文本，有时甚至长达数页。

让我给你看看我说的多个组件是什么意思。我将用一个示例提示来作为我们今天的目录。这个提示来自 OpenAI 的提示指南，是他们在 SWE-bench 基准测试中表现最好的提示示例。我做了一个可视化，我阅读并标记了这个提示，把它分成了六个组件：

1.  **任务 (Task)**：只占整个提示的 1%。
2.  **思维链指令 (Chain of Thought Instructions)**：占了大约 20%。
3.  **详细的上下文和指令 (Detailed Context and Instructions)**：关于如何回答问题以及可以做什么。
4.  **示例 (Examples)**：包含一些少样本示例。
5.  **工具定义 (Tool Definitions)**：在 Claude 的系统提示里，这部分大概占了 70%。
6.  **格式化指令 (Formatting Instructions)**：因为这个例子是关于 Git 提交的，所以你必须非常明确和重复地说明如何正确格式化 Git 提交。

还有一个“其他”部分在最后。但问题在于，当这个提示在你的代码里时，它看起来不是这样的。它看起来是这样的，一大片不透明的文本，延续好几页。我们认为提示是任何人都能理解的东西，但当你在代码库中扫视它时，体验非常糟糕。实际上，这还有点不公平，我还没打开语法高亮。好了，打开语法高亮了，现在清晰多了吧？

这就是我们今天要解决的问题。

## Overture 地图与数据融合的挑战

我叫 Drew Brunig，我的背景是文化人类学和计算机科学。我帮助人类理解数据，也帮助数据理解人类。今天，我将谈谈 Overture 地arps 基金会，因为它将是我们今天的示例项目。我们将为 Overture Maps 创建一个真实的管道。

Overture 地图基金会提供一个免费、开放的地理空间基础和参考图层。它告诉你关于街道、建筑、地点、地址等等的一切。这不是某个不起眼的小项目，有近 40 家公司在构建它，由 AWS、Meta、微软、TomTom 共同创立。现在，这些数据被部署在很多公司的地图产品中，数十亿人正在使用这些地图信息，你今天就可以去使用它，完全免费。

今天我们将讨论兴趣点（POI）或地点，比如企业、学校、医院、公园等。这个数据层主要来自 Meta 和微软的数据，你可以直接使用。但我们将多个数据集（现在大概有四五个地点数据集）汇集在一起，我们必须做一个叫做“数据融合（Conflation）”的操作。如果你做过地理空间数据处理，你就知道数据融合是一个巨大的麻烦。它是将多个地理空间数据集合并的行为，以便将指向现实世界中同一个商业实体的数据关联起来。

这很难，非常痛苦。原因是地点数据是由人类创建的，存在糟糕的数据录入。你永远无法想象“Walmart”有多少种不同的拼写方式。此外，还有相似的区域名称。比如在亚特兰大，几乎所有东西都叫“Peach Tree”（桃树）。你要区分“桃树加油站”和街对面的另一个“桃树加油站”是两个不同的东西。我们还遇到过糟糕的地址和地理编码，地址格式化是一个非常难解决的问题。

所有这些问题，听起来都非常适合用大语言模型来解决，因为这都是人类创造的混乱数据。但问题是，我们的管道里有 7000 万个地点，而且我们需要将它们相互比较。这是一个每月的管道，很快就要变成每两周一次。我们不可能把所有东西都通过大语言模型处理，成本、速度、可靠性都不允许。

所以我们使用复合式 AI 管道（Compound AI Pipelines），进行空间聚类、字符串相似度比较、嵌入距离计算等等。大多数匹配并不需要大语言模型。我们自己就能搞定大部分。然后，我们再引入大语言模型。

但问题是，Overture 的匹配器是由来自多个不同公司的多个人维护和编辑的。他们可能临时加入，然后又被调到别的项目。所以，拥有一个巨大而不透明的提示对我们来说是个非常糟糕的主意。我们力求云平台无关、技术平台无关，并且能够轻松启动一切。我们可能还想在未来在不同的模型上运行它。

## DSPy：解决方案

我们如何解决这个问题？这就是为什么我成了 DSPy 的忠实拥护者。

DSPy 这个框架让一切都变得更容易。我认为这就是它的核心价值：明天会有更好的提示策略，会有新的优化方法论的论文发布，两周后会有比你现在用的更好、更便宜的模型。你不应该把自己和这些东西中的任何一个绑定。

这就是我喜欢 DSPy 的原因。DSPy 将你的任务与大语言模型解耦。它让你用编程的方式来定义你的任务。我们从写提示（prompting）转向了写程序（programming）。所以，我们可以跳过所有写提示的环节，直接写程序，这容易多了。

我们写的是任务，而不是提示。我们可以用 DSPy 来优化我们的函数，对照我们的评估数据，确保我们的提示是负责任和高性能的。我们还可以拥抱模型的可移植性。当一个新模型发布时，我们切换过去，用我们的评估数据跑一遍优化，然后就可以投入使用了。就是这么简单。

## DSPy 如何工作：签名与模块

让我们回到 OpenAI 的那个例子。我们想在我们的数据融合任务的提示中包含不同的组件。我们如何用 DSPy 来实现任务和指令呢？

DSPy 通过结构来创建提示。我们可以快速地规划出我们需要什么，然后管理我们的提示。我们需要两样东西：

1.  **签名 (Signature)**：一个花哨的词，意思就是“我想要的输入和输出是什么”。
2.  **模块 (Module)**：基本上就是“我要用什么提示策略来执行这个输入输出”。

签名可以只是简单的字符串，比如“输入 -> 输出”。我们也可以把它定义成一个包含多个输入和输出的类。模块则告诉你“如何”实现它，它们是提示策略。

-   **Predict**: 基本的模块，就是“把这个变成那个”。
-   **ChainOfThought**: “我希望你一步步思考来得到答案”。
-   **React**: 允许你使用工具。

模块可以保留可训练的参数，你还可以把这些模块堆叠起来。

这是如何快速上手的代码，大约 12 行。我们连接到大语言模型，DSPy 在后台使用 `light-llm`，所以你可以用 OpenAI、Anthropic、Ollama 等等。然后我在 `Predict` 模块中定义我的签名，即输入一个“问题”，得到一个“答案”。然后我就可以运行它了。

```python
# 示例代码
import dspy

# 1. 配置 LLM
turbo = dspy.OpenAI(model='gpt-3.5-turbo')
dspy.settings.configure(lm=turbo)

# 2. 定义签名并创建模块
class BasicQA(dspy.Signature):
    """Answer questions with short factoid answers."""
    question = dspy.InputField()
    answer = dspy.OutputField(desc="often a single word or phrase")

qa_predictor = dspy.Predict(BasicQA)

# 3. 运行
question = "What is the capital of France?"
prediction = qa_predictor(question=question)
print(prediction.answer)
```

它在后台做了什么？当你给它一个“问题 -> 答案”的签名，并放进 `Predict` 模块时，它会把它变成一个系统提示，告诉你它期望的格式。你完全不用操心这个。

酷的是，这是模块化的。我可以把 `Predict` 换成 `ChainOfThought`，只需要改几个字符，系统提示就变了，会包含“推理”部分，然后我就可以得到一个独立的“推理”字段，而我几乎什么都没做。

## 为数据融合任务定义签名

现在，让我们来定义一个签名类，这是我数据融合管道中调用大语言模型部分的开始。我用 Pydantic 风格的类型字段来定义。

```python
# 示例代码
class Place(dspy.BaseModel):
    name: str = dspy.InputField()
    address: str = dspy.InputField()

class PlaceMatcher(dspy.Signature):
    """Review two places and determine if they're the same place in the real world."""
    place1: Place = dspy.InputField()
    place2: Place = dspy.InputField()
    
    match: bool = dspy.OutputField(desc="Do the two places refer to the same place?")
    match_confidence: str = dspy.OutputField(desc="low, medium, or high")
```

文档字符串（docstring）会被用在你的提示里，这是一个简单有效的小技巧。我给字段添加了描述，比如 `match` 字段的描述是“这两个地方是否指向同一个地方？”。这也会被带到我的提示中。我还要求它给我一个匹配的置信度：低、中、高。

当我用两个地点调用这个匹配器时，我得到的是一个 Prediction 对象，里面有布尔值的 `match` 和一个高置信度的 `match_confidence`。最酷的是，我不需要解析任何 JSON，也不需要对着大语言模型大喊大叫让它正确格式化。它就这么自然地出来了。我没有用任何正则表达式，我不想自找麻烦。

就这样，我用大约 12 行代码处理了任务、思维链指令和所有的格式化问题。

## DSPy 的优化能力

剩下的就是那些详细的上下文和指令了，这些东西能帮你得到你想要的结果。在 DSPy 中，这一切都来自你的评估数据（eval data），来自优化我们提示的能力。

要在 DSPy 中优化一个提示，你只需要三样东西：

1.  **验证函数 (Validation Function)**：或者叫奖励函数、度量标准。我的度量标准很简单，就是把预测结果和人工标注的示例进行比较，看它们是否匹配。
2.  **优化器 (Optimizer)**：我们这里用的是 `MIPROv2`。
3.  **评估数据 (Eval Data)**：这是最重要的。

然后我们优化我们的匹配器，并保存优化后的提示。

我这里用了一个较小的模型（比如 Qwen 0.6B）来运行推理，但用一个更大的模型（比如 GPT-4）来充当“提示编写者”。在 MIPRO 中，我们用大语言模型来尝试编写更好的提示。它会生成多个候选提示，然后通过贝叶斯测试，比较这些提示在评估数据上的表现，找出表现最好的，并把它们最好的部分融合在一起，最后得出一个优化后的提示。

这个过程是自动的。它还会决定是否需要在提示中加入示例，需要多少个，是合成的还是真实的。你只要点击运行，然后看着你的分数上升。

这是原始的提示，大概是“判断两个兴趣点是否指向同一个地方”。经过一轮优化后，我得到了这样一个提示：“给定两个代表地点或商家的记录，每个记录至少包含一个名称和地址，分析信息并判断它们是否指向同一个现实世界实体。考虑大小写、音译、缩写或格式上的微小差异作为潜在匹配。只有当名称和地址都高度相似时才输出 true……”

这是一个很棒的提示，而且不是我写的。不仅如此，我还知道它的表现有多好。我的准确率从 60% 提高到了 82%，而我没有写一个字的提示。

## 模型的便携性

现在，如果这还不够酷的话，来看看这个。在 Overture，我们力求云平台无关。这有点尴尬，因为我们的成员里就有两个云平台（微软和亚马逊）和三个模型构建者（微软、亚马逊和 Llama）。

但酷的是，我只需要在代码里改一行，重新运行优化，就可以更换模型。

-   用 **Qwen** 模型，我的准确率从 60% 提升到 **82%**。
-   如果 Meta 来说“你得用 **Llama**”，我们运行优化，准确率从 84% 提升到 **91%**。
-   如果微软说“我们想试试 **Phi-3**”，我们再做一次，准确率从 86% 提升到 **95%**。

明天总会有更好的模型。而这里的重点是，每一个模型的最佳提示都是不同的。不要花无数个小时去构建一个在新模型出来后就要被扔掉的提示。

## 总结与下一步

如果你想把这个管道做得更深入，你可以尝试新的优化器，比如 DSPy 3.0 即将发布的 `Simba`。你可以利用微调（fine-tuning）。你可以构建多阶段模型，比如我有一个模型专门用来把地址拆分成组件，然后和我的数据融合器一起进行端到端的优化。你还可以整合工具。

记住，**DSPy 将你的任务与大语言模型解耦**。

-   **写任务，而不是写提示。**
-   **使用 DSPy 优化你的函数。** 更好的优化器总会出现，它让你专注于两件事：你想做的任务和你的评估数据。每个人都应该有评估数据，这是我们最有价值的东西。提示一文不值，评估数据才是黄金。
-   **拥抱模型的可移植性。** 你可以测试所有模型，并且测试得非常好。

所以，你今天就应该试试 DSPy。我给你们留两个作业。

第一个作业是，今天就开始用 DSPy。用它定义你的任务，别担心详尽的提示，也别担心格式化。随着你构建更成熟的管道，你可以与 DSPy 一同成长，引入你的评估数据并进行优化，就像我们做的，准确率从 60% 提高到 82%。

第二个作业是，去写一个 DSPy 的签名。就去试一试，非常简单，非常酷。另外，我希望你们去看看 Overture 的数据。如果你在你的技术栈里用到了任何地理空间数据，这是一个最好的入门数据集。它在 Databricks Marketplace 里就有。

最后，可以看看我的博客文章。我喜欢用每个人都能理解的方式来解释技术，这样我们才能进行富有成效的对话，而不被炒作或恐惧所蒙蔽。

非常感谢大家。
