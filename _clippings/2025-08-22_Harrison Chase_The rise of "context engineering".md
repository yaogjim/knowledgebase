---
title: "The rise of \"context engineering\""
source: "https://blog.langchain.com/the-rise-of-context-engineering/"
author:
  - "[[Harrison Chase]]"
published: 2025-08-22
created: 2025-08-22
description: "Header image from Dex Horthy on Twitter.Context engineering is building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task.Most of the time when an agent is not performing reliably the underlying cause is that the"
tags:
  - "Harrison Chase"
---
*标题图片来自* [*推特上的德克斯·霍蒂*](https://x.com/dexhorthy/status/1933283008863482067?ref=blog.langchain.com) *。*

上下文工程是构建动态系统，以正确的格式提供正确的信息和工具，使大语言模型（LLM）能够合理地完成任务。

大多数情况下，当智能体表现不稳定时，根本原因是没有向模型传达适当的上下文、指令和工具。

大语言模型（LLM）应用正从单一提示发展为更复杂、动态的智能体系统。因此，上下文工程正成为人工智能工程师能够培养的最重要技能。

## 什么是上下文工程？

上下文工程是构建动态系统，以正确的格式提供正确的信息和工具，使大语言模型（LLM）能够合理地完成任务。

这就是我喜欢的定义，它基于托比·卢特克（Tobi Lutke）、安库尔·戈亚尔（Ankur Goyal）和瓦尔登·严（Walden Yan）最近对此的看法。让我们来剖析一下。

**上下文工程是一个系统**

复杂的智能体可能会从许多来源获取上下文。上下文可以来自应用程序的开发者、用户、先前的交互、工具调用或其他外部数据。将这些全部整合在一起涉及一个复杂的系统。

**这个系统是动态的**

许多这些上下文片段可以动态传入。因此，构建最终提示的逻辑也需要是动态的。它不仅仅是一个静态提示。

**你需要正确的信息**

智能代理系统表现不佳的一个常见原因是它们没有正确的上下文。大语言模型无法读取人的想法——你需要给它们正确的信息。输入垃圾，输出垃圾。

**你需要合适的工具**

并非总是仅基于输入，LLM 就能解决任务。在这些情况下，如果你想让 LLM 有能力这样做，你需要确保它有合适的工具。这些工具可以是用于查找更多信息、采取行动或介于两者之间的任何工具。给 LLM 合适的工具与给它正确的信息同样重要。

**The format matters**

就像与人类交流一样，你与大语言模型（LLMs）交流的方式很重要。一条简短但具有描述性的错误消息比一个大的 JSON blob 更有用。这也适用于工具。在确保大语言模型能够使用工具时，工具的输入参数非常重要。

**它有可能完成这项任务吗？**

当你思考上下文工程时，这是一个非常值得提出的好问题。它强化了一个观点，即 LLMs 不是读心术工具——你需要为它们的成功做好准备。这也有助于区分失败模式。它是因为你没有给它正确的信息或工具而失败吗？还是它已经掌握了所有正确信息，只是搞砸了？这些失败模式有非常不同的解决方法。

## 为什么上下文工程很重要

当智能代理系统出错时，很大程度上是因为大型语言模型（LLM）出了问题。从第一性原理出发思考，大型语言模型（LLMs）可能出错有两个原因：

1. 基础模型搞砸了，它还不够好
2. 基础模型没有被给予适当的上下文来生成良好的输出

通常情况下（尤其是随着模型性能提升），模型错误更多是由第二个原因导致的。传递给模型的上下文可能由于以下几个原因而存在问题：

- 只是缺少模型做出正确决策所需的上下文。模型又不是读心术大师。如果你不给它们正确的上下文，它们就不会知道其存在。
- 上下文格式很差。就像人类一样，沟通很重要！当你将数据传入模型时，你对数据的格式化方式绝对会影响它的响应。

## 上下文工程与提示工程有何不同？

为什么从“提示词”转向“上下文”？早期，开发者专注于巧妙措辞提示词以引出更好的答案。但随着应用变得越来越复杂，向人工智能提供完整且结构化的上下文显然比任何神奇的措辞都重要得多。

我还要指出，提示工程是上下文工程的一个子集。即使你拥有所有的上下文信息，你在提示中如何组织它仍然至关重要。不同之处在于，你构建提示不是为了使其能很好地处理单一的输入数据集，而是为了处理一组动态数据并对其进行正确格式化。

我还要强调的是，上下文的一个关键部分通常是关于大语言模型（LLM）应如何表现的核心指令。这往往是提示工程的一个关键部分。你会说为智能体应如何表现提供清晰详细的指令是上下文工程还是提示工程呢？我认为两者都有一点。

## 上下文工程的示例

一些良好的上下文工程的基本示例包括：

- 工具使用：确保如果智能体需要访问外部信息，它拥有能够访问该信息的工具。当工具返回信息时，它们的格式应最大程度便于大语言模型（LLMs）理解。
- 短期记忆：如果一段对话持续了一段时间，创建该对话的摘要并在未来使用。
- 长期记忆：如果用户在之前的对话中表达了偏好，能够获取该信息。
- 提示工程：关于智能体应如何表现的指令在提示中清晰列出。
- 检索：动态获取信息并在调用大语言模型（LLM）之前将其插入到提示中。

## LangGraph 如何实现上下文工程

当我们构建 [LangGraph](https://github.com/langchain-ai/langgraph?ref=blog.langchain.com) 时，我们的目标是使其成为最可控的智能体框架。这也使得它能够完美地实现上下文工程。

使用 LangGraph，你可以掌控一切。你决定运行哪些步骤。你决定\*\*确切地\*\*将哪些内容输入到你的 LLM 中。你决定将输出存储在哪里。你掌控一切。

这使你能够进行所有你想要的上下文工程。代理抽象（大多数其他代理框架所强调的）的一个缺点是它们限制了上下文工程。可能存在一些地方，你无法确切更改进入大语言模型（LLM）的内容，也无法确切更改事先运行的步骤。

旁注：Dex Horthy 的《十二要素应用》是一本非常值得一读的书。其中很多观点都与上下文工程相关（“掌控你的提示”、“掌控你的上下文构建”等）。本博客的标题图片也取自 Dex。我们非常欣赏他阐述该领域重要内容的方式。

## LangSmith 如何助力上下文工程

[LangSmith](https://smith.langchain.com/?ref=blog.langchain.com) 是我们的大语言模型（LLM）应用可观测性与评估解决方案。LangSmith 的一项关键特性是能够 [追踪你的智能体调用](https://docs.smith.langchain.com/observability/tutorials/observability?ref=blog.langchain.com) 。尽管在我们构建 LangSmith 时“上下文工程”这个术语还不存在，但它恰如其分地描述了这种追踪所带来的帮助。

LangSmith 可让您查看智能体中发生的所有步骤。这使您能够了解为收集发送到 LLM 中的数据而运行了哪些步骤。

LangSmith 可让您查看 LLM 的确切输入和输出。这能让您确切了解 LLM 接收了什么——它拥有的数据以及数据的格式。然后，您可以调试这些数据是否包含任务所需的所有相关信息。这包括 LLM 可以使用哪些工具——这样您就可以调试它是否被赋予了有助于完成手头任务的适当工具。

## 沟通就是你所需要的一切

几个月前，我写了一篇名为《沟通就是一切》的博客文章。主要观点是，与大语言模型（LLM）进行沟通很困难，且未得到足够重视，它常常是许多智能体错误的根源。其中许多观点都与上下文工程有关！

上下文工程并不是一个新想法——在过去一两年里，智能体构建者们一直在这么做。这是一个新术语，恰如其分地描述了一项日益重要的技能。我们将围绕这个主题撰写并分享更多内容。我们认为我们构建的许多工具（LangGraph、LangSmith）非常适合用于实现上下文工程，所以我们很高兴看到对这方面的重视开始兴起。